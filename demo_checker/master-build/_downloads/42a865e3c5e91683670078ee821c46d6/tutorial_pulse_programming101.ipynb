{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Differentiable pulse programming with qubits in PennyLane\n=========================================================\n\n::: {.meta}\n:property=\\\"og:description\\\": Simulating differentialble pulse programs\nin PennyLane with qubits :property=\\\"og:image\\\":\n<https://pennylane.ai/qml/_images/thumbnail_tutorial_pulse_programming.png>\n:::\n\n::: {.related}\nahs\\_aquila Pulse programming on neutral atom hardware\n:::\n\nAuthor: Korbinian Kottmann --- Posted: 8 March 2023.\n\nQuantum computers perform gates via electromagnetic pulses on the\nhardware level. In differentiable pulse programming, we can write\nquantum algorithms directly on the hardware level and variationally\noptimize the shape, phase and amplitude of the interactions for our\ndesired goals. In this demo, we are going to introduce pulse programming\nwith qubits in PennyLane and run the ctrl-VQE algorithm on a two-qubit\nHamiltonian for the $\\text{HeH}^+$ molecule.\n\n| \n\n![](../demonstrations/pulse_programming101/pulse_illustration.png){.align-center\nwidth=\"50.0%\"}\n\n| \n\nPulses in quantum computers\n---------------------------\n\nIn many quantum computing architectures such as\n[superconducting](https://pennylane.ai/qml/demos/tutorial_sc_qubits.html),\n[ion trap](https://pennylane.ai/qml/demos/tutorial_trapped_ions.html)\nand [neutral atom\nRydberg](https://pennylane.ai/qml/demos/tutorial_pasqal.html) systems,\nqubits are realized through physical systems with a discrete set of\nenergy levels. For example, transmon qubits realize an anharmonic\noscillator whose ground and first excited states can serve as the two\nenergy levels of a qubit. Such a qubit can be controlled via an\nelectromagnetic field tuned to its energy gap. In general, this\nelectromagnetic field can be altered in time, leading to a\ntime-dependent Hamiltonian $H(t)$ describing the effect of the field on\nthe qubits. We call driving the system with such an electromagnetic\nfield for a fixed time window $[t_0, t_1]$ a *pulse sequence*. During a\npulse sequence, the state evolves according to the time-dependent\nSchr\u00f6dinger equation\n\n$$\\frac{d}{dt}|\\psi\\rangle = -i H(t) |\\psi\\rangle$$\n\nfrom an initial state $|\\psi(t_0)\\rangle$ to a final state\n$|\\psi(t_1)\\rangle$. This process corresponds to a unitary evolution\n$U(t_0, t_1)$ of the input state from time $t_0$ to $t_1$, i.e.\n$|\\psi(t_1)\\rangle = U(t_0, t_1) |\\psi(t_0)\\rangle$.\n\nIn most digital quantum computers (with the exception of\n[measurement-based](https://pennylane.ai/qml/demos/tutorial_mbqc.html)\narchitectures), the amplitude and frequencies of predefined pulse\nsequences are fine tuned to realize the native gates of the quantum\ncomputer. More specifically, the Hamiltonian interaction $H(t)$ is tuned\nsuch that the respective evolution $U(t_0, t_1)$ realizes for example a\nPauli or CNOT gate (see e.g. *cross-resonance* gates for superconducting\nqubits in).\n\nPulse programming in PennyLane\n------------------------------\n\nA user of a quantum computer typically operates on the higher and more\nabstract gate level. Future fault-tolerant quantum computers require\nthis abstraction to allow for error correction. For noisy and\nintermediate-sized quantum computers, the abstraction of decomposing\nquantum algorithms into a fixed native gate set can be a hindrance and\nunnecessarily increase execution time, therefore leading to more noise\nin the computation. The idea of differentiable pulse programming is to\noptimize quantum circuits on the pulse level instead, with the aim of\nachieving the shortest interaction sequence a hardware system allows.\n\nIn PennyLane, we can simulate arbitrary qubit system interactions to\nexplore the possibilities of such pulse programs. First, we need to\ndefine the time-dependent Hamiltonian $H(p, t)= \\sum_i f_i(p_i, t) H_i$\nwith constant operators $H_i$ and control fields $f_i(p_i, t)$. The\nHamiltonian depends on the set of parameters $p = \\{p_i\\}$. One way to\ndo this in PennyLane is in the following way:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nimport pennylane.numpy as np\nimport jax.numpy as jnp\nimport jax\nimport matplotlib.pyplot as plt\n\n# Set to float64 precision and remove jax CPU/GPU warning\njax.config.update(\"jax_enable_x64\", True)\njax.config.update(\"jax_platform_name\", \"cpu\")\n\ndef f1(p, t):\n    # polyval(p, t) evaluates a polynomial of degree N=len(p)\n    # i.e. p[0]*t**(N-1) + p[1]*t**(N-2) + ... + p[N-2]*t + p[N-1]\n    return jnp.polyval(p, t)\n\ndef f2(p, t):\n    return p[0] * jnp.sin(p[1] * t)\n\nHt = f1 * qml.PauliX(0) + f2 * qml.PauliY(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This constructs a\n`~pennylane.pulse.ParametrizedHamiltonian`{.interpreted-text\nrole=\"class\"}. Note that the `callable` functions `f1` and `f2` are\nexpected to have the fixed signature `(p, t)`. When calling the\n`~pennylane.pulse.ParametrizedHamiltonian`{.interpreted-text\nrole=\"class\"}, a `tuple` or `list` of the parameters for each of the\nfunctions is passed in the same order the Hamiltonian was constructed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p1 = jnp.ones(5)              # parameters for f1\np2 = jnp.array([1.0, jnp.pi]) # parameters for f2\nt = 0.5                       # some fixed point in time\nprint(Ht((p1, p2), t))        # order of parameters p1, p2 matters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can construct general Hamiltonians of the form\n$\\sum_i H_i^d + \\sum_i f_i(p_i, t) H_i$ using\n`qml.dot <pennylane.dot>`{.interpreted-text role=\"func\"}. Such a\ntime-dependent Hamiltonian consists of time-independent drift terms\n$H_i^d$ and time-dependent control terms $f_i(p_i, t) H_i$ with scalar\ncomplex-valued functions $f_i(p, t).$ In the following we are going to\nconstruct $\\sum_i X_i X_{i+1} + \\sum_i f_i(p_i, t) Z_i$ with\n$f_i(p_i, t) = \\sin(p_i^0 t) + \\sin(p_i^1 t) \\forall i$ as an example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coeffs = [1.0] * 2\ncoeffs += [lambda p, t: jnp.sin(p[0] * t) + jnp.sin(p[1] * t) for _ in range(3)]\nops = [qml.PauliX(i) @ qml.PauliX(i + 1) for i in range(2)]\nops += [qml.PauliZ(i) for i in range(3)]\n\nHt = qml.dot(coeffs, ops)\n\n# random coefficients\nkey = jax.random.PRNGKey(777)\nsubkeys = jax.random.split(key, 3) # create list of 3 subkeys\nparams = [jax.random.uniform(subkeys[i], shape=[2], maxval=5) for i in range(3)]\nprint(Ht(params, 0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize the Hamiltonian interaction by plotting the\ntime-dependent envelopes. We refer to the drift term as all constant\nterms in time, i.e. $\\sum_i X_i X_{i+1}$, and plot the envelopes\n$f_i(p_i, t)$ of the time-dependent terms $f_i(p_i, t) Z_i$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ts = jnp.linspace(0.0, 5.0, 100)\nfs = Ht.coeffs_parametrized\nops = Ht.ops_parametrized\nn_channels = len(fs)\nfig, axs = plt.subplots(nrows=n_channels, figsize=(5, 2 * n_channels), gridspec_kw={\"hspace\": 0})\nfor n in range(n_channels):\n    ax = axs[n]\n    ax.plot(ts, fs[n](params[n], ts))\n    ax.set_ylabel(f\"$f_{n}$\")\naxs[0].set_title(f\"Envelopes $f_i(p_i, t)$ of $\\sum_i X_i X_{{i+1}} + \\sum_i f_i(p_i, t) Z_i$\")\naxs[-1].set_xlabel(\"time t\")\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A pulse program is then executed by using the\n`~.pennylane.evolve`{.interpreted-text role=\"func\"} transform to create\nthe evolution gate $U(t_0, t_1)$, which implicitly depends on the\nparameters `p`. The objective of the program is then to compute the\nexpectation value of some objective Hamiltonian `H_obj` (here\n$\\sum_i Z_i$ as a simple example).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit.jax\", range(4))\n\nts = jnp.array([0.0, 3.0])\nH_obj = sum([qml.PauliZ(i) for i in range(4)])\n\n\n@jax.jit\n@qml.qnode(dev, interface=\"jax\")\ndef qnode(params):\n    qml.evolve(Ht)(params, ts)\n    return qml.expval(H_obj)\n\n\nprint(qnode(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We used the decorator `jax.jit` to compile this execution just-in-time.\nThis means the first execution will typically take a little longer with\nthe benefit that all following executions will be significantly faster,\nsee the [jax docs on\njitting](https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html).\nNote that when removing the `jax.jit` decorator, the numerical solver\n[odeint](https://github.com/google/jax/blob/main/jax/experimental/ode.py)\nfor the time evolution inside `~.pennylane.evolve`{.interpreted-text\nrole=\"func\"} is still jit-compiled by default.\n\nResearchers interested in more specific hardware systems can simulate\nthem using the specific Hamiltonian interactions. For example, we will\nsimulate a transmon qubit system in the ctrl-VQE example in the last\nsection of this demo.\n\nGradients of pulse programs\n===========================\n\nInternally, pulse programs in PennyLane solve the time-dependent\nSchr\u00f6dinger equation using the\n[Dopri5](https://en.wikipedia.org/wiki/Dormand%E2%80%93Prince_method)\nsolver for ordinary differential equations (ODEs). In particular, the\nstep sizes between $t_0$ and $t_1$ are chosen adaptively to stay within\na given error tolerance. We can backpropagate through this ODE solver\nand obtain the gradient via `jax.grad`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(jax.grad(qnode)(params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, one could consider computing the gradient with the\nparameter shift rule, which is particularly interesting for real\nhardware execution. In classical simulations, however, backpropagation\nis recommended.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Piecewise-constant parametrizations\n===================================\n\nPennyLane also provides a variety of convenience functions to create,\nfor example, piece-wise-constant parametrizations defining the function\nvalues at fixed time bins as parameters. We can construct such a\ncallable with `~pennylane.pulse.pwc`{.interpreted-text role=\"func\"} by\nproviding a `timespan` argument which is expected to be either a total\ntime (`float`) or a start and end time (`tuple`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timespan = 10.0\ncoeffs = [qml.pulse.pwc(timespan) for _ in range(2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This creates a callable with signature `(p, t)` that returns\n`p[int(len(p)*t/duration)]`, such that the passed parameters are the\nfunction values for different time bins. Note how the number of time\nbins is implicitly defined through the length of the parameters. In the\nfollowing example, we are going to use `4` and `10` time bins defined\nthrough the length of parameters, respectively. Let us create uniformly\nrandom parameters between 0 and 5 and plot the corresponding\npiece-wise-constant function sampled at `100` different points in time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "key = jax.random.PRNGKey(777)\nsubkeys = jax.random.split(key, 2) # creates a list of two sub-keys\ntheta0 = jax.random.uniform(subkeys[0], shape=[4], maxval=5)\ntheta1 = jax.random.uniform(subkeys[1], shape=[10], maxval=5)\ntheta = [theta0, theta1]\n\nts = jnp.linspace(0.0, timespan, 100)[:-1]\nfig, axs = plt.subplots(nrows=2, sharex=True)\nfor i in range(2):\n    ax = axs[i]\n    ax.plot(ts, coeffs[i](theta[i], ts), \".-\")\n    ax.set_ylabel(f\"coeffs[{i}]\")\nax.set_xlabel(\"time t\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use these callables as before to construct a\n`~.pennylane.pulse.ParametrizedHamiltonian`{.interpreted-text\nrole=\"func\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ops = [qml.PauliX(i) for i in range(2)]\nH = qml.pulse.ParametrizedHamiltonian(coeffs, ops)\nprint(H(theta, 0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that this construction is equivalent to using\n`qml.dot <pennylane.dot>`{.interpreted-text role=\"func\"}.\n\nVariational quantum eigensolver with pulse programming\n======================================================\n\nWe can now use the ability to access gradients to perform the\nvariational quantum eigensolver on the pulse level (ctrl-VQE) as is done\nin. For a more general introduction to VQE, see\n`tutorial_vqe`{.interpreted-text role=\"doc\"}. First, we define the\nmolecular Hamiltonian whose energy expectation value we want to\nminimize. This serves as our objective Hamiltonian. We are using\n$\\text{HeH}^+$ as a simple example and load it from the [PennyLane\nquantum datasets](https://pennylane.ai/qml/datasets.html) website. We\nare going to use the tapered Hamiltonian, which makes use of symmetries\nto reduce the number of qubits, see\n`tutorial_qubit_tapering`{.interpreted-text role=\"doc\"} for details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = qml.data.load(\"qchem\", molname=\"HeH+\", basis=\"STO-3G\", bondlength=1.5)[0]\nH_obj = data.tapered_hamiltonian\n\n# casting the Hamiltonian coefficients to a jax Array\nH_obj = qml.Hamiltonian(jnp.array(H_obj.coeffs), H_obj.ops)\nE_exact = data.fci_energy\nn_wires = len(H_obj.wires)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a realistic physical system with pulse level control, we are\nconsidering a coupled transmon qubit system with the constant drift term\nHamiltonian\n\n$$H_D = \\sum_q \\omega_q a_q^\\dagger a_q - \\sum_q \\frac{\\delta_q}{2} a^\\dagger_q a^\\dagger_q a_q a_q + \\sum_{\\langle pq \\rangle} g_{pq} a^\\dagger_p a_q$$\n\nwith bosonic creation and annihilation operators. The anharmonicity\n$\\delta_q$ is describing the contribution to higher energy levels. We\nare only going to consider the qubit subspace and hence set this term to\nzero. The order of magnitude of the resonance frequencies $\\omega_q$ and\ncoupling strength $g_{pq}$ are taken from (in GHz). Let us construct the\nHamiltonian in PennyLane:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def a(wires):\n    return 0.5 * qml.PauliX(wires) + 0.5j * qml.PauliY(wires)\n\ndef ad(wires):\n    return 0.5 * qml.PauliX(wires) - 0.5j * qml.PauliY(wires)\n\nomega = 2 * jnp.pi * jnp.array([4.8080, 4.8333])\ng = 2 * jnp.pi * jnp.array([0.01831, 0.02131])\n\nH_D = qml.dot(omega, [ad(i) @ a(i) for i in range(n_wires)])\nH_D += qml.dot(\n    g, [ad(i) @ a((i + 1) % n_wires) + ad((i + 1) % n_wires) @ a(i) for i in range(n_wires)]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The system is driven under the control term\n\n$$H_C(t) = \\sum_q \\Omega_q(t) \\left(e^{i\\nu_q t} a_q + e^{-i\\nu_q t} a^\\dagger_q \\right)$$\n\nwith the (real) time-dependent amplitudes $\\Omega_q(t)$ and frequencies\n$\\nu_q$ of the drive. We let $\\Omega(t)$ be a real piecewise-constant\nfunction whose values are optimized. In a transmon qubit systems,\nentangling gates such as `CNOT` are realized by driving a target qubit\nwith the resonance frequency of the control qubit. This is referred to\nas cross resonance and is described in. Here, we allow for more general\ntwo-qubit interactions by training the drive frequency $\\nu_q$ on each\nqubit.\n\nFor this drive, there are certain restrictions by the hardware that we\nwant to already account for to make our simulation as realistic as\npossible. We therefore restrict the amplitude to $\\pm 20 \\text{MHz}$ and\nthe frequency deviation $\\Delta \\nu_q = \\omega_q - \\nu_q$ to\n$\\pm 1 \\text{GHz}$ (as is done in). We achieve this by normalizing the\nrespective quantities with a shifted sigmoid\n$\\mathcal{N}(x) = \\frac{1 - e^{-x}}{1 + e^{-x}}$, which ensures\ndifferentiability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def normalize(x):\n    \"\"\"Differentiable normalization to +/- 1 outputs (shifted sigmoid)\"\"\"\n    return (1 - jnp.exp(-x))/(1 + jnp.exp(-x))\n\n# Because ParametrizedHamiltonian expects each callable function to have the signature\n# f(p, t) but we have additional parameters it depends on, we create a wrapper function\n# that constructs the callables with the appropriate parameters imprinted on them\ndef drive_field(T, omega, sign=1.0):\n    def wrapped(p, t):\n        # The first len(p)-1 values of the trainable params p characterize the pwc function\n        amp = qml.pulse.pwc(T)(p[:-1], t)\n        # The amplitude is normalized to maximally reach +/-20MHz (0.02GHz)\n        amp = 0.02*normalize(amp)\n\n        # The last value of the trainable params p provides the drive frequency deviation\n        # We normalize as the difference to drive can maximally be +/-1 GHz\n        d_angle = normalize(p[-1])\n        phase = jnp.exp(sign * 1j * (omega + d_angle) * t)\n        return amp * phase\n\n    return wrapped\n\nduration = 15.0\n\nfs = [drive_field(duration, omega[i], 1.0) for i in range(n_wires)]\nfs += [drive_field(duration, omega[i], -1.0) for i in range(n_wires)]\nops = [a(i) for i in range(n_wires)]\nops += [ad(i) for i in range(n_wires)]\n\nH_C = qml.dot(fs, ops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall, we end up with the time-dependent parametrized Hamiltonian\n$H(p, t) = H_D + H_C(p, t)$ under which the system is evolved for the\ngiven time window of `15ns`. Note that we are expressing time in\nnanoseconds ($10^{-9}$ s) and frequencies (and energies) in gigahertz\n($10^{9}$ Hz), such that both exponents cancel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H_pulse = H_D + H_C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we define the `qnode` that computes the expectation value of the\nmolecular Hamiltonian.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dev = qml.device(\"default.qubit.jax\", wires=range(n_wires))\n\n@qml.qnode(dev, interface=\"jax\")\ndef qnode(theta, t=duration):\n    qml.BasisState(list(data.tapered_hf_state), wires=H_obj.wires)\n    qml.evolve(H_pulse)(params=(*theta, *theta), t=t)\n    return qml.expval(H_obj)\n\nvalue_and_grad = jax.jit(jax.value_and_grad(qnode))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have all the ingredients to run our ctrl-VQE program. We use the\n`adam` implementation in\n[optax](https://optax.readthedocs.io/en/latest/), a package for\noptimizations in `jax`.\n\nIt has been shown that the loss landscapes of pulse programs are\ntrap-free for a variety of conditions and loss functions, including\nours. In practice however, we see that the optimization is senstive to\nthe initial values of the parameters and the optimization strategy. In\nparticular, we often find ourselves with very slow progress during\noptimization, indicating wide flat regions in the loss landscape. This\ncan be salvaged by increasing the learning rate. Sometimes, it proved\nadvantageous to increase the learning rate after an initial finer search\nfor a better starting point. Further, we note that with the increase in\nthe number of parameters due to the continuous evolution, the\noptimization becomes harder.\n\nWhether or not that is due to the increased parameter search space or an\ninherent effect of pulse programs like barren plateaus in variational\nquantum circuits is to be determined in future work.\n\nWe systematically tried a variety of combinations of learning rate\nschedule, optimizer, and initial values. Here, we provide one possible\nchoice leading to good results.\n\nWe choose `t_bins = 100` segments for the piece-wise-constant\nparametrization of the pulses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t_bins = 100  # number of time bins\n\nkey = jax.random.PRNGKey(999)\ntheta = 0.9*jax.random.uniform(key, shape=jnp.array([n_wires, t_bins+1]))\n\nimport optax\nfrom datetime import datetime\n\nn_epochs = 60\n\n# The following block creates a constant schedule of the learning rate\n# that increases from 0.1 to 0.5 after 10 epochs\nschedule0 = optax.constant_schedule(1e-1)\nschedule1 = optax.constant_schedule(5e-1)\nschedule = optax.join_schedules([schedule0, schedule1], [10])\noptimizer = optax.adam(learning_rate=schedule)\nopt_state = optimizer.init(theta)\n\nenergy = np.zeros(n_epochs + 1)\nenergy[0] = qnode(theta)\ngradients = np.zeros(n_epochs)\n\n## Compile the evaluation and gradient function and report compilation time\ntime0 = datetime.now()\n_ = value_and_grad(theta)\ntime1 = datetime.now()\nprint(f\"grad and val compilation time: {time1 - time0}\")\n\n## Optimization loop\nfor n in range(n_epochs):\n    val, grad_circuit = value_and_grad(theta)\n    updates, opt_state = optimizer.update(grad_circuit, opt_state)\n    theta = optax.apply_updates(theta, updates)\n\n    energy[n + 1] = val\n    gradients[n] = np.mean(np.abs(grad_circuit))\n\n    if not n % 10:\n        print(f\"{n+1} / {n_epochs}; energy discrepancy: {val-E_exact}\")\n        print(f\"mean grad: {gradients[n]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that we have converged to chemical accuracy after half the number\nof epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(nrows=1, figsize=(5, 3), sharex=True)\n\ny = np.array(energy) - E_exact\nax.plot(y, \".:\", label=\"$\\\\langle H_{{obj}}\\\\rangle - E_{{FCI}}$\")\nax.fill_between([0, len(y)], [1e-3] * 2, 3e-4, alpha=0.2, label=\"chem acc.\")\nax.set_yscale(\"log\")\nax.set_ylabel(\"Energy ($E_H$)\")\nax.set_xlabel(\"epoch\")\nax.legend()\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also visualize the envelopes for each qubit in time. We only plot\nthe real amplitude $\\Omega(t)$ and indicate the deviation\n$\\Delta \\nu_q = \\omega_q - \\nu_q$ of the drive frequency $\\nu_q$ from\nthe qubit frequency $\\omega_q$ in the labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_channels = n_wires\nts = jnp.linspace(0, duration, t_bins)\nfig, axs = plt.subplots(nrows=n_channels, figsize=(5, 2 * n_channels), sharex=True)\nfor n in range(n_channels):\n    ax = axs[n]\n    label = f\"$\\\\Delta \\\\nu_{n}$: {normalize(theta[n][-1]):.3}\"\n    ax.plot(ts, 0.02*normalize(theta[n][:-1]), \".:\", label=label)\n    ax.set_ylabel(f\"$amp_{n}$ (GHz)\")\n    ax.legend()\nax.set_xlabel(\"t (ns)\")\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that we obtain bang-bang like solutions as indicated in[^1], making\nit likely we are close to the minimal evolution time with `15ns`.\n\nConclusion\n==========\n\nPulse programming is an exciting new field within noisy quantum\ncomputing. By skipping the digital abstraction, one can write\nvariational programs on the hardware level, potentially minimizing the\ncomputation time. Ideally, this allows for effectively deeper circuits\non noisy hardware. On the other hand, the possibility to continuously\nvary the Hamiltonian interaction in time significantly increases the\nparameter space. A good parametrization trading off flexibility and the\nnumber of parameters is therefore necessary as systems scale up.\nFurther, the increased flexibility also affects the search space in\nHilbert space that pulse gates can reach. Barren plateaus in variational\nquantum algorithms are typically due to a lack of a good inductive bias\nin the ansatz, i.e. having a search space that is too large. It is\ntherefore crucial to find physically motivated ans\u00e4tze for pulse\nprograms.\n\nReferences\n==========\n\n[^1]: Ayush Asthana, Chenxu Liu, Oinam Romesh Meitei, Sophia E.\n    Economou, Edwin Barnes, Nicholas J. Mayhall \\\"Minimizing state\n    preparation times in pulse-level variational molecular simulations\\\"\n    [arXiv:2203.06818](https://arxiv.org/abs/2203.06818), 2022.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "About the author\n================\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}