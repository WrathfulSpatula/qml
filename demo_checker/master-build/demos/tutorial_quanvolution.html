
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Train a quantum convolutional neural network to classify MNIST images." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/circuit.png" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Quanvolutional Neural Networks &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_quanvolution.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Train a quantum convolutional neural network to classify MNIST images." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Quanvolutional Neural Networks &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_quanvolution.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Ensemble classification with Rigetti and Qiskit devices" href="ensemble_multi_qpu.html" />
    <link rel="prev" title="Learning to learn with quantum neural networks" href="learning2learn.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="ensemble_multi_qpu.html" title="Ensemble classification with Rigetti and Qiskit devices"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="learning2learn.html" title="Learning to learn with quantum neural networks"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_qml.html" accesskey="U">Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quanvolutional Neural Networks</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-demos-tutorial-quanvolution-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="quanvolutional-neural-networks">
<span id="quanvolution"></span><span id="sphx-glr-demos-tutorial-quanvolution-py"></span><h1>Quanvolutional Neural Networks<a class="headerlink" href="#quanvolutional-neural-networks" title="Permalink to this headline">¶</a></h1>
<p><em>Author: Andrea Mari — Posted: 24 March 2020. Last updated: 15 January 2021.</em></p>
<p>In this demo we implement the <em>Quanvolutional Neural Network</em>, a quantum
machine learning model originally introduced in
<a class="reference external" href="https://arxiv.org/abs/1904.04767">Henderson et al. (2019)</a>.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0)"><img alt="../_images/circuit2.png" src="../_images/circuit2.png" style="width: 90%;" /></a>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classical-convolution">
<h3>Classical convolution<a class="headerlink" href="#classical-convolution" title="Permalink to this headline">¶</a></h3>
<p>The <em>convolutional neural network</em> (CNN) is a standard model in classical machine learning which is particularly
suitable for processing images.
The model is based on the idea of a <em>convolution layer</em> where, instead of processing the full input data with a global function,
a local convolution is applied.</p>
<p>If the input is an image, small local regions are sequentially processed with the same kernel. The results obtained for each region are usually associated to different channels
of a single output pixel. The union of all the output pixels produces a new image-like object, which can be further processed by
additional layers.</p>
</div>
<div class="section" id="quantum-convolution">
<h3>Quantum convolution<a class="headerlink" href="#quantum-convolution" title="Permalink to this headline">¶</a></h3>
<p>One can extend the same idea also to the context of quantum variational circuits. A possible approach is given
by the following procedure which is very similar to the one used in Ref. [1]. The scheme is also represented in the
figure at the top of this tutorial.</p>
<ol class="arabic simple">
<li><p>A small region of the input image, in our example a <span class="math notranslate nohighlight">\(2 \times 2\)</span> square, is embedded into a quantum circuit.
In this demo, this is achieved with parametrized rotations applied to the qubits initialized in the ground state.</p></li>
<li><p>A quantum computation, associated to a unitary <span class="math notranslate nohighlight">\(U\)</span>, is performed on the system.
The unitary could be generated by a variational quantum circuit or, more simply, by a random circuit as
proposed in Ref. [1].</p></li>
<li><p>The quantum system is finally measured, obtaining a list of classical expectation values.
The measurement results could also be classically post-processed as proposed in Ref. [1] but, for simplicity, in this
demo we directly use the raw expectation values.</p></li>
<li><p>Analogously to a classical convolution layer, each expectation value is mapped to a different channel of a
single output pixel.</p></li>
<li><p>Iterating the same procedure over different regions, one can scan the full input image,
producing an output object which will be structured as a multi-channel image.</p></li>
<li><p>The quantum convolution can be followed by further quantum layers or by classical layers.</p></li>
</ol>
<p>The main difference with respect to a classical convolution is that a quantum circuit can
generate highly complex kernels whose computation could be, at least in principle, classically intractable.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this tutorial we follow the approach of Ref. [1] in which a fixed non-trainable quantum
circuit is used as a “quanvolution” kernel, while the subsequent classical layers
are trained for the classification problem of interest.
However, by leveraging the ability of PennyLane to evaluate gradients of
quantum circuits, the quantum kernel could also be trained.</p>
</div>
</div>
</div>
<div class="section" id="general-setup">
<h2>General setup<a class="headerlink" href="#general-setup" title="Permalink to this headline">¶</a></h2>
<p>This Python code requires <em>PennyLane</em> with the <em>TensorFlow</em> interface and the plotting library <em>matplotlib</em>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">pennylane.templates</span> <span class="kn">import</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RandomLayers.html#pennylane.RandomLayers" title="pennylane.RandomLayers" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">RandomLayers</span></a>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
<div class="section" id="setting-of-the-main-hyper-parameters-of-the-model">
<h3>Setting of the main hyper-parameters of the model<a class="headerlink" href="#setting-of-the-main-hyper-parameters-of-the-model" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">30</span>   <span class="c1"># Number of optimization epochs</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>    <span class="c1"># Number of random layers</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">50</span>    <span class="c1"># Size of the train dataset</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">30</span>     <span class="c1"># Size of the test dataset</span>

<span class="n">SAVE_PATH</span> <span class="o">=</span> <span class="s2">&quot;quanvolution/&quot;</span> <span class="c1"># Data saving folder</span>
<span class="n">PREPROCESS</span> <span class="o">=</span> <span class="kc">True</span>           <span class="c1"># If False, skip quantum processing and load data from SAVE_PATH</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>           <span class="c1"># Seed for NumPy random number generator</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>       <span class="c1"># Seed for TensorFlow random number generator</span>
</pre></div>
</div>
</div>
<div class="section" id="loading-of-the-mnist-dataset">
<h3>Loading of the MNIST dataset<a class="headerlink" href="#loading-of-the-mnist-dataset" title="Permalink to this headline">¶</a></h3>
<p>We import the MNIST dataset from <em>Keras</em>. To speedup the evaluation of this demo
we use only a small number of training and test images. Obviously, better
results are achievable when using the full dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_dataset</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>
<span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist_dataset</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Reduce dataset size</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>

<span class="c1"># Normalize pixel values within 0 and 1</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a> <span class="o">/</span> <span class="mi">255</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a> <span class="o">/</span> <span class="mi">255</span>

<span class="c1"># Add extra dimension for convolution channels</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz

   16384/11490434 [..............................] - ETA: 0s
 4104192/11490434 [=========&gt;....................] - ETA: 0s
11493376/11490434 [==============================] - 0s 0us/step

11501568/11490434 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<div class="section" id="quantum-circuit-as-a-convolution-kernel">
<h2>Quantum circuit as a convolution kernel<a class="headerlink" href="#quantum-circuit-as-a-convolution-kernel" title="Permalink to this headline">¶</a></h2>
<p>We follow the scheme described in the introduction and represented in the figure at the top
of this demo.</p>
<p>We initialize a PennyLane <code class="docutils literal notranslate"><span class="pre">default.qubit</span></code> device, simulating a system of <span class="math notranslate nohighlight">\(4\)</span> qubits.
The associated <code class="docutils literal notranslate"><span class="pre">qnode</span></code> represents the quantum circuit consisting of:</p>
<ol class="arabic simple">
<li><p>an embedding layer of local <span class="math notranslate nohighlight">\(R_y\)</span> rotations (with angles scaled by a factor of <span class="math notranslate nohighlight">\(\pi\)</span>);</p></li>
<li><p>a random circuit of <code class="docutils literal notranslate"><span class="pre">n_layers</span></code>;</p></li>
<li><p>a final measurement in the computational basis, estimating <span class="math notranslate nohighlight">\(4\)</span> expectation values.</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dev</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1"># Random circuit parameters</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rand_params</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">high</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_layers</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;autograd&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">phi</span><span class="p">):</span>
    <span class="c1"># Encoding of 4 classical input values</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RY.html#pennylane.RY" title="pennylane.RY" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RY</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="n">j</span><span class="p">)</span>

    <span class="c1"># Random quantum circuit</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RandomLayers.html#pennylane.RandomLayers" title="pennylane.RandomLayers" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">RandomLayers</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">rand_params</span></a><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)))</span>

    <span class="c1"># Measurement producing 4 classical output values</span>
    <span class="k">return</span> <span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="n">j</span><span class="p">))</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</pre></div>
</div>
<p>The next function defines the convolution scheme:</p>
<ol class="arabic simple">
<li><p>the image is divided into squares of <span class="math notranslate nohighlight">\(2 \times 2\)</span> pixels;</p></li>
<li><p>each square is processed by the quantum circuit;</p></li>
<li><p>the <span class="math notranslate nohighlight">\(4\)</span> expectation values are mapped into <span class="math notranslate nohighlight">\(4\)</span> different
channels of a single output pixel.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This process halves the resolution of the input image. In the
standard language of CNN, this would correspond to a convolution
with a <span class="math notranslate nohighlight">\(2 \times 2\)</span> <em>kernel</em> and a <em>stride</em> equal to <span class="math notranslate nohighlight">\(2\)</span>.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quanv</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convolves the input image with many applications of the same quantum circuit.&quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="c1"># Loop over the coordinates of the top-left pixel of 2X2 squares</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
            <span class="c1"># Process a squared 2x2 region of the image with a quantum circuit</span>
            <span class="n">q_results</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">circuit</span></a><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                    <span class="n">image</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="c1"># Assign expectation values to different channels of the output pixel (j/2, k/2)</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
                <span class="n">out</span><span class="p">[</span><span class="n">j</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">k</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_results</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
<div class="section" id="quantum-pre-processing-of-the-dataset">
<h3>Quantum pre-processing of the dataset<a class="headerlink" href="#quantum-pre-processing-of-the-dataset" title="Permalink to this headline">¶</a></h3>
<p>Since we are not going to train the quantum convolution layer, it is more
efficient to apply it as a “pre-processing” layer to all the images of our dataset.
Later an entirely classical model will be directly trained and tested on the
pre-processed dataset, avoiding unnecessary repetitions of quantum computations.</p>
<p>The pre-processed images will be saved in the folder <code class="docutils literal notranslate"><span class="pre">SAVE_PATH</span></code>.
Once saved, they can be directly loaded by setting <code class="docutils literal notranslate"><span class="pre">PREPROCESS</span> <span class="pre">=</span> <span class="pre">False</span></code>,
otherwise the quantum convolution is evaluated at each run of the code.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">PREPROCESS</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Quantum pre-processing of train images:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">        &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_train</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span><span class="o">.</span><span class="n">append</span></a><span class="p">(</span><span class="n">quanv</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img</span></a><span class="p">))</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a><span class="p">)</span>

    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span></a> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Quantum pre-processing of test images:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img</span></a> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2">        &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_test</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span><span class="o">.</span><span class="n">append</span></a><span class="p">(</span><span class="n">quanv</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">img</span></a><span class="p">))</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span></a><span class="p">)</span>

    <span class="c1"># Save pre-processed images</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_train_images.npy&quot;</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_test_images.npy&quot;</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span></a><span class="p">)</span>


<span class="c1"># Load pre-processed images</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_train_images.npy&quot;</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">SAVE_PATH</span> <span class="o">+</span> <span class="s2">&quot;q_test_images.npy&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Quantum pre-processing of train images:
1/50
2/50
3/50
4/50
5/50
6/50
7/50
8/50
9/50
10/50
11/50
12/50
13/50
14/50
15/50
16/50
17/50
18/50
19/50
20/50
21/50
22/50
23/50
24/50
25/50
26/50
27/50
28/50
29/50
30/50
31/50
32/50
33/50
34/50
35/50
36/50
37/50
38/50
39/50
40/50
41/50
42/50
43/50
44/50
45/50
46/50
47/50
48/50
49/50
50/50
Quantum pre-processing of test images:
1/30
2/30
3/30
4/30
5/30
6/30
7/30
8/30
9/30
10/30
11/30
12/30
13/30
14/30
15/30
16/30
17/30
18/30
19/30
20/30
21/30
22/30
23/30
24/30
25/30
26/30
27/30
28/30
29/30
30/30
</pre></div>
</div>
<p>Let us visualize the effect of the quantum convolution
layer on a batch of samples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n_channels</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Input&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>

    <span class="c1"># Plot all output channels</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_channels</span><span class="p">):</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Output [ch. </span><span class="si">{}</span><span class="s2">]&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quanvolution_001.png" srcset="../_images/sphx_glr_tutorial_quanvolution_001.png" alt="tutorial quanvolution" class = "sphx-glr-single-img"/><p>Below each input image, the <span class="math notranslate nohighlight">\(4\)</span> output channels generated by the
quantum convolution are visualized in gray scale.</p>
<p>One can clearly notice the downsampling of the resolution and
some local distortion introduced by the quantum kernel.
On the other hand the global shape of the image is preserved,
as expected for a convolution layer.</p>
</div>
</div>
<div class="section" id="hybrid-quantum-classical-model">
<h2>Hybrid quantum-classical model<a class="headerlink" href="#hybrid-quantum-classical-model" title="Permalink to this headline">¶</a></h2>
<p>After the application of the quantum convolution layer we feed the resulting
features into a classical neural network that will be trained to classify
the <span class="math notranslate nohighlight">\(10\)</span> different digits of the MNIST dataset.</p>
<p>We use a very simple model: just a fully connected layer with
10 output nodes with a final <em>softmax</em> activation function.</p>
<p>The model is compiled with a <em>stochastic-gradient-descent</em> optimizer,
and a <em>cross-entropy</em> loss function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">MyModel</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes and returns a custom Keras model</span>
<span class="sd">    which is ready to be trained.&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>We first initialize an instance of the model, then we train and validate
it with the dataset that has been already pre-processed by a quantum convolution.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">q_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

<span class="n">q_history</span> <span class="o">=</span> <span class="n">q_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_train_images</span></a><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">q_test_images</span></a><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
13/13 - 0s - loss: 2.8250 - accuracy: 0.1400 - val_loss: 2.4170 - val_accuracy: 0.1333 - 463ms/epoch - 36ms/step
Epoch 2/30
13/13 - 0s - loss: 2.1073 - accuracy: 0.2200 - val_loss: 2.1754 - val_accuracy: 0.2333 - 30ms/epoch - 2ms/step
Epoch 3/30
13/13 - 0s - loss: 1.7399 - accuracy: 0.4400 - val_loss: 2.0416 - val_accuracy: 0.4000 - 29ms/epoch - 2ms/step
Epoch 4/30
13/13 - 0s - loss: 1.3471 - accuracy: 0.6000 - val_loss: 1.8371 - val_accuracy: 0.4000 - 44ms/epoch - 3ms/step
Epoch 5/30
13/13 - 0s - loss: 1.1440 - accuracy: 0.7600 - val_loss: 1.7137 - val_accuracy: 0.2667 - 46ms/epoch - 4ms/step
Epoch 6/30
13/13 - 0s - loss: 0.9736 - accuracy: 0.8400 - val_loss: 1.6647 - val_accuracy: 0.4667 - 29ms/epoch - 2ms/step
Epoch 7/30
13/13 - 0s - loss: 0.7637 - accuracy: 0.9200 - val_loss: 1.5564 - val_accuracy: 0.4333 - 29ms/epoch - 2ms/step
Epoch 8/30
13/13 - 0s - loss: 0.6176 - accuracy: 0.9600 - val_loss: 1.4829 - val_accuracy: 0.3667 - 29ms/epoch - 2ms/step
Epoch 9/30
13/13 - 0s - loss: 0.5348 - accuracy: 0.9800 - val_loss: 1.3995 - val_accuracy: 0.5000 - 44ms/epoch - 3ms/step
Epoch 10/30
13/13 - 0s - loss: 0.4435 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.4000 - 45ms/epoch - 3ms/step
Epoch 11/30
13/13 - 0s - loss: 0.3997 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.5333 - 44ms/epoch - 3ms/step
Epoch 12/30
13/13 - 0s - loss: 0.3624 - accuracy: 1.0000 - val_loss: 1.3952 - val_accuracy: 0.4667 - 29ms/epoch - 2ms/step
Epoch 13/30
13/13 - 0s - loss: 0.3116 - accuracy: 1.0000 - val_loss: 1.2872 - val_accuracy: 0.5333 - 43ms/epoch - 3ms/step
Epoch 14/30
13/13 - 0s - loss: 0.2958 - accuracy: 0.9800 - val_loss: 1.2182 - val_accuracy: 0.5333 - 43ms/epoch - 3ms/step
Epoch 15/30
13/13 - 0s - loss: 0.2445 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.5333 - 29ms/epoch - 2ms/step
Epoch 16/30
13/13 - 0s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.5333 - 29ms/epoch - 2ms/step
Epoch 17/30
13/13 - 0s - loss: 0.2002 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.5333 - 44ms/epoch - 3ms/step
Epoch 18/30
13/13 - 0s - loss: 0.1800 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.5000 - 44ms/epoch - 3ms/step
Epoch 19/30
13/13 - 0s - loss: 0.1634 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.5667 - 29ms/epoch - 2ms/step
Epoch 20/30
13/13 - 0s - loss: 0.1527 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.6000 - 29ms/epoch - 2ms/step
Epoch 21/30
13/13 - 0s - loss: 0.1386 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.5333 - 29ms/epoch - 2ms/step
Epoch 22/30
13/13 - 0s - loss: 0.1274 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.6000 - 44ms/epoch - 3ms/step
Epoch 23/30
13/13 - 0s - loss: 0.1202 - accuracy: 1.0000 - val_loss: 1.1159 - val_accuracy: 0.6333 - 29ms/epoch - 2ms/step
Epoch 24/30
13/13 - 0s - loss: 0.1120 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.5667 - 29ms/epoch - 2ms/step
Epoch 25/30
13/13 - 0s - loss: 0.1078 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.6000 - 44ms/epoch - 3ms/step
Epoch 26/30
13/13 - 0s - loss: 0.0968 - accuracy: 1.0000 - val_loss: 1.1195 - val_accuracy: 0.5667 - 30ms/epoch - 2ms/step
Epoch 27/30
13/13 - 0s - loss: 0.0917 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.6000 - 29ms/epoch - 2ms/step
Epoch 28/30
13/13 - 0s - loss: 0.0906 - accuracy: 1.0000 - val_loss: 1.0814 - val_accuracy: 0.5667 - 29ms/epoch - 2ms/step
Epoch 29/30
13/13 - 0s - loss: 0.0836 - accuracy: 1.0000 - val_loss: 1.1247 - val_accuracy: 0.5667 - 44ms/epoch - 3ms/step
Epoch 30/30
13/13 - 0s - loss: 0.0773 - accuracy: 1.0000 - val_loss: 1.0791 - val_accuracy: 0.6000 - 43ms/epoch - 3ms/step
</pre></div>
</div>
<p>In order to compare the results achievable with and without the quantum convolution layer,
we initialize also a “classical” instance of the model that will be directly trained
and validated with the raw MNIST images (i.e., without quantum pre-processing).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">c_model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">()</span>

<span class="n">c_history</span> <span class="o">=</span> <span class="n">c_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">train_images</span></a><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">test_images</span></a><span class="p">,</span> <span class="n">test_labels</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
13/13 - 0s - loss: 2.3920 - accuracy: 0.1000 - val_loss: 2.3593 - val_accuracy: 0.0333 - 328ms/epoch - 25ms/step
Epoch 2/30
13/13 - 0s - loss: 2.0247 - accuracy: 0.2600 - val_loss: 2.1961 - val_accuracy: 0.1000 - 45ms/epoch - 3ms/step
Epoch 3/30
13/13 - 0s - loss: 1.7295 - accuracy: 0.5200 - val_loss: 2.0452 - val_accuracy: 0.2000 - 29ms/epoch - 2ms/step
Epoch 4/30
13/13 - 0s - loss: 1.4920 - accuracy: 0.7400 - val_loss: 1.8979 - val_accuracy: 0.3000 - 46ms/epoch - 4ms/step
Epoch 5/30
13/13 - 0s - loss: 1.2813 - accuracy: 0.8800 - val_loss: 1.7643 - val_accuracy: 0.5000 - 44ms/epoch - 3ms/step
Epoch 6/30
13/13 - 0s - loss: 1.1111 - accuracy: 0.9000 - val_loss: 1.6653 - val_accuracy: 0.5000 - 45ms/epoch - 3ms/step
Epoch 7/30
13/13 - 0s - loss: 0.9656 - accuracy: 0.9200 - val_loss: 1.5896 - val_accuracy: 0.5667 - 45ms/epoch - 3ms/step
Epoch 8/30
13/13 - 0s - loss: 0.8459 - accuracy: 0.9400 - val_loss: 1.5169 - val_accuracy: 0.6333 - 45ms/epoch - 3ms/step
Epoch 9/30
13/13 - 0s - loss: 0.7474 - accuracy: 0.9400 - val_loss: 1.4564 - val_accuracy: 0.7000 - 44ms/epoch - 3ms/step
Epoch 10/30
13/13 - 0s - loss: 0.6632 - accuracy: 0.9600 - val_loss: 1.4129 - val_accuracy: 0.7000 - 29ms/epoch - 2ms/step
Epoch 11/30
13/13 - 0s - loss: 0.5979 - accuracy: 0.9600 - val_loss: 1.3647 - val_accuracy: 0.7000 - 29ms/epoch - 2ms/step
Epoch 12/30
13/13 - 0s - loss: 0.5373 - accuracy: 0.9600 - val_loss: 1.3518 - val_accuracy: 0.6667 - 29ms/epoch - 2ms/step
Epoch 13/30
13/13 - 0s - loss: 0.4858 - accuracy: 1.0000 - val_loss: 1.3173 - val_accuracy: 0.6333 - 29ms/epoch - 2ms/step
Epoch 14/30
13/13 - 0s - loss: 0.4388 - accuracy: 1.0000 - val_loss: 1.2759 - val_accuracy: 0.7000 - 30ms/epoch - 2ms/step
Epoch 15/30
13/13 - 0s - loss: 0.3981 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.7000 - 45ms/epoch - 3ms/step
Epoch 16/30
13/13 - 0s - loss: 0.3641 - accuracy: 1.0000 - val_loss: 1.2296 - val_accuracy: 0.7000 - 30ms/epoch - 2ms/step
Epoch 17/30
13/13 - 0s - loss: 0.3357 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.7000 - 45ms/epoch - 3ms/step
Epoch 18/30
13/13 - 0s - loss: 0.3090 - accuracy: 1.0000 - val_loss: 1.1904 - val_accuracy: 0.7000 - 45ms/epoch - 3ms/step
Epoch 19/30
13/13 - 0s - loss: 0.2836 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.6667 - 29ms/epoch - 2ms/step
Epoch 20/30
13/13 - 0s - loss: 0.2636 - accuracy: 1.0000 - val_loss: 1.1595 - val_accuracy: 0.6667 - 29ms/epoch - 2ms/step
Epoch 21/30
13/13 - 0s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.6667 - 29ms/epoch - 2ms/step
Epoch 22/30
13/13 - 0s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.6667 - 30ms/epoch - 2ms/step
Epoch 23/30
13/13 - 0s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.1327 - val_accuracy: 0.6667 - 30ms/epoch - 2ms/step
Epoch 24/30
13/13 - 0s - loss: 0.1980 - accuracy: 1.0000 - val_loss: 1.1228 - val_accuracy: 0.6333 - 45ms/epoch - 3ms/step
Epoch 25/30
13/13 - 0s - loss: 0.1868 - accuracy: 1.0000 - val_loss: 1.1165 - val_accuracy: 0.6667 - 44ms/epoch - 3ms/step
Epoch 26/30
13/13 - 0s - loss: 0.1743 - accuracy: 1.0000 - val_loss: 1.1081 - val_accuracy: 0.6667 - 44ms/epoch - 3ms/step
Epoch 27/30
13/13 - 0s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 1.0975 - val_accuracy: 0.6667 - 44ms/epoch - 3ms/step
Epoch 28/30
13/13 - 0s - loss: 0.1560 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.6667 - 29ms/epoch - 2ms/step
Epoch 29/30
13/13 - 0s - loss: 0.1468 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.6667 - 44ms/epoch - 3ms/step
Epoch 30/30
13/13 - 0s - loss: 0.1383 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.6667 - 45ms/epoch - 3ms/step
</pre></div>
</div>
</div>
<div class="section" id="results">
<h3>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h3>
<p>We can finally plot the test accuracy and the test loss with respect to the
number of training epochs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">],</span> <span class="s2">&quot;-ob&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;With quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_accuracy&quot;</span><span class="p">],</span> <span class="s2">&quot;-og&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Without quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">q_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="s2">&quot;-ob&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;With quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">c_history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="s2">&quot;-og&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Without quantum layer&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_quanvolution_002.png" srcset="../_images/sphx_glr_tutorial_quanvolution_002.png" alt="tutorial quanvolution" class = "sphx-glr-single-img"/></div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Maxwell Henderson, Samriddhi Shakya, Shashindra Pradhan, Tristan Cook.
“Quanvolutional Neural Networks: Powering Image Recognition with Quantum Circuits.”
<a class="reference external" href="https://arxiv.org/abs/1904.04767">arXiv:1904.04767</a>, 2019.</p></li>
</ol>
</div>
<div class="section" id="about-the-author">
<h2>About the author<a class="headerlink" href="#about-the-author" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/andrea_mari.jpeg" alt="Andrea Mari" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Andrea Mari</h4>
        <p class="bio-text__author-description">Andrea obtained a PhD in quantum information theory from the University of Potsdam (Germany). He worked as a postdoc at Scuola Normale Superiore (Pisa, Italy) and as a remote researcher at Xanadu. Since 2020 is a Member of Technical Staff at Unitary Fund.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  49.613 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-quanvolution-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/07f96da9d2a06a34225e43e45c520464/tutorial_quanvolution.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_quanvolution.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/dd55ba785f4e3c57b89e7002dbe54aad/tutorial_quanvolution.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_quanvolution.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_quanvolution</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Quanvolutional Neural Networks</a><ul class='current'>
<li class='current'><a class="reference internal" href="#introduction">Introduction</a><ul class='current'>
<li class='current'><a class="reference internal" href="#classical-convolution">Classical convolution</a></li>
<li class='current'><a class="reference internal" href="#quantum-convolution">Quantum convolution</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#general-setup">General setup</a><ul class='current'>
<li class='current'><a class="reference internal" href="#setting-of-the-main-hyper-parameters-of-the-model">Setting of the main hyper-parameters of the model</a></li>
<li class='current'><a class="reference internal" href="#loading-of-the-mnist-dataset">Loading of the MNIST dataset</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#quantum-circuit-as-a-convolution-kernel">Quantum circuit as a convolution kernel</a><ul class='current'>
<li class='current'><a class="reference internal" href="#quantum-pre-processing-of-the-dataset">Quantum pre-processing of the dataset</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#hybrid-quantum-classical-model">Hybrid quantum-classical model</a><ul class='current'>
<li class='current'><a class="reference internal" href="#training">Training</a></li>
<li class='current'><a class="reference internal" href="#results">Results</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-author">About the author</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_quanvolution</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_qml.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="ensemble_multi_qpu.html" title="Ensemble classification with Rigetti and Qiskit devices"
             >next</a> |</li>
        <li class="right" >
          <a href="learning2learn.html" title="Learning to learn with quantum neural networks"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_qml.html" >Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quanvolutional Neural Networks</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>