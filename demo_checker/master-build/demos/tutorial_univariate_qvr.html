
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Learn how to quantumly detect anomalous behaviour in time series data with the help of Covalent." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/thumbnail_tutorial_univariate_qvr.jpg" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Quantum detection of time series anomalies &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_univariate_qvr.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Learn how to quantumly detect anomalous behaviour in time series data with the help of Covalent." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Quantum detection of time series anomalies &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_univariate_qvr.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Contextuality and inductive bias in QML" href="tutorial_contextuality.html" />
    <link rel="prev" title="Introduction to Geometric Quantum Machine Learning" href="tutorial_geometric_qml.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_contextuality.html" title="Contextuality and inductive bias in QML"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_geometric_qml.html" title="Introduction to Geometric Quantum Machine Learning"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_qml.html" accesskey="U">Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum detection of time series anomalies</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-demos-tutorial-univariate-qvr-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="quantum-detection-of-time-series-anomalies">
<span id="sphx-glr-demos-tutorial-univariate-qvr-py"></span><h1>Quantum detection of time series anomalies<a class="headerlink" href="#quantum-detection-of-time-series-anomalies" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_qaoa_intro.html"];
    var related_tutorials_titles = ['Intro to QAOA'];
</script></p>
<p><em>Authors: Jack Stephen Baker, Santosh Kumar Radha — Posted: 7 February 2023.</em></p>
<p>Systems producing observable characteristics which evolve with time are
almost everywhere we look. The temperature changes as day turns to night,
stock markets fluctuate and the bacteria colony living in the coffee cup to your
right, which you <em>promised</em> you would clean yesterday, is slowly growing
(seriously, clean it). In many situations, it is important to know when these
systems start behaving abnormally. For example, if the pressure
inside a nuclear fission reactor starts violently fluctuating, you may wish
to be alerted of that. The task of identifying such temporally abnormal
behaviour is known as time series anomaly detection and is well known in machine
learning circles.</p>
<p>In this tutorial, we take a stab at time series anomaly detection using the <em>Quantum Variational
Rewinding</em> algorithm, or QVR, proposed by <a class="reference external" href="https://arxiv.org/abs/2210.16438">Baker, Horowitz, Radha et.
al (2022)</a> <a class="footnote-reference brackets" href="#baker2022" id="id1">1</a> — a quantum machine learning algorithm for gate model quantum computers. QVR leverages the power of unitary time evolution/devolution operators to
learn a model of <em>normal</em> behaviour for time series data. Given a new (i.e., unseen in training) time
series, the normal model produces a value that, beyond a threshold,
defines anomalous behaviour. In this tutorial, we’ll be showing you how
all of this works, combining elements from
<a class="reference external" href="https://www.covalent.xyz/">Covalent</a>,
<a class="reference external" href="https://pennylane.ai/">Pennylane</a> and
<a class="reference external" href="https://pytorch.org/">PyTorch</a>.</p>
<p>Before getting into the technical details of the algorithm, let’s get a high-level overview with the help of the cartoon below.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/cartoon_pennylane.png"><img alt="QVR cartoon" src="../_images/cartoon_pennylane.png" style="width: 70%;" /></a>
</div>
<p>Going left-to-right, a time series is sampled at three points in time, corresponding to
different stages in the life cycle of a butterfly: a catepillar, a chrysalis and a butterfly.
This information is then encoded into quantum states and passed to a
time machine which time devolves the states as generated by a learnt
Hamiltonian operator (in practice, there is a distribution of such operators).
After the devolved state is measured, the time series is recognized as
normal if the average measurement is smaller than a given threshold and anomalous if the
threshold is exceeded. In the first case, the time series is considered
rewindable, correctly recovering the initial condition for the life cycle
of a butterfly: eggs on a leaf. In the second case, the output is unrecognizable.</p>
<p>This will all make more sense once we delve into the math a little. Let’s do it!</p>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>To begin, let’s quickly recount the data that QVR handles: time series.
A general time series <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> can be described as a sequence of
<span class="math notranslate nohighlight">\(p\)</span>-many observations of a process/system arranged in
chronological order, where <span class="math notranslate nohighlight">\(p\)</span> is a positive integer:</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{y} := (\boldsymbol{y}_t: t \in T), \quad T := (t_l: l \in \mathbb{Z}^{+}_{\leq p}).\]</div>
<p>In the simple and didactic case treated in this tutorial, <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> is univariate (i.e, is a
one-dimensional time series), so bold-face for <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> is
dropped from this point onwards. Also, we take <span class="math notranslate nohighlight">\(y_t \in \mathbb{R}\)</span> and
<span class="math notranslate nohighlight">\(t_l \in \mathbb{R}_{&gt;0}\)</span>.</p>
<p>The goal of QVR and many other (classical) machine learning algorithms
for time series anomaly detection is to determine a suitable <em>anomaly
score</em> function <span class="math notranslate nohighlight">\(a_{X}\)</span>, where <span class="math notranslate nohighlight">\(X\)</span> is a training dataset of
<em>normal</em> time series instances <span class="math notranslate nohighlight">\(x \in X\)</span> (<span class="math notranslate nohighlight">\(x\)</span> is defined
analogously to <span class="math notranslate nohighlight">\(y\)</span> in the above), from which the anomaly score function
was learnt. When passed a general time series
<span class="math notranslate nohighlight">\(y\)</span>, this function produces a real number:
<span class="math notranslate nohighlight">\(a_X(y) \in \mathbb{R}\)</span>. The goal is to have
<span class="math notranslate nohighlight">\(a_X(x) \approx 0\)</span>, for all <span class="math notranslate nohighlight">\(x \in X\)</span>. Then, for an unseen time
series <span class="math notranslate nohighlight">\(y\)</span> and a threshold <span class="math notranslate nohighlight">\(\zeta \in \mathbb{R}\)</span>, the series is said to be anomalous should
<span class="math notranslate nohighlight">\(a_X(y) &gt; \zeta,\)</span> and normal otherwise. We show a strategy for setting
<span class="math notranslate nohighlight">\(\zeta\)</span> later in this tutorial.</p>
<p>The first step for doing all of this <em>quantumly</em> is to generate a
sequence <span class="math notranslate nohighlight">\(\mathcal{S} := (|x_{t} \rangle: t \in T)\)</span> of
<span class="math notranslate nohighlight">\(n\)</span>-qubit quantum states corresponding to a classical time series
instance in the training set. Now, we suppose that each
<span class="math notranslate nohighlight">\(|x_t \rangle\)</span> is a quantum state evolved to a time <span class="math notranslate nohighlight">\(t\)</span>, as
generated by an <em>unknown embedding Hamiltonian</em> <span class="math notranslate nohighlight">\(H_E\)</span>. That is,
each element of <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is defined by
<span class="math notranslate nohighlight">\(|x_t \rangle = e^{-iH_E(x_t)}|0\rangle^{\otimes n} = U(x_t)|0\rangle^{\otimes n}\)</span>
for an embedding unitary operator <span class="math notranslate nohighlight">\(U(x_t)\)</span> implementing a quantum
feature map (see the <a class="reference external" href="https://docs.pennylane.ai/en/stable/introduction/templates.html#embedding-templates">Pennylane embedding
templates</a>
for efficient quantum circuits for doing so). Next, we operate on each
<span class="math notranslate nohighlight">\(|x_t\rangle\)</span> with a parameterized
<span class="math notranslate nohighlight">\(e^{-iH(\boldsymbol{\alpha}, \boldsymbol{\gamma})t}\)</span> operator to
prepare the states</p>
<div class="math notranslate nohighlight">
\[|x_t, \boldsymbol{\alpha}, \boldsymbol{\gamma}\rangle := e^{-iH(\boldsymbol{\alpha}, \boldsymbol{\gamma})t}|x_t\rangle,\]</div>
<p>where we write
<span class="math notranslate nohighlight">\(e^{-iH(\boldsymbol{\alpha}, \boldsymbol{\gamma})t}\)</span> as an
eigendecomposition</p>
<div class="math notranslate nohighlight">
\[V_t(\boldsymbol{\alpha}, \boldsymbol{\gamma}) := W^{\dagger}(\boldsymbol{\alpha})D(\boldsymbol{\gamma}, t)W(\boldsymbol{\alpha}) = e^{-iH(\boldsymbol{\alpha}, \boldsymbol{\gamma})t}.\]</div>
<p>Here, the unitary matrix of eigenvectors <span class="math notranslate nohighlight">\(W(\boldsymbol{\alpha})\)</span>  is parametrized by <span class="math notranslate nohighlight">\(\boldsymbol{\alpha}\)</span> and the unitary diagonalization <span class="math notranslate nohighlight">\(D(\boldsymbol{\gamma}, t)\)</span>
is parametrized by <span class="math notranslate nohighlight">\(\boldsymbol{\gamma}.\)</span>
Both can be implemented
efficiently using parameterized quantum circuits. The above equality
with <span class="math notranslate nohighlight">\(e^{-iH(\boldsymbol{\alpha}, \boldsymbol{\gamma})t}\)</span> is a
consequence of Stone’s theorem for strongly continuous one-parameter
unitary groups <a class="footnote-reference brackets" href="#stone1932" id="id2">2</a>.</p>
<p>We now ask the question: <em>What condition is required for</em>
<span class="math notranslate nohighlight">\(|x_t, \boldsymbol{\alpha}, \boldsymbol{\gamma} \rangle = |0 \rangle^{\otimes n}\)</span> <em>for all time?</em>
To answer this, we impose
<span class="math notranslate nohighlight">\(P(|0\rangle^{\otimes n}) = |\langle 0|^{\otimes n}|x_t, \boldsymbol{\alpha}, \boldsymbol{\gamma} \rangle|^2 = 1.\)</span>
Playing with the algebra a little, we find that the following condition must be satisfied for all <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[\langle 0|^{\otimes n}e^{-iH(\boldsymbol{\alpha}, \boldsymbol{\gamma})t}e^{-iH_E(x_t)}|0\rangle^{\otimes n} = 1 \iff  H(\boldsymbol{\alpha}, \boldsymbol{\gamma})t = -H_E(x_t).\]</div>
<p>In other words, for the above to be true, the parameterized unitary
operator <span class="math notranslate nohighlight">\(V_t(\boldsymbol{\alpha}, \boldsymbol{\gamma})\)</span> should be
able to reverse or <em>rewind</em> <span class="math notranslate nohighlight">\(|x_t\rangle\)</span> to its initial
state <span class="math notranslate nohighlight">\(|0\rangle^{\otimes n}\)</span> before the embedding unitary operator <span class="math notranslate nohighlight">\(U(x_t)\)</span> was
applied.</p>
<p>We are nearly there! Because it is reasonable to expect that a single
Hamiltonian will not be able to successfully rewind every
<span class="math notranslate nohighlight">\(x \in X\)</span> (in fact, this is impossible to do if each
<span class="math notranslate nohighlight">\(x\)</span> is unique, which is usually true), we consider the average effect of many
Hamiltonians generated by drawing <span class="math notranslate nohighlight">\(\boldsymbol{\gamma}\)</span> from a
normal distribution <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma)\)</span> with mean <span class="math notranslate nohighlight">\(\mu\)</span> and
standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>:</p>
<div class="math notranslate nohighlight">
\[F(\boldsymbol{\phi}, x_t) := \mathop{\mathbb{E}_{\boldsymbol{\gamma} \sim \mathcal{N}(\mu, \sigma)}}\left[\langle 0|^{\otimes n} |x_t, \boldsymbol{\alpha}, \boldsymbol{\gamma}\rangle  \right], \quad \boldsymbol{\phi} = [\boldsymbol{\alpha}, \mu, \sigma].\]</div>
<p>The goal is for the function <span class="math notranslate nohighlight">\(F\)</span> defined above to be as close to <span class="math notranslate nohighlight">\(1\)</span> as possible,
for all <span class="math notranslate nohighlight">\(x \in X\)</span> and <span class="math notranslate nohighlight">\(t \in T.\)</span> With this in mind, we can
define the loss function to minimize as the mean square error
regularized by a penalty function <span class="math notranslate nohighlight">\(P_{\tau}(\sigma)\)</span> with a single
hyperparameter <span class="math notranslate nohighlight">\(\tau\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L(\boldsymbol{\phi})} = \frac{1}{2|X||T|}\sum_{x \in X} \sum_{t \in T}[1 - F(\boldsymbol{\phi}, x_t)]^2 + P_{\tau}(\sigma).\]</div>
<p>We will show the exact form of <span class="math notranslate nohighlight">\(P_{\tau}(\sigma)\)</span> later.
The general purpose of the penalty function is to penalize
large values of <span class="math notranslate nohighlight">\(\sigma\)</span> (justification for this is given in the
Supplement of <a class="footnote-reference brackets" href="#baker2022" id="id3">1</a>). After approximately finding the argument <span class="math notranslate nohighlight">\(\boldsymbol{\phi}^{\star}\)</span>
that minimizes the loss function
(found using a classical optimization routine), we finally arrive at a definition
for our anomaly score function <span class="math notranslate nohighlight">\(a_X(y)\)</span></p>
<div class="math notranslate nohighlight">
\[a_X(y) = \frac{1}{|T|}\sum_{t \in T}[1 - F(\boldsymbol{\phi}^{\star}, y_t)]^2.\]</div>
<p>It may now be apparent that we have implemented a clustering algorithm!
That is, our model <span class="math notranslate nohighlight">\(F\)</span> was trained such that normal time series
<span class="math notranslate nohighlight">\(x \in X\)</span> produce <span class="math notranslate nohighlight">\(F(\boldsymbol{\phi}^{\star}, x_t)\)</span>
clustered about a center at <span class="math notranslate nohighlight">\(1\)</span>. Given a new time series
<span class="math notranslate nohighlight">\(y\)</span>, should <span class="math notranslate nohighlight">\(F(\boldsymbol{\phi}^{\star}, y_t)\)</span> venture far
from the normal center at <span class="math notranslate nohighlight">\(1\)</span>, we are observing anomalous behaviour!</p>
<p>Take the time now to have another look at the cartoon at the start of this tutorial.
Hopefully things should start making sense now.</p>
<p>Now with our algorithm defined, let’s stitch this all together: enter
<a class="reference external" href="https://www.covalent.xyz/">Covalent</a>.</p>
</div>
<div class="section" id="covalent-heterogeneous-workflow-orchestration">
<h2>Covalent: heterogeneous workflow orchestration<a class="headerlink" href="#covalent-heterogeneous-workflow-orchestration" title="Permalink to this headline">¶</a></h2>
<p>Presently, many QML algorithms are <em>heterogeneous</em> in nature. This means that
they require computational resources from both classical and quantum computing.
Covalent is a tool that can be used
to manage their interaction by sending different tasks to different
computational resources and stitching them together as a workflow. While you
will be introduced to other concepts in Covalent throughout this
tutorial, we define two key components to begin with.</p>
<ol class="arabic">
<li><p><strong>Electrons</strong>. Decorate regular Python functions with
<code class="docutils literal notranslate"><span class="pre">&#64;ct.electron</span></code> to desginate a <em>task</em>. These are the atoms of
a computation.</p></li>
<li><p><strong>Lattices</strong>. Decorate a regular Python function with <code class="docutils literal notranslate"><span class="pre">&#64;ct.lattice</span></code>
to designate a <em>workflow</em>. These contain electrons stitched together to do something useful.</p>
<p>Different electrons can be run remotely on
different hardware and multiple computational paridigms (classical, quantum, etc.: see the <a class="reference external" href="https://covalent.readthedocs.io/en/stable/plugins.html">Covalent executors</a>).
In this tutorial, however, to keep things simple, tasks are run on a local
Dask cluster, which provides (among other things) auto-parallelization.</p>
</li>
</ol>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/covalent_platform.png"><img alt="The Covalent platform" src="../_images/covalent_platform.png" style="width: 70%;" /></a>
</div>
<p>Now is a good time to import Covalent and launch the Covalent server!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">covalent</span> <span class="k">as</span> <span class="nn">ct</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Set up Covalent server</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;COVALENT_SERVER_IFACE_ANY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">&quot;covalent start&quot;</span><span class="p">)</span>
<span class="c1"># If you run into any out-of-memory issues with Dask when running this notebook,</span>
<span class="c1"># Try reducing the number of workers and making a specific memory request. I.e.:</span>
<span class="c1"># os.system(&quot;covalent start -m &quot;2GiB&quot; -n 2&quot;)</span>
<span class="c1"># try covalent –help for more info</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># give the Dask cluster some time to launch</span>
</pre></div>
</div>
</div>
<div class="section" id="generating-univariate-synthetic-time-series">
<h2>Generating univariate synthetic time series<a class="headerlink" href="#generating-univariate-synthetic-time-series" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we shall deal with a simple and didactic example.
Normal time series instances are chosen to be noisy low-amplitude
signals normally distributed about the origin. In our case, <span class="math notranslate nohighlight">\(x_t \sim \mathcal{N}(0, 0.1)\)</span>.
Series we deem to be anomalous are the same but with randomly inserted
spikes with random durations and amplitudes.</p>
<p>Let’s make a <code class="docutils literal notranslate"><span class="pre">&#64;ct.electron</span></code> to generate each of these synthetic time
series sets. For this, we’ll need to import Torch. We’ll also
set the default tensor type and pick a random seed for the whole tutorial
for reproducibility.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Seed Torch for reproducibility and set default tensor type</span>
<span class="n">GLOBAL_SEED</span> <span class="o">=</span> <span class="mi">1989</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">GLOBAL_SEED</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_default_tensor_type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">)</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">generate_normal_time_series_set</span><span class="p">(</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_series</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">t_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">t_end</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">GLOBAL_SEED</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate a normal time series data set where each of the p elements</span>
<span class="sd">    is drawn from a normal distribution x_t ~ N(0, noise_amp).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="p">(</span><span class="n">num_series</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">T</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">generate_anomalous_time_series_set</span><span class="p">(</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_series</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">noise_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">spike_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_duration</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">t_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">t_end</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">GLOBAL_SEED</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate an anomalous time series data set where the p elements of each sequence are</span>
<span class="sd">    from a normal distribution x_t ~ N(0, noise_amp). Then,</span>
<span class="sd">    anomalous spikes of random amplitudes and durations are inserted.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="p">(</span><span class="n">num_series</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">:</span>
        <span class="c1"># 5–10 spikes allowed</span>
        <span class="n">spike_num</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">())</span>
        <span class="n">durations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">max_duration</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">spike_num</span><span class="p">,))</span>
        <span class="n">spike_start_idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">p</span> <span class="o">-</span> <span class="n">max_duration</span><span class="p">)[:</span><span class="n">spike_num</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">start_idx</span><span class="p">,</span> <span class="n">duration</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">spike_start_idxs</span><span class="p">,</span> <span class="n">durations</span><span class="p">):</span>
            <span class="n">y</span><span class="p">[</span><span class="n">start_idx</span> <span class="p">:</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">duration</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">spike_amp</span><span class="p">,</span> <span class="p">(</span><span class="n">duration</span><span class="p">,))</span>
    <span class="n">T</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Y</span><span class="p">,</span> <span class="n">T</span>
</pre></div>
</div>
<p>Let’s do a quick sanity check and plot a couple of these series. Despite the
above function’s <code class="docutils literal notranslate"><span class="pre">&#64;ct.electron</span></code> decorators, these can still be used as normal
Python functions without using the Covalent server. This is useful
for quick checks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">X_norm</span><span class="p">,</span> <span class="n">T_norm</span> <span class="o">=</span> <span class="n">generate_normal_time_series_set</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
<span class="n">Y_anom</span><span class="p">,</span> <span class="n">T_anom</span> <span class="o">=</span> <span class="n">generate_anomalous_time_series_set</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">T_norm</span><span class="p">,</span> <span class="n">X_norm</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Normal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">T_anom</span><span class="p">,</span> <span class="n">Y_anom</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Anomalous&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$y(t)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;t&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">leg</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_univariate_qvr_001.png" srcset="../_images/sphx_glr_tutorial_univariate_qvr_001.png" alt="tutorial univariate qvr" class = "sphx-glr-single-img"/><p>Taking a look at the above, the generated series are what we wanted. We have
a simple human-parsable notion of what it is for a time series to be anomalous
(big spikes). Of course, we don’t need a complicated algorithm to be able to detect
such anomalies but this is just a didactic example remember!</p>
<p>Like many machine learning algorithms, training is done in mini-batches.
Examining the form of the loss function
<span class="math notranslate nohighlight">\(\mathcal{L}(\boldsymbol{\phi})\)</span>, we can see that time series are
atomized. In other words, each term in the mean square error is for a given
<span class="math notranslate nohighlight">\(x_t\)</span> and not measured against the entire series <span class="math notranslate nohighlight">\(x\)</span>. This
allows us to break down the training set <span class="math notranslate nohighlight">\(X\)</span> into
time-series-independent chunks. Here’s an electron to do that:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">make_atomized_training_set</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert input time series data provided in a two-dimensional tensor format</span>
<span class="sd">    to atomized tuple chunks: (xt, t).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X_flat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">T_flat</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">atomized</span> <span class="o">=</span> <span class="p">[(</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">xt</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X_flat</span><span class="p">,</span> <span class="n">T_flat</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">atomized</span>
</pre></div>
</div>
<p>We now wish to pass this to a cycled <code class="docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code>.
However, this object is not
<a class="reference external" href="https://docs.python.org/3/library/pickle.html#:~:text=%E2%80%9CPickling%E2%80%9D%20is%20the%20process%20whereby,back%20into%20an%20object%20hierarchy.">pickleable</a>,
which is a requirement of electrons in Covalent. We therefore use the
below helper class to create a pickleable version.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterator</span>


<span class="k">class</span> <span class="nc">DataGetter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A pickleable mock-up of a Python iterator on a torch.utils.Dataloader.</span>
<span class="sd">    Provide a dataset X and the resulting object O will allow you to use next(O).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">GLOBAL_SEED</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calls the _init_data method on intialization of a DataGetter object.&quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_data</span><span class="p">(</span>
            <span class="nb">iter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">:</span> <span class="n">Iterator</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load all of the iterator into a list.&quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Analogous behaviour to the native Python next() but calling the</span>
<span class="sd">        .pop() of the data attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>  <span class="c1"># Caught when the data set runs out of elements</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_data</span><span class="p">(</span>
                <span class="nb">iter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
</pre></div>
</div>
<p>We call an instance of the above in an electron</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_training_cycler</span><span class="p">(</span><span class="n">Xtr</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">GLOBAL_SEED</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataGetter</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get an instance of the DataGetter class defined above, which behaves analogously to</span>
<span class="sd">    next(iterator) but is pickleable.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DataGetter</span><span class="p">(</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
<p>We now have the means to create synthetic data and cycle through a
training set. Next, we need to build our loss function
<span class="math notranslate nohighlight">\(\mathcal{L}(\boldsymbol{\phi})\)</span> from electrons with the help of
<code class="docutils literal notranslate"><span class="pre">PennyLane</span></code>.</p>
</div>
<div class="section" id="building-the-loss-function">
<h2>Building the loss function<a class="headerlink" href="#building-the-loss-function" title="Permalink to this headline">¶</a></h2>
<p>Core to building the loss function is the quantum circuit implementing
<span class="math notranslate nohighlight">\(V_t(\boldsymbol{\alpha}, \boldsymbol{\gamma}) := W^{\dagger}(\boldsymbol{\alpha})D(\boldsymbol{\gamma}, t)W(\boldsymbol{\alpha})\)</span>.
While there are existing templates in <code class="docutils literal notranslate"><span class="pre">PennyLane</span></code> for implementing
<span class="math notranslate nohighlight">\(W(\boldsymbol{\alpha})\)</span>, we use a custom circuit to implement
<span class="math notranslate nohighlight">\(D(\boldsymbol{\gamma}, t)\)</span>. Following the approach taken in
<a class="footnote-reference brackets" href="#welch2014" id="id4">3</a> (also explained in <a class="footnote-reference brackets" href="#baker2022" id="id5">1</a> and the
appendix of <a class="footnote-reference brackets" href="#cirstoiu2020" id="id6">4</a>), we create the electron:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">D</span><span class="p">(</span><span class="n">gamma</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">get_probs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates an n_qubit quantum circuit according to a k-local Walsh operator</span>
<span class="sd">    expansion. Here, k-local means that 1 &lt;= k &lt;= n of the n qubits can interact.</span>
<span class="sd">    See &lt;https://doi.org/10.1088/1367-2630/16/3/033040&gt; for more</span>
<span class="sd">    details. Optionally return probabilities of bit strings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">n_qubits</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">comb</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">),</span> <span class="n">i</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">comb</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RZ.html#pennylane.RZ" title="pennylane.RZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RZ</span></a><span class="p">(</span><span class="n">gamma</span><span class="p">[</span><span class="n">cnt</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">comb</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
                <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">comb</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">cnots</span> <span class="o">=</span> <span class="p">[</span><span class="n">comb</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">comb</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">cnots</span><span class="p">:</span>
                    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">j</span><span class="p">)</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RZ.html#pennylane.RZ" title="pennylane.RZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RZ</span></a><span class="p">(</span><span class="n">gamma</span><span class="p">[</span><span class="n">cnt</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">comb</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
                <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">cnots</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">j</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">get_probs</span><span class="p">:</span>
        <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.probs.html#pennylane.probs" title="pennylane.probs" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">probs</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">))</span>
</pre></div>
</div>
<p>While the above may seem a little complicated, since we only use a single
qubit in this tutorial, the resulting circuit is merely a single <span class="math notranslate nohighlight">\(R_z(\theta)\)</span> gate.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_qubits</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dev</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">n_qubits</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">D_one_qubit</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.qnode.html#pennylane.qnode" title="pennylane.qnode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">qnode</span></a><span class="p">(</span><span class="n">dev</span><span class="p">)(</span><span class="n">D</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.draw_mpl.html#pennylane.draw_mpl" title="pennylane.draw_mpl" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">draw_mpl</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">D_one_qubit</span></a><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_univariate_qvr_002.png" srcset="../_images/sphx_glr_tutorial_univariate_qvr_002.png" alt="tutorial univariate qvr" class = "sphx-glr-single-img"/><p>You may find the general function for <span class="math notranslate nohighlight">\(D\)</span> useful in case you want to experiment
with more qubits and your own (possibly multi-dimensional) data after
this tutorial.</p>
<p>Next, we define a circuit to calculate the probability of certain bit strings being measured in the
computational basis. In our simple example, we work only with one qubit
and use the <code class="docutils literal notranslate"><span class="pre">default.qubit</span></code> local quantum circuit simulator.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">diff_method</span><span class="o">=</span><span class="s2">&quot;backprop&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_probs</span><span class="p">(</span>
    <span class="n">xt</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">gamma</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">U</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">D</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Measure the probabilities for measuring each bitstring after applying a</span>
<span class="sd">    circuit of the form W†DWU to the |0⟩^(⊗n) state. This</span>
<span class="sd">    function is defined for individual sequence elements xt.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">U</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">))</span>
    <span class="n">W</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">))</span>
    <span class="n">D</span><span class="p">(</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">t</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.adjoint.html#pennylane.adjoint" title="pennylane.adjoint" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">adjoint</span></a><span class="p">(</span><span class="n">W</span><span class="p">)(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">))</span>
    <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.probs.html#pennylane.probs" title="pennylane.probs" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">probs</span></a><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">))</span>
</pre></div>
</div>
<p>To take the projector
<span class="math notranslate nohighlight">\(|0\rangle^{\otimes n} \langle 0 |^{\otimes n}\)</span>, we consider only
the probability of measuring the bit string of all zeroes, which is the
0th element of the probabilities (bit strings are returned in
lexicographic order).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_callable_projector_func</span><span class="p">(</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">U</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span> <span class="n">W</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span> <span class="n">D</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">probs_func</span><span class="p">:</span> <span class="nb">callable</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">callable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Using get_probs() above, take only the probability of measuring the</span>
<span class="sd">    bitstring of all zeroes (i.e, take the projector</span>
<span class="sd">    |0⟩^(⊗n)⟨0|^(⊗n)) on the time devolved state.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">callable_proj</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">:</span> <span class="n">probs_func</span><span class="p">(</span>
        <span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">n_qubits</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">callable_proj</span>
</pre></div>
</div>
<p>We now have the necessary ingredients to build
<span class="math notranslate nohighlight">\(F(\boldsymbol{\phi}, x_t)\)</span>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">F</span><span class="p">(</span>
    <span class="n">callable_proj</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">xt</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Take the classical expecation value of of the projector on zero sampling</span>
<span class="sd">    the parameters of D from normal distributions. The expecation value is estimated</span>
<span class="sd">    with an average over n_samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># length of gamma should not exceed 2^n - 1</span>
    <span class="n">gammas</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">))</span> <span class="o">+</span> <span class="n">mu</span>
    <span class="n">expectation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">gammas</span><span class="p">):</span>
        <span class="n">expectation</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">callable_proj</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expectation</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<p>We now return to the matter of the penalty function <span class="math notranslate nohighlight">\(P_{\tau}\)</span>.
We choose</p>
<div class="math notranslate nohighlight">
\[P_{\tau}(\sigma) := \frac{1}{\pi} \arctan(2 \pi \tau |\sigma|).\]</div>
<p>As an electron, we have</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">callable_arctan_penalty</span><span class="p">(</span><span class="n">tau</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">callable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a callable arctan function with a single hyperparameter</span>
<span class="sd">    tau to penalize large entries of sigma.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prefac</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">callable_pen</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">sigma</span><span class="p">:</span> <span class="n">prefac</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arctan</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">callable_pen</span>
</pre></div>
</div>
<p>The above is a sigmoidal function chosen because it comes with the useful property of being bounded.
The prefactor of <span class="math notranslate nohighlight">\(1/\pi\)</span> is chosen such that the final loss
<span class="math notranslate nohighlight">\(\mathcal{L}(\boldsymbol{\phi})\)</span> is defined in the range (0, 1),
as defined in the below electron.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_loss</span><span class="p">(</span>
    <span class="n">callable_proj</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">alpha</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">sigma</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">callable_penalty</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate the loss function ℒ, defined in the background section</span>
<span class="sd">    for a certain set of parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X_batch</span><span class="p">,</span> <span class="n">T_batch</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">X_batch</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_batch</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># unsqueeze required for tensor to have the correct dimension for PennyLane templates</span>
        <span class="n">loss</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span>
            <span class="o">-</span> <span class="n">F</span><span class="p">(</span>
                <span class="n">callable_proj</span><span class="p">,</span>
                <span class="n">X_batch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">T_batch</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">alpha</span><span class="p">,</span>
                <span class="n">mu</span><span class="p">,</span>
                <span class="n">sigma</span><span class="p">,</span>
                <span class="n">gamma_length</span><span class="p">,</span>
                <span class="n">n_samples</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">square</span><span class="p">()</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">callable_penalty</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="training-the-normal-model">
<h2>Training the normal model<a class="headerlink" href="#training-the-normal-model" title="Permalink to this headline">¶</a></h2>
<p>Now equipped with a loss function, we need to minimize it with a
classical optimization routine. To start this optimization, however, we
need some initial parameters. We can generate them with the below
electron.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_initial_parameters</span><span class="p">(</span>
    <span class="n">W</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span> <span class="n">W_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">GLOBAL_SEED</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Randomly generate initial parameters. We need initial parameters for the</span>
<span class="sd">    variational circuit ansatz implementing W(alpha) and the standard deviation</span>
<span class="sd">    and mean (sigma and mu) for the normal distribution we sample gamma from.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">init_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">W_layers</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">))</span>
    <span class="n">init_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Best to start sigma small and expand if needed</span>
    <span class="n">init_sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">init_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">init_alpha</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
        <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">init_mu</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
        <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">init_sigma</span> <span class="o">+</span> <span class="mf">0.05</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">init_params</span>
</pre></div>
</div>
<p>Using the <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> interface to <code class="docutils literal notranslate"><span class="pre">PennyLane</span></code>, we define our final
electron before running the training workflow.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">train_model_gradients</span><span class="p">(</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">init_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">pytorch_optimizer</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">cycler</span><span class="p">:</span> <span class="n">DataGetter</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">callable_penalty</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">batch_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">callable_proj</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">GLOBAL_SEED</span><span class="p">,</span>
    <span class="n">print_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the QVR model (minimize the loss function) with respect to the</span>
<span class="sd">    variational parameters using gradient-based training. You need to pass a</span>
<span class="sd">    PyTorch optimizer and a learning rate (lr).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">pytorch_optimizer</span><span class="p">(</span><span class="n">init_params</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">init_params</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">get_loss</span><span class="p">(</span>
            <span class="n">callable_proj</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">cycler</span><span class="p">),</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">callable_penalty</span>
        <span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_iterations</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>
        <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">batch_iterations</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">print_intermediate</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration number </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="se">\n</span><span class="s2"> Current loss </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">results_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;opt_params&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
            <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s2">&quot;sigma&quot;</span><span class="p">:</span> <span class="n">opt</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
        <span class="p">},</span>
        <span class="s2">&quot;loss_history&quot;</span><span class="p">:</span> <span class="n">loss_history</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">results_dict</span>
</pre></div>
</div>
<p>Now, enter our first <code class="docutils literal notranslate"><span class="pre">&#64;ct.lattice</span></code>. This combines the above electrons,
eventually returning the optimal parameters
<span class="math notranslate nohighlight">\(\boldsymbol{\phi}^{\star}\)</span> and the loss with batch iterations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">lattice</span>
<span class="k">def</span> <span class="nf">training_workflow</span><span class="p">(</span>
    <span class="n">U</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">D</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">probs_func</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">W_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_series</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">noise_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">t_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">t_end</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">pytorch_optimizer</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">batch_iterations</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Combine all of the previously defined electrons to do an entire training workflow,</span>
<span class="sd">    including (1) generating synthetic data, (2) packaging it into training cyclers</span>
<span class="sd">    (3) preparing the quantum functions and (4) optimizing the loss function with</span>
<span class="sd">    gradient based optimization. You can find definitions for all of the arguments</span>
<span class="sd">    by looking at the electrons and text cells above.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">generate_normal_time_series_set</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">num_series</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span><span class="p">)</span>
    <span class="n">Xtr</span> <span class="o">=</span> <span class="n">make_atomized_training_set</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
    <span class="n">cycler</span> <span class="o">=</span> <span class="n">get_training_cycler</span><span class="p">(</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">init_params</span> <span class="o">=</span> <span class="n">get_initial_parameters</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_layers</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">)</span>
    <span class="n">callable_penalty</span> <span class="o">=</span> <span class="n">callable_arctan_penalty</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">callable_proj</span> <span class="o">=</span> <span class="n">get_callable_projector_func</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">probs_func</span><span class="p">)</span>
    <span class="n">results_dict</span> <span class="o">=</span> <span class="n">train_model_gradients</span><span class="p">(</span>
        <span class="n">lr</span><span class="p">,</span>
        <span class="n">init_params</span><span class="p">,</span>
        <span class="n">pytorch_optimizer</span><span class="p">,</span>
        <span class="n">cycler</span><span class="p">,</span>
        <span class="n">n_samples</span><span class="p">,</span>
        <span class="n">callable_penalty</span><span class="p">,</span>
        <span class="n">batch_iterations</span><span class="p">,</span>
        <span class="n">callable_proj</span><span class="p">,</span>
        <span class="n">gamma_length</span><span class="p">,</span>
        <span class="n">print_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">results_dict</span>
</pre></div>
</div>
<p>Before running this workflow, we define all of the input parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">general_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;U&quot;</span><span class="p">:</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AngleEmbedding.html#pennylane.AngleEmbedding" title="pennylane.AngleEmbedding" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">AngleEmbedding</span></a><span class="p">,</span>
    <span class="s2">&quot;W&quot;</span><span class="p">:</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.StronglyEntanglingLayers.html#pennylane.StronglyEntanglingLayers" title="pennylane.StronglyEntanglingLayers" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">StronglyEntanglingLayers</span></a><span class="p">,</span>
    <span class="s2">&quot;D&quot;</span><span class="p">:</span> <span class="n">D</span><span class="p">,</span>
    <span class="s2">&quot;n_qubits&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;probs_func&quot;</span><span class="p">:</span> <span class="n">get_probs</span><span class="p">,</span>
    <span class="s2">&quot;gamma_length&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;n_samples&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;p&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
    <span class="s2">&quot;num_series&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
    <span class="s2">&quot;noise_amp&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;t_init&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="s2">&quot;t_end&quot;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span>
    <span class="s2">&quot;k&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">training_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;tau&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;pytorch_optimizer&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="s2">&quot;batch_iterations&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s2">&quot;W_layers&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">training_options</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">general_options</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now dispatch the lattice to the Covalent server.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tr_dispatch_id</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span><span class="n">training_workflow</span><span class="p">)(</span><span class="o">**</span><span class="n">training_options</span><span class="p">)</span>
</pre></div>
</div>
<p>If you are running the notebook version of this tutorial, if you
navigate to <a class="reference external" href="http://localhost:48008/">http://localhost:48008/</a> you can view the workflow on the
Covalent GUI. It will look like the screenshot below, showing nicely how all of the
electrons defined above interact with each other in the workflow. You can
also track the progress of the calculation here.</p>
<div class="figure align-center" id="id8">
<a class="reference internal image-reference" href="../_images/covalent_tutorial_screenshot.png"><img alt="Training workflow screenshot in Covalent" src="../_images/covalent_tutorial_screenshot.png" style="width: 85%;" /></a>
<p class="caption"><span class="caption-text">A screenshot of the Covalent GUI for the training workflow.</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<p>We now pull the results back from the Covalent server:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ct_tr_results</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">get_result</span><span class="p">(</span><span class="n">dispatch_id</span><span class="o">=</span><span class="n">tr_dispatch_id</span><span class="p">,</span> <span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">results_dict</span> <span class="o">=</span> <span class="n">ct_tr_results</span><span class="o">.</span><span class="n">result</span>
</pre></div>
</div>
<p>and take a look at the training loss history:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;loss_history&quot;</span><span class="p">],</span> <span class="s2">&quot;.-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss [$\mathcal</span><span class="si">{L}</span><span class="s2">$]&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Batch iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Loss function versus batch iterations in training&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_univariate_qvr_003.png" srcset="../_images/sphx_glr_tutorial_univariate_qvr_003.png" alt="Loss function versus batch iterations in training" class = "sphx-glr-single-img"/></div>
<div class="section" id="tuning-the-threshold-zeta">
<h2>Tuning the threshold <span class="math notranslate nohighlight">\(\zeta\)</span><a class="headerlink" href="#tuning-the-threshold-zeta" title="Permalink to this headline">¶</a></h2>
<p>When we have access to labelled anomalous series (as we do in our toy
problem here, often not the case in reality), we can tune the threshold
<span class="math notranslate nohighlight">\(\zeta\)</span> to maximize some success metric. We choose to maximize the
accuracy score as defined using the three electrons below.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_preds_given_threshold</span><span class="p">(</span><span class="n">zeta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;For a given threshold, get the predicted labels (1 or -1), given the anomaly scores.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">zeta</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">])</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_truth_labels</span><span class="p">(</span>
    <span class="n">normal_series_set</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">anomalous_series_set</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a 1D tensor containing the truth values (1 or -1) for a given set of</span>
<span class="sd">    time series.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">normal_series_set</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">anom</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">anomalous_series_set</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">norm</span><span class="p">,</span> <span class="n">anom</span><span class="p">])</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_accuracy_score</span><span class="p">(</span><span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">truth</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given the predictions and truth values, return a number between 0 and 1</span>
<span class="sd">    indicating the accuracy of predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">truth</span><span class="p">)</span> <span class="o">/</span> <span class="n">truth</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Then, knowing the anomaly scores <span class="math notranslate nohighlight">\(a_X(y)\)</span> for a validation data
set, we can scan through various values of <span class="math notranslate nohighlight">\(\zeta\)</span> on a fine 1D grid and calcuate
the accuracy score. Our goal is to pick the <span class="math notranslate nohighlight">\(\zeta\)</span> with the
largest accuracy score.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">threshold_scan_acc_score</span><span class="p">(</span>
    <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">truth_labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">zeta_min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">zeta_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given the anomaly scores and truth values,</span>
<span class="sd">    scan over a range of thresholds = [zeta_min, zeta_max] with a</span>
<span class="sd">    fixed number of steps, calculating the accuracy score at each point.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">zeta</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">zeta_min</span><span class="p">,</span> <span class="n">zeta_max</span><span class="p">,</span> <span class="n">steps</span><span class="p">)):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">get_preds_given_threshold</span><span class="p">(</span><span class="n">zeta</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
        <span class="n">accs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">get_accuracy_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">truth_labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accs</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_anomaly_score</span><span class="p">(</span>
    <span class="n">callable_proj</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">alpha_star</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">mu_star</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">sigma_star</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">get_time_resolved</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the anomaly score for an input time series y. We need to pass the</span>
<span class="sd">    optimal parameters (arguments with suffix _star). Optionally return the</span>
<span class="sd">    time-resolved score (the anomaly score contribution at a given t).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="mi">1</span>
            <span class="o">-</span> <span class="n">F</span><span class="p">(</span>
                <span class="n">callable_proj</span><span class="p">,</span>
                <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">T</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">alpha_star</span><span class="p">,</span>
                <span class="n">mu_star</span><span class="p">,</span>
                <span class="n">sigma_star</span><span class="p">,</span>
                <span class="n">gamma_length</span><span class="p">,</span>
                <span class="n">n_samples</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">square</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">get_time_resolved</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>


<span class="nd">@ct</span><span class="o">.</span><span class="n">electron</span>
<span class="k">def</span> <span class="nf">get_norm_and_anom_scores</span><span class="p">(</span>
    <span class="n">X_norm</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">X_anom</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">T</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">callable_proj</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">model_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the anomaly scores assigned to input normal and anomalous time series instances.</span>
<span class="sd">    model_params is a dictionary containing the optimal model parameters.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">]</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;mu&quot;</span><span class="p">]</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;sigma&quot;</span><span class="p">]</span>
    <span class="n">norm_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">get_anomaly_score</span><span class="p">(</span><span class="n">callable_proj</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">xt</span> <span class="ow">in</span> <span class="n">X_norm</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">anom_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">get_anomaly_score</span><span class="p">(</span><span class="n">callable_proj</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">xt</span> <span class="ow">in</span> <span class="n">X_anom</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">norm_scores</span><span class="p">,</span> <span class="n">anom_scores</span><span class="p">])</span>
</pre></div>
</div>
<p>We now create our second <code class="docutils literal notranslate"><span class="pre">&#64;ct.lattice</span></code>. We are to test the optimal
model against two random models. If our model is trainable, we should
see that the trained model is better.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">lattice</span>
<span class="k">def</span> <span class="nf">threshold_tuning_workflow</span><span class="p">(</span>
    <span class="n">opt_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">probs_func</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">zeta_min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">zeta_max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_series</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">noise_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">spike_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_duration</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">t_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">t_end</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">U</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">D</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">random_model_seeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">W_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A workflow for tuning the threshold value zeta, in order to maximize the accuracy score</span>
<span class="sd">    for a validation data set. Results are tested against random models at their optimal zetas.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate datasets</span>
    <span class="n">X_val_norm</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">generate_normal_time_series_set</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">num_series</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span><span class="p">)</span>
    <span class="n">X_val_anom</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">generate_anomalous_time_series_set</span><span class="p">(</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">num_series</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="n">spike_amp</span><span class="p">,</span> <span class="n">max_duration</span><span class="p">,</span> <span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span>
    <span class="p">)</span>
    <span class="n">truth_labels</span> <span class="o">=</span> <span class="n">get_truth_labels</span><span class="p">(</span><span class="n">X_val_norm</span><span class="p">,</span> <span class="n">X_val_anom</span><span class="p">)</span>

    <span class="c1"># Initialize quantum functions</span>
    <span class="n">callable_proj</span> <span class="o">=</span> <span class="n">get_callable_projector_func</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">probs_func</span><span class="p">)</span>

    <span class="n">accs_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scores_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Evaluate optimal model</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">get_norm_and_anom_scores</span><span class="p">(</span>
        <span class="n">X_val_norm</span><span class="p">,</span> <span class="n">X_val_anom</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">callable_proj</span><span class="p">,</span> <span class="n">opt_params</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span>
    <span class="p">)</span>
    <span class="n">accs_opt</span> <span class="o">=</span> <span class="n">threshold_scan_acc_score</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">truth_labels</span><span class="p">,</span> <span class="n">zeta_min</span><span class="p">,</span> <span class="n">zeta_max</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span>
    <span class="n">accs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accs_opt</span><span class="p">)</span>
    <span class="n">scores_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

    <span class="c1"># Evaluate random models</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">random_model_seeds</span><span class="p">:</span>
        <span class="n">rand_params</span> <span class="o">=</span> <span class="n">get_initial_parameters</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_layers</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">get_norm_and_anom_scores</span><span class="p">(</span>
            <span class="n">X_val_norm</span><span class="p">,</span> <span class="n">X_val_anom</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">callable_proj</span><span class="p">,</span> <span class="n">rand_params</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span>
        <span class="p">)</span>
        <span class="n">accs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">threshold_scan_acc_score</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">truth_labels</span><span class="p">,</span> <span class="n">zeta_min</span><span class="p">,</span> <span class="n">zeta_max</span><span class="p">,</span> <span class="n">steps</span><span class="p">))</span>
        <span class="n">scores_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accs_list</span><span class="p">,</span> <span class="n">scores_list</span>
</pre></div>
</div>
<p>We now set the input parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">threshold_tuning_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;spike_amp&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
    <span class="s2">&quot;max_duration&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;zeta_min&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;zeta_max&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;steps&quot;</span><span class="p">:</span> <span class="mi">100000</span><span class="p">,</span>
    <span class="s2">&quot;random_model_seeds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;W_layers&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;opt_params&quot;</span><span class="p">:</span> <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;opt_params&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">threshold_tuning_options</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">general_options</span><span class="p">)</span>
</pre></div>
</div>
<p>As before, we dispatch the lattice to the <code class="docutils literal notranslate"><span class="pre">Covalent</span></code> server.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">val_dispatch_id</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span><span class="n">threshold_tuning_workflow</span><span class="p">)(</span><span class="o">**</span><span class="n">threshold_tuning_options</span><span class="p">)</span>
<span class="n">ct_val_results</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">get_result</span><span class="p">(</span><span class="n">dispatch_id</span><span class="o">=</span><span class="n">val_dispatch_id</span><span class="p">,</span> <span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">accs_list</span><span class="p">,</span> <span class="n">scores_list</span> <span class="o">=</span> <span class="n">ct_val_results</span><span class="o">.</span><span class="n">result</span>
</pre></div>
</div>
<p>Now, we can plot the results:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">zeta_xlims</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.38</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.38</span><span class="p">)]</span>
<span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Trained model&quot;</span><span class="p">,</span> <span class="s2">&quot;Random model 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Random model 2&quot;</span><span class="p">]</span>
<span class="n">zetas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
    <span class="n">threshold_tuning_options</span><span class="p">[</span><span class="s2">&quot;zeta_min&quot;</span><span class="p">],</span>
    <span class="n">threshold_tuning_options</span><span class="p">[</span><span class="s2">&quot;zeta_max&quot;</span><span class="p">],</span>
    <span class="n">threshold_tuning_options</span><span class="p">[</span><span class="s2">&quot;steps&quot;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="s2">&quot;row&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">zetas</span><span class="p">,</span> <span class="n">accs_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">zeta_xlims</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Threshold [$\zeta$]&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">scores_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span> <span class="p">:</span> <span class="n">general_options</span><span class="p">[</span><span class="s2">&quot;num_series&quot;</span><span class="p">]],</span>
            <span class="n">scores_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">general_options</span><span class="p">[</span><span class="s2">&quot;num_series&quot;</span><span class="p">]</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="p">],</span>
        <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Normal&quot;</span><span class="p">,</span> <span class="s2">&quot;Anomalous&quot;</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span>
        <span class="n">zetas</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accs_list</span><span class="p">[</span><span class="n">i</span><span class="p">])],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Optimal $\zeta$&quot;</span>
    <span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy score&quot;</span><span class="p">)</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Anomaly score [$a_X(y)$]&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_univariate_qvr_004.png" srcset="../_images/sphx_glr_tutorial_univariate_qvr_004.png" alt="Trained model, Random model 1, Random model 2" class = "sphx-glr-single-img"/><p>Parsing the above, we can see that the optimal model achieves high
accuracy when the threshold is tuned using the validation data.
On the other hand, the random models return mostly random results
(sometimes even worse than random guesses), regardless of how we set the
threshold.</p>
</div>
<div class="section" id="testing-the-model">
<h2>Testing the model<a class="headerlink" href="#testing-the-model" title="Permalink to this headline">¶</a></h2>
<p>Now with optimal thresholds for our optimized and random models, we can perform testing.
We already have all of the electrons to do this, so we create
the <code class="docutils literal notranslate"><span class="pre">&#64;ct.lattice</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ct</span><span class="o">.</span><span class="n">lattice</span>
<span class="k">def</span> <span class="nf">testing_workflow</span><span class="p">(</span>
    <span class="n">opt_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">gamma_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">probs_func</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">best_zetas</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
    <span class="n">p</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_series</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">noise_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">spike_amp</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_duration</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">t_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">t_end</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">k</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">U</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">W</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">D</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="n">n_qubits</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">random_model_seeds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">W_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A workflow for calculating anomaly scores for a set of testing time series</span>
<span class="sd">    given an optimal model and set of random models. We use the optimal zetas found in threshold tuning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Generate time series</span>
    <span class="n">X_val_norm</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">generate_normal_time_series_set</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">num_series</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span><span class="p">)</span>
    <span class="n">X_val_anom</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">generate_anomalous_time_series_set</span><span class="p">(</span>
        <span class="n">p</span><span class="p">,</span> <span class="n">num_series</span><span class="p">,</span> <span class="n">noise_amp</span><span class="p">,</span> <span class="n">spike_amp</span><span class="p">,</span> <span class="n">max_duration</span><span class="p">,</span> <span class="n">t_init</span><span class="p">,</span> <span class="n">t_end</span>
    <span class="p">)</span>
    <span class="n">truth_labels</span> <span class="o">=</span> <span class="n">get_truth_labels</span><span class="p">(</span><span class="n">X_val_norm</span><span class="p">,</span> <span class="n">X_val_anom</span><span class="p">)</span>

    <span class="c1"># Prepare quantum functions</span>
    <span class="n">callable_proj</span> <span class="o">=</span> <span class="n">get_callable_projector_func</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">probs_func</span><span class="p">)</span>

    <span class="n">accs_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Evaluate optimal model</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">get_norm_and_anom_scores</span><span class="p">(</span>
        <span class="n">X_val_norm</span><span class="p">,</span> <span class="n">X_val_anom</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">callable_proj</span><span class="p">,</span> <span class="n">opt_params</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span>
    <span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">get_preds_given_threshold</span><span class="p">(</span><span class="n">best_zetas</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scores</span><span class="p">)</span>
    <span class="n">accs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_accuracy_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">truth_labels</span><span class="p">))</span>
    <span class="c1"># Evaluate random models</span>
    <span class="k">for</span> <span class="n">zeta</span><span class="p">,</span> <span class="n">seed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_zetas</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">random_model_seeds</span><span class="p">):</span>
        <span class="n">rand_params</span> <span class="o">=</span> <span class="n">get_initial_parameters</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">W_layers</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">get_norm_and_anom_scores</span><span class="p">(</span>
            <span class="n">X_val_norm</span><span class="p">,</span> <span class="n">X_val_anom</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">callable_proj</span><span class="p">,</span> <span class="n">rand_params</span><span class="p">,</span> <span class="n">gamma_length</span><span class="p">,</span> <span class="n">n_samples</span>
        <span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">get_preds_given_threshold</span><span class="p">(</span><span class="n">zeta</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
        <span class="n">accs_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_accuracy_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">truth_labels</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">accs_list</span>
</pre></div>
</div>
<p>We dispatch it to the Covalent server with the appropriate parameters.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">testing_options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;spike_amp&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
    <span class="s2">&quot;max_duration&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;best_zetas&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">zetas</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">accs</span><span class="p">)]</span> <span class="k">for</span> <span class="n">accs</span> <span class="ow">in</span> <span class="n">accs_list</span><span class="p">],</span>
    <span class="s2">&quot;random_model_seeds&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;W_layers&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s2">&quot;opt_params&quot;</span><span class="p">:</span> <span class="n">results_dict</span><span class="p">[</span><span class="s2">&quot;opt_params&quot;</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">testing_options</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">general_options</span><span class="p">)</span>

<span class="n">test_dispatch_id</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span><span class="n">testing_workflow</span><span class="p">)(</span><span class="o">**</span><span class="n">testing_options</span><span class="p">)</span>
<span class="n">ct_test_results</span> <span class="o">=</span> <span class="n">ct</span><span class="o">.</span><span class="n">get_result</span><span class="p">(</span><span class="n">dispatch_id</span><span class="o">=</span><span class="n">test_dispatch_id</span><span class="p">,</span> <span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">accs_list</span> <span class="o">=</span> <span class="n">ct_test_results</span><span class="o">.</span><span class="n">result</span>
</pre></div>
</div>
<p>Finally, we plot the results below.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">accs_list</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Trained model&quot;</span><span class="p">,</span> <span class="s2">&quot;Random model 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Random model 2&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy score&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Accuracy scores for trained and random models&quot;</span><span class="p">)</span>
<span class="n">leg</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_univariate_qvr_005.png" srcset="../_images/sphx_glr_tutorial_univariate_qvr_005.png" alt="Accuracy scores for trained and random models" class = "sphx-glr-single-img"/><p>As can be seen, once more, the trained model is far more accurate than
the random models. Awesome! Now that we’re done with the calculations in
this tutorial, we just need to remember to shut down the Covalent server</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Shut down the covalent server</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s2">&quot;covalent stop&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="conclusions">
<h2>Conclusions<a class="headerlink" href="#conclusions" title="Permalink to this headline">¶</a></h2>
<p>We’ve now reached the end of this tutorial! Quickly recounting what we have learnt, we:</p>
<ol class="arabic simple">
<li><p>Learnt the background of how to detect anomalous time series instances, <em>quantumly</em>,</p></li>
<li><p>Learnt how to build the code to achieve this using PennyLane and PyTorch, and,</p></li>
<li><p>Learnt the basics of Covalent: a workflow orchestration tool for heterogeneous computation</p></li>
</ol>
<p>If you want to learn more about QVR, you should consult the paper <a class="footnote-reference brackets" href="#baker2022" id="id7">1</a> where we
generalize the math a little and test the algorithm on less trivial time series data than
was dealt with in this tutorial. We also ran some experiments on real quantum computers,
enhancing our results using error mitigation techniques. If you want to play some more with
Covalent, check us out on <a class="reference external" href="https://github.com/AgnostiqHQ/covalent/">GitHub</a> and/or engage
with other tutorials in our <a class="reference external" href="https://covalent.readthedocs.io/en/stable/">documentation</a>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="baker2022"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id3">2</a>,<a href="#id5">3</a>,<a href="#id7">4</a>)</span></dt>
<dd><p>Baker, Jack S. et al. “Quantum Variational Rewinding for Time Series
Anomaly Detection.” arXiv preprint
<a class="reference external" href="https://arxiv.org/abs/2210.16438">arXiv:2210.164388</a> (2022).</p>
</dd>
<dt class="label" id="stone1932"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Stone, Marshall H. “On one-parameter unitary groups in Hilbert
space.” Annals of Mathematics, 643-648,
<a class="reference external" href="https://doi.org/10.2307/1968538">doi:10.2307/1968538</a> (1932).</p>
</dd>
<dt class="label" id="welch2014"><span class="brackets"><a class="fn-backref" href="#id4">3</a></span></dt>
<dd><p>Welch, Jonathan et al. “Efficient quantum circuits for diagonal
unitaries without ancillas”, New Journal of Physics, <strong>16</strong>, 033040
<a class="reference external" href="https://doi.org/10.1088/1367-2630/16/3/033040">doi:10.1088/1367-2630/16/3/033040</a>
(2014).</p>
</dd>
<dt class="label" id="cirstoiu2020"><span class="brackets"><a class="fn-backref" href="#id6">4</a></span></dt>
<dd><p>Cîrstoiu, Cristina et al. “Variational fast forwarding for quantum
simulation beyond the coherence time”, npj Quantum Information,
<strong>6</strong>,
<a class="reference external" href="https://doi.org/10.1038/s41534-020-00302-0">doi:10.1038/s41534-020-00302-0</a>,
(2020)</p>
</dd>
</dl>
</div>
<div class="section" id="about-the-authors">
<h2>About the authors<a class="headerlink" href="#about-the-authors" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/jack_stephen_baker.png" alt="Jack Stephen Baker" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Jack Stephen Baker</h4>
        <p class="bio-text__author-description">Jack is a quantum algorithms researcher at Agnostiq specializing in quantum machine learning and optimization.</p>
    </div>
</div><div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/santosh_kumar_radha.png" alt="Santosh Kumar Radha" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Santosh Kumar Radha</h4>
        <p class="bio-text__author-description">Santosh is the head of research and development and product lead at Agnostiq.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 9 minutes  39.226 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-univariate-qvr-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/29a23cd82c00993d489bc40c10e75628/tutorial_univariate_qvr.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_univariate_qvr.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/60c502629b942dd4dc528083fb3c0d4e/tutorial_univariate_qvr.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_univariate_qvr.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_univariate_qvr</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Quantum detection of time series anomalies</a><ul class='current'>
<li class='current'><a class="reference internal" href="#background">Background</a></li>
<li class='current'><a class="reference internal" href="#covalent-heterogeneous-workflow-orchestration">Covalent: heterogeneous workflow orchestration</a></li>
<li class='current'><a class="reference internal" href="#generating-univariate-synthetic-time-series">Generating univariate synthetic time series</a></li>
<li class='current'><a class="reference internal" href="#building-the-loss-function">Building the loss function</a></li>
<li class='current'><a class="reference internal" href="#training-the-normal-model">Training the normal model</a></li>
<li class='current'><a class="reference internal" href="#tuning-the-threshold-zeta">Tuning the threshold <span class="math notranslate nohighlight">\(\zeta\)</span></a></li>
<li class='current'><a class="reference internal" href="#testing-the-model">Testing the model</a></li>
<li class='current'><a class="reference internal" href="#conclusions">Conclusions</a></li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-authors">About the authors</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_univariate_qvr</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_qml.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_contextuality.html" title="Contextuality and inductive bias in QML"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_geometric_qml.html" title="Introduction to Geometric Quantum Machine Learning"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_qml.html" >Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum detection of time series anomalies</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>