
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "demos/tutorial_expressivity_fourier_series.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_demos_tutorial_expressivity_fourier_series.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_demos_tutorial_expressivity_fourier_series.py:


Quantum models as Fourier series
================================

.. meta::
    :property="og:description": The class of functions a quantum model can learn is characterized by the structure of its corresponding Fourier series.
    :property="og:image": https://pennylane.ai/qml/_images/scheme.png

.. related::

   tutorial_data_reuploading_classifier Data-reuploading classifier

*Authors: Maria Schuld and Johannes Jakob Meyer — Posted: 24 August 2020. Last updated: 15 January 2021.*

.. GENERATED FROM PYTHON SOURCE LINES 19-28

This demonstration is based on the paper *The effect of data encoding on
the expressive power of variational quantum machine learning models* by
`Schuld, Sweke, and Meyer
(2020) <https://arxiv.org/abs/2008.08605>`__ [#schuld2020]_.

.. figure:: ../demonstrations/expressivity_fourier_series/scheme_thumb.png
  :width: 50%
  :align: center


.. GENERATED FROM PYTHON SOURCE LINES 31-37

The paper links common quantum machine learning models designed for
near-term quantum computers to Fourier series (and, in more general, to
Fourier-type sums). With this link, the class of functions a quantum
model can learn (i.e., its "expressivity") can be characterized by the
model's control of the Fourier series' frequencies and coefficients.


.. GENERATED FROM PYTHON SOURCE LINES 40-43

Background
----------


.. GENERATED FROM PYTHON SOURCE LINES 46-65

Ref. [#schuld2020]_ considers quantum machine
learning models of the form

.. math:: f_{\boldsymbol \theta}(x) = \langle 0| U^{\dagger}(x,\boldsymbol \theta) M U(x, \boldsymbol \theta) | 0 \rangle 

where :math:`M` is a measurement observable and
:math:`U(x, \boldsymbol \theta)` is a variational quantum circuit that
encodes a data input :math:`x` and depends on a
set of parameters :math:`\boldsymbol \theta`. Here we will restrict ourselves
to one-dimensional data inputs, but the paper motivates that higher-dimensional
features simply generalize to multi-dimensional Fourier series.

The circuit itself repeats :math:`L` layers, each consisting of a data-encoding circuit
block :math:`S(x)` and a trainable circuit block
:math:`W(\boldsymbol \theta)` that is controlled by the parameters
:math:`\boldsymbol \theta`. The data encoding block consists of gates of
the form :math:`\mathcal{G}(x) = e^{-ix H}`, where :math:`H` is a
Hamiltonian. A prominent example of such gates are Pauli rotations.


.. GENERATED FROM PYTHON SOURCE LINES 68-79

The paper shows how such a quantum model can be written as a
Fourier-type sum of the form

.. math::  f_{ \boldsymbol \theta}(x) = \sum_{\omega \in \Omega} c_{\omega}( \boldsymbol \theta) \; e^{i  \omega x}. 

As illustrated in the picture below (which is Figure 1 from the paper),
the "encoding Hamiltonians" in :math:`S(x)` determine the set
:math:`\Omega` of available "frequencies", and the remainder of the
circuit, including the trainable parameters, determines the coefficients
:math:`c_{\omega}`.


.. GENERATED FROM PYTHON SOURCE LINES 82-88

.. figure:: ../demonstrations/expressivity_fourier_series/scheme.png
  :width: 50%
  :align: center

|


.. GENERATED FROM PYTHON SOURCE LINES 91-107

The paper demonstrates many of its findings for circuits in which
:math:`\mathcal{G}(x)` is a single-qubit Pauli rotation gate. For 
example, it shows that :math:`r` repetitions of a Pauli rotation-encoding 
gate in "sequence" (on the same qubit, but with multiple layers :math:`r=L`) or
in "parallel" (on :math:`r` different qubits, with :math:`L=1`) creates a quantum
model that can be expressed as a *Fourier series* of the form

.. math::  f_{ \boldsymbol \theta}(x) = \sum_{n \in \Omega} c_{n}(\boldsymbol \theta) e^{i  n x}, 

where :math:`\Omega = \{ -r, \dots, -1, 0, 1, \dots, r\}` is a spectrum
of consecutive integer-valued frequencies up to degree :math:`r`.

As a result, we expect quantum models that encode an input :math:`x` by
:math:`r` Pauli rotations to only be able to fit Fourier series of at
most degree :math:`r`.


.. GENERATED FROM PYTHON SOURCE LINES 111-114

Goal of this demonstration
--------------------------


.. GENERATED FROM PYTHON SOURCE LINES 117-135

The experiments below investigate this "Fourier-series"-like nature of
quantum models by showing how to reproduce the simulations underlying
Figures 3, 4 and 5 in Section II of the paper:

-  **Figures 3 and 4** are function-fitting experiments, where quantum
   models with different encoding strategies have the task to fit
   Fourier series up to a certain degree. As in the paper, we will use
   examples of qubit-based quantum circuits where a single data feature
   is encoded via Pauli rotations.

-  **Figure 5** plots the Fourier coefficients of randomly sampled
   instances from a family of quantum models which is defined by some
   parametrized ansatz.

The code is presented so you can easily modify it in order to play
around with other settings and models. The settings used in the paper 
are given in the various subsections.


.. GENERATED FROM PYTHON SOURCE LINES 138-141

First of all, let's make some imports and define a standard loss
function for the training.


.. GENERATED FROM PYTHON SOURCE LINES 141-156

.. code-block:: default


    import matplotlib.pyplot as plt
    import pennylane as qml
    from pennylane import numpy as np

    np.random.seed(42)

    def square_loss(targets, predictions):
        loss = 0
        for t, p in zip(targets, predictions):
            loss += (t - p) ** 2
        loss = loss / len(targets)
        return 0.5*loss









.. GENERATED FROM PYTHON SOURCE LINES 157-160

Part I: Fitting Fourier series with serial Pauli-rotation encoding
------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 163-177

First we will reproduce Figures 3 and 4 from the paper. These
show how quantum models that use Pauli rotations as data-encoding 
gates can only fit Fourier series up to a certain degree. The
degree corresponds to the number of times that the Pauli gate gets
repeated in the quantum model.

Let us consider circuits where the encoding gate gets repeated
sequentially (as in Figure 2a of the paper). For simplicity we will only
look at single-qubit circuits:

.. figure:: ../demonstrations/expressivity_fourier_series/single_qubit_model.png
  :width: 50%
  :align: center


.. GENERATED FROM PYTHON SOURCE LINES 180-183

Define a target function
~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 186-197

We first define a (classical) target function which will be used as a 
"ground truth" that the quantum model has to fit. The target function is 
constructed as a Fourier series of a specific degree.

We also allow for a rescaling of the data by a hyperparameter ``scaling``,
which we will do in the quantum model as well. As shown in [#schuld2020]_, for the quantum model to
learn the classical model in the experiment below,
the scaling of the quantum model and the target function have to match,
which is an important observation for
the design of quantum machine learning models.


.. GENERATED FROM PYTHON SOURCE LINES 197-214

.. code-block:: default



    degree = 1  # degree of the target function
    scaling = 1  # scaling of the data
    coeffs = [0.15 + 0.15j]*degree  # coefficients of non-zero frequencies
    coeff0 = 0.1  # coefficient of zero frequency

    def target_function(x):
        """Generate a truncated Fourier series, where the data gets re-scaled."""
        res = coeff0
        for idx, coeff in enumerate(coeffs):
            exponent = np.complex128(scaling * (idx+1) * x * 1j)
            conj_coeff = np.conjugate(coeff)
            res += coeff * np.exp(exponent) + conj_coeff * np.exp(-exponent)
        return np.real(res)









.. GENERATED FROM PYTHON SOURCE LINES 215-217

Let's have a look at it.


.. GENERATED FROM PYTHON SOURCE LINES 217-227

.. code-block:: default


    x = np.linspace(-6, 6, 70, requires_grad=False)
    target_y = np.array([target_function(x_) for x_ in x], requires_grad=False)

    plt.plot(x, target_y, c='black')
    plt.scatter(x, target_y, facecolor='white', edgecolor='black')
    plt.ylim(-1, 1)
    plt.show();





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_001.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 228-262

.. note:: 

    To reproduce the figures in the paper, you can use the following
    settings in the cells above:

    -  For the settings

       ::

           degree = 1
           coeffs = (0.15 + 0.15j) * degree 
           coeff0 = 0.1

       this function is the ground truth
       :math:`g(x) = \sum_{n=-1}^1 c_{n} e^{-nix}` from Figure 3 in the
       paper.

    -  To get the ground truth :math:`g'(x) = \sum_{n=-2}^2 c_{n} e^{-nix}`
       with :math:`c_0=0.1`, :math:`c_1 = c_2 = 0.15 - 0.15i` from Figure 3,
       you need to increase the degree to two:

       ::

           degree = 2

    -  The ground truth from Figure 4 can be reproduced by changing the
       settings to:

       ::

           degree = 5 
           coeffs = (0.05 + 0.05j) * degree 
           coeff0 = 0.0 


.. GENERATED FROM PYTHON SOURCE LINES 265-268

Define the serial quantum model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 271-273

We now define the quantum model itself.


.. GENERATED FROM PYTHON SOURCE LINES 273-300

.. code-block:: default


    scaling = 1

    dev = qml.device('default.qubit', wires=1)

    def S(x):
        """Data-encoding circuit block."""
        qml.RX(scaling * x, wires=0)

    def W(theta):
        """Trainable circuit block."""
        qml.Rot(theta[0], theta[1], theta[2], wires=0)

    
    @qml.qnode(dev, interface="autograd")
    def serial_quantum_model(weights, x):
    
        for theta in weights[:-1]:
            W(theta)
            S(x)
        
        # (L+1)'th unitary
        W(weights[-1])
    
        return qml.expval(qml.PauliZ(wires=0))









.. GENERATED FROM PYTHON SOURCE LINES 301-304

You can run the following cell multiple times, each time sampling
different weights, and therefore different quantum models.


.. GENERATED FROM PYTHON SOURCE LINES 304-316

.. code-block:: default


    r = 1 # number of times the encoding gets repeated (here equal to the number of layers)
    weights = 2 * np.pi * np.random.random(size=(r+1, 3), requires_grad=True) # some random initial weights

    x = np.linspace(-6, 6, 70, requires_grad=False)
    random_quantum_model_y = [serial_quantum_model(weights, x_) for x_ in x]

    plt.plot(x, random_quantum_model_y, c='blue')
    plt.ylim(-1,1)
    plt.show()





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_002.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 317-322

No matter what weights are picked, the single qubit model for `L=1` will always be a sine function 
of a fixed frequency. The weights merely influence the amplitude, y-shift, and phase of the sine.

This observation is formally derived in Section II.A of the paper.


.. GENERATED FROM PYTHON SOURCE LINES 326-331

.. note:: 

    You can increase the number of layers. Figure 4 from the paper, for
    example, uses the settings ``L=1``, ``L=3`` and ``L=5``.


.. GENERATED FROM PYTHON SOURCE LINES 334-336

Finally, let's look at the circuit we just created:


.. GENERATED FROM PYTHON SOURCE LINES 336-340

.. code-block:: default


    print(qml.draw(serial_quantum_model)(weights, x[-1]))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    0: ──Rot(2.35,5.97,4.60)──RX(6.00)──Rot(3.76,0.98,0.98)─┤  <Z>




.. GENERATED FROM PYTHON SOURCE LINES 341-344

Fit the model to the target
~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 347-350

The next step is to optimize the weights in order to fit the ground
truth.


.. GENERATED FROM PYTHON SOURCE LINES 350-377

.. code-block:: default


    def cost(weights, x, y):
        predictions = [serial_quantum_model(weights, x_) for x_ in x]
        return square_loss(y, predictions)

    max_steps = 50
    opt = qml.AdamOptimizer(0.3)
    batch_size = 25
    cst = [cost(weights, x, target_y)]  # initial cost

    for step in range(max_steps):

        # Select batch of data
        batch_index = np.random.randint(0, len(x), (batch_size,))
        x_batch = x[batch_index]
        y_batch = target_y[batch_index]

        # Update the weights by one optimizer step
        weights, _, _ = opt.step(cost, weights, x_batch, y_batch)

        # Save, and possibly print, the current cost
        c = cost(weights, x, target_y)
        cst.append(c)
        if (step + 1) % 10 == 0:
            print("Cost at step {0:3}: {1}".format(step + 1, c))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Cost at step  10: 0.03212041720004578
    Cost at step  20: 0.013853561883024685
    Cost at step  30: 0.004049396436389444
    Cost at step  40: 0.0005624933894468351
    Cost at step  50: 8.145777333271227e-05




.. GENERATED FROM PYTHON SOURCE LINES 378-382

To continue training, you may just run the above cell again. Once you
are happy, you can use the trained model to predict function values, and
compare them with the ground truth.


.. GENERATED FROM PYTHON SOURCE LINES 382-392

.. code-block:: default


    predictions = [serial_quantum_model(weights, x_) for x_ in x]

    plt.plot(x, target_y, c='black')
    plt.scatter(x, target_y, facecolor='white', edgecolor='black')
    plt.plot(x, predictions, c='blue')
    plt.ylim(-1,1)
    plt.show();





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_003.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 393-395

Let's also have a look at the cost during training.


.. GENERATED FROM PYTHON SOURCE LINES 395-403

.. code-block:: default


    plt.plot(range(len(cst)), cst)
    plt.ylabel("Cost")
    plt.xlabel("Step")
    plt.ylim(0, 0.23)
    plt.show();





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_004.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_004.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 404-416

With the initial settings and enough training steps, the quantum model 
learns to fit the ground truth perfectly. This is expected, since 
the number of Pauli-rotation-encoding gates and the degree of the 
ground truth Fourier series are both one.

If the ground truth's degree is larger than the number of layers in the
quantum model, the fit will look much less accurate. And finally, we
also need to have the correct scaling of the data: if one of the models
changes the ``scaling`` parameter (which effectively scales the
frequencies), fitting does not work even with enough encoding
repetitions.


.. GENERATED FROM PYTHON SOURCE LINES 419-428

.. note::

    You will find that the training takes much longer, and needs a lot more steps to converge for 
    larger L. Some initial weights may not even converge to a good solution at all; the training 
    seems to get stuck in a minimum. 

    It is an open research question whether for asymptotically large L, the single qubit 
    model can fit *any* function by constructing arbitrary Fourier coefficients.


.. GENERATED FROM PYTHON SOURCE LINES 431-434

Part II: Fitting Fourier series with parallel Pauli-rotation encoding
---------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 437-457

Our next task is to repeat the function-fitting experiment for a circuit
where the Pauli rotation gate gets repeated :math:`r` times on
*different* qubits, using a single layer :math:`L=1`.

As shown in the paper, we expect similar results to the serial model: a
Fourier series of degree :math:`r` can only be fitted if there are at
least :math:`r` repetitions of the encoding gate in the quantum model.
However, in practice this experiment is a bit harder, since the dimension of the
trainable unitaries :math:`W` grows quickly with the number of qubits.

In the paper, the investigations are made with the assumption that the
purple trainable blocks :math:`W` are arbitrary unitaries. We could use
the :class:`~.pennylane.templates.ArbitraryUnitary` template, but since this
template requires a number of parameters that grows exponentially with
the number of qubits (:math:`4^L-1` to be precise), this quickly becomes
cumbersome to train.

We therefore follow Figure 4 in the paper and use an ansatz for
:math:`W`. 


.. GENERATED FROM PYTHON SOURCE LINES 460-464

.. figure:: ../demonstrations/expressivity_fourier_series/parallel_model.png
  :width: 70%
  :align: center


.. GENERATED FROM PYTHON SOURCE LINES 467-470

Define the parallel quantum model
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 473-478

The ansatz is PennyLane's layer structure called
:class:`~.pennylane.templates.StronglyEntanglingLayers`, and as the name suggests, it has itself a
user-defined number of layers (which we will call "ansatz layers" to
avoid confusion).


.. GENERATED FROM PYTHON SOURCE LINES 478-482

.. code-block:: default


    from pennylane.templates import StronglyEntanglingLayers









.. GENERATED FROM PYTHON SOURCE LINES 483-486

Let's have a quick look at the ansatz itself for 3 qubits by making a
dummy circuit of 2 ansatz layers:


.. GENERATED FROM PYTHON SOURCE LINES 486-501

.. code-block:: default


    n_ansatz_layers = 2
    n_qubits = 3

    dev = qml.device('default.qubit', wires=4)

    @qml.qnode(dev, interface="autograd")
    def ansatz(weights):
        StronglyEntanglingLayers(weights, wires=range(n_qubits))
        return qml.expval(qml.Identity(wires=0))

    weights_ansatz = 2 * np.pi * np.random.random(size=(n_ansatz_layers, n_qubits, 3))
    print(qml.draw(ansatz, expansion_strategy="device")(weights_ansatz))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    0: ──Rot(1.38,4.29,0.48)─╭●────╭X──Rot(4.26,3.55,1.68)─╭●─╭X────┤  <I>
    1: ──Rot(5.35,3.11,3.02)─╰X─╭●─│───Rot(5.52,5.01,4.14)─│──╰●─╭X─┤     
    2: ──Rot(3.72,5.18,2.19)────╰X─╰●──Rot(5.34,5.45,4.45)─╰X────╰●─┤     




.. GENERATED FROM PYTHON SOURCE LINES 502-504

Now we define the actual quantum model.


.. GENERATED FROM PYTHON SOURCE LINES 504-530

.. code-block:: default


    scaling = 1
    r = 3

    dev = qml.device('default.qubit', wires=r)

    def S(x):
        """Data-encoding circuit block."""
        for w in range(r):
            qml.RX(scaling * x, wires=w)

    def W(theta):
        """Trainable circuit block."""
        StronglyEntanglingLayers(theta, wires=range(r))

    
    @qml.qnode(dev, interface="autograd")
    def parallel_quantum_model(weights, x):
    
        W(weights[0])
        S(x)        
        W(weights[1])
    
        return qml.expval(qml.PauliZ(wires=0))









.. GENERATED FROM PYTHON SOURCE LINES 531-533

Again, you can sample random weights and plot the model function:


.. GENERATED FROM PYTHON SOURCE LINES 533-545

.. code-block:: default


    trainable_block_layers = 3
    weights = 2 * np.pi * np.random.random(size=(2, trainable_block_layers, r, 3), requires_grad=True)

    x = np.linspace(-6, 6, 70, requires_grad=False)
    random_quantum_model_y = [parallel_quantum_model(weights, x_) for x_ in x]

    plt.plot(x, random_quantum_model_y, c='blue')
    plt.ylim(-1,1)
    plt.show();





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_005.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_005.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 546-549

Training the model
~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 552-558

Training the model is done exactly as before, but it may take a lot
longer this time. We set a default of 25 steps, which you should
increase if necessary. Small models of <6 qubits
usually converge after a few hundred steps at most—but this
depends on your settings.


.. GENERATED FROM PYTHON SOURCE LINES 558-585

.. code-block:: default


    def cost(weights, x, y):
        predictions = [parallel_quantum_model(weights, x_) for x_ in x]
        return square_loss(y, predictions)

    max_steps = 50
    opt = qml.AdamOptimizer(0.3)
    batch_size = 25
    cst = [cost(weights, x, target_y)]  # initial cost

    for step in range(max_steps):

        # select batch of data
        batch_index = np.random.randint(0, len(x), (batch_size,))
        x_batch = x[batch_index]
        y_batch = target_y[batch_index]

        # update the weights by one optimizer step
        weights, _, _ = opt.step(cost, weights, x_batch, y_batch)
    
        # save, and possibly print, the current cost
        c = cost(weights, x, target_y)
        cst.append(c)
        if (step + 1) % 10 == 0:
            print("Cost at step {0:3}: {1}".format(step + 1, c))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Cost at step  10: 0.017166449445318976
    Cost at step  20: 0.005497199314425964
    Cost at step  30: 0.004784402394898685
    Cost at step  40: 0.004015481434555319
    Cost at step  50: 0.0013998102989783007




.. GENERATED FROM PYTHON SOURCE LINES 587-598

.. code-block:: default



    predictions = [parallel_quantum_model(weights, x_) for x_ in x]

    plt.plot(x, target_y, c='black')
    plt.scatter(x, target_y, facecolor='white', edgecolor='black')
    plt.plot(x, predictions, c='blue')
    plt.ylim(-1,1)
    plt.show();





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_006.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_006.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 600-609

.. code-block:: default



    plt.plot(range(len(cst)), cst)
    plt.ylabel("Cost")
    plt.xlabel("Step")
    plt.show();






.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_007.png
   :alt: tutorial expressivity fourier series
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_007.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 610-618

.. note:: 

    To reproduce the right column in Figure 4 from the paper, use the 
    correct ground truth, :math:`r=3` and ``trainable_block_layers=3``,
    as well as sufficiently many training steps. The amount of steps 
    depends on the initial weights and other hyperparameters, and 
    in some settings training may not converge to zero error at all.


.. GENERATED FROM PYTHON SOURCE LINES 620-623

Part III: Sampling Fourier coefficients
---------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 626-637

When we use a trainable ansatz above, it is possible that even with
enough repetitions of the data-encoding Pauli rotation, the quantum
model cannot fit the circuit, since the expressivity of quantum models
also depends on the Fourier coefficients the model can create.

Figure 5 in [#schuld2020]_ shows Fourier coefficients
from quantum models sampled from a model family defined by an 
ansatz for the trainable circuit block. For this we need a
function that numerically computes the Fourier coefficients of a
periodic function f with period :math:`2 \pi`.


.. GENERATED FROM PYTHON SOURCE LINES 637-648

.. code-block:: default


    def fourier_coefficients(f, K):
        """
        Computes the first 2*K+1 Fourier coefficients of a 2*pi periodic function.
        """
        n_coeffs = 2 * K + 1
        t = np.linspace(0, 2 * np.pi, n_coeffs, endpoint=False)
        y = np.fft.rfft(f(t)) / t.size
        return y









.. GENERATED FROM PYTHON SOURCE LINES 649-652

Define your quantum model
~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 655-660

Now we need to define a quantum model. This could be any model, using a
qubit or continuous-variable circuit, or one of the quantum models from
above. We will use a slight derivation of the ``parallel_qubit_model()``
from above, this time using the :class:`~.pennylane.templates.BasicEntanglerLayers` ansatz:


.. GENERATED FROM PYTHON SOURCE LINES 660-688

.. code-block:: default


    from pennylane.templates import BasicEntanglerLayers

    scaling = 1
    n_qubits = 4

    dev = qml.device('default.qubit', wires=n_qubits)

    def S(x):
        """Data encoding circuit block."""
        for w in range(n_qubits):
            qml.RX(scaling * x, wires=w)

    def W(theta):
        """Trainable circuit block."""
        BasicEntanglerLayers(theta, wires=range(n_qubits))

    
    @qml.qnode(dev, interface="autograd")
    def quantum_model(weights, x):
    
        W(weights[0])
        S(x)
        W(weights[1])
    
        return qml.expval(qml.PauliZ(wires=0))









.. GENERATED FROM PYTHON SOURCE LINES 689-692

It will also be handy to define a function that samples different random
weights of the correct size for the model.


.. GENERATED FROM PYTHON SOURCE LINES 692-699

.. code-block:: default


    n_ansatz_layers = 1

    def random_weights():
        return 2 * np.pi * np.random.random(size=(2, n_ansatz_layers, n_qubits))









.. GENERATED FROM PYTHON SOURCE LINES 700-704

Now we can compute the first few Fourier coefficients for samples from
this model. The samples are created by randomly sampling different
parameters using the ``random_weights()`` function.


.. GENERATED FROM PYTHON SOURCE LINES 704-725

.. code-block:: default


    n_coeffs = 5
    n_samples = 100


    coeffs = []
    for i in range(n_samples):

        weights = random_weights()

        def f(x):
            return np.array([quantum_model(weights, x_) for x_ in x])

        coeffs_sample = fourier_coefficients(f, n_coeffs)
        coeffs.append(coeffs_sample)

    coeffs = np.array(coeffs)
    coeffs_real = np.real(coeffs)
    coeffs_imag = np.imag(coeffs)









.. GENERATED FROM PYTHON SOURCE LINES 726-730

Let's plot the real vs. the imaginary part of the coefficients. As a
sanity check, the :math:`c_0` coefficient should be real, and therefore
have no contribution on the y-axis.


.. GENERATED FROM PYTHON SOURCE LINES 730-748

.. code-block:: default


    n_coeffs = len(coeffs_real[0])

    fig, ax = plt.subplots(1, n_coeffs, figsize=(15, 4))

    for idx, ax_ in enumerate(ax):
        ax_.set_title(r"$c_{}$".format(idx))
        ax_.scatter(coeffs_real[:, idx], coeffs_imag[:, idx], s=20, 
                    facecolor='white', edgecolor='red')
        ax_.set_aspect("equal")
        ax_.set_ylim(-1, 1)
        ax_.set_xlim(-1, 1)


    plt.tight_layout(pad=0.5)
    plt.show();





.. image-sg:: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_008.png
   :alt: $c_0$, $c_1$, $c_2$, $c_3$, $c_4$, $c_5$
   :srcset: /demos/images/sphx_glr_tutorial_expressivity_fourier_series_008.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 749-761

Playing around with different quantum models, you will find
that some quantum models create different distributions over
the coefficients than others. For example ``BasicEntanglingLayers``
(with the default Pauli-X rotation) seems to have a structure
that forces the even Fourier coefficients to zero, while
``StronglyEntanglingLayers`` will have a non-zero variance
for all supported coefficients.

Note also how the variance of the distribution decreases for growing
orders of the coefficients—an effect linked to the convergence of a
Fourier series.


.. GENERATED FROM PYTHON SOURCE LINES 764-772

.. note::

    To reproduce the results from Figure 5 you have to change the ansatz (no
    unitary, ``BasicEntanglerLayers`` or ``StronglyEntanglingLayers``, and
    set ``n_ansatz_layers`` either to :math:`1` or :math:`5`). The
    ``StronglyEntanglingLayers`` requires weights of shape
    ``size=(2, n_ansatz_layers, n_qubits, 3)``.


.. GENERATED FROM PYTHON SOURCE LINES 775-784

Continuous-variable model
~~~~~~~~~~~~~~~~~~~~~~~~~

Ref. [#schuld2020]_ mentions that a phase rotation in
continuous-variable quantum computing has a spectrum that supports *all*
Fourier frequecies. To play with this model, we finally show you the
code for a continuous-variable circuit. For example, to see its Fourier
coefficients run the cell below, and then re-run the two cells above.


.. GENERATED FROM PYTHON SOURCE LINES 784-808

.. code-block:: default


    var = 2
    n_ansatz_layers = 1
    dev_cv = qml.device('default.gaussian', wires=1)

    def S(x):
        qml.Rotation(x, wires=0)

    def W(theta):
        """Trainable circuit block."""
        for r_ in range(n_ansatz_layers):
            qml.Displacement(theta[0], theta[1], wires=0)
            qml.Squeezing(theta[2], theta[3], wires=0)

    @qml.qnode(dev_cv)
    def quantum_model(weights, x):
        W(weights[0])
        S(x)
        W(weights[1])
        return qml.expval(qml.QuadX(wires=0))

    def random_weights():
        return np.random.normal(size=(2, 5 * n_ansatz_layers), loc=0, scale=var)








.. GENERATED FROM PYTHON SOURCE LINES 809-820

.. note:: 

    To find out what effect so-called "non-Gaussian" gates like the 
    ``Kerr`` gate have, you need to install the 
    `strawberryfields plugin <https://pennylane-sf.readthedocs.io/en/latest/>`_ 
    and change the device to 

    .. code-block:: python

        dev_cv = qml.device('strawberryfields.fock', wires=1, cutoff_dim=50)


.. GENERATED FROM PYTHON SOURCE LINES 823-837

References
---------------

.. [#schuld2020] 

    Maria Schuld, Ryan Sweke, and Johannes Jakob Meyer. "The effect of data encoding on
    the expressive power of variational quantum machine learning models." 
    `arXiv:2008.08605 <https://arxiv.org/abs/2008.08605>`__ (2020).


About the authors
-----------------
.. include:: ../_static/authors/maria_schuld.txt

.. include:: ../_static/authors/johannes_jakob_meyer.txt


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 3 minutes  49.190 seconds)


.. _sphx_glr_download_demos_tutorial_expressivity_fourier_series.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tutorial_expressivity_fourier_series.py <tutorial_expressivity_fourier_series.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tutorial_expressivity_fourier_series.ipynb <tutorial_expressivity_fourier_series.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
