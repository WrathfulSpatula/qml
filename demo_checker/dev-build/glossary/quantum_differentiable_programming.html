
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Quantum Differentiable Programming &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/glossary/quantum_differentiable_programming.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Quantum Differentiable Programming &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/glossary/quantum_differentiable_programming.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quantum embedding" href="quantum_embedding.html" />
    <link rel="prev" title="Quantum Convolutional Neural Networks" href="qcnn.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="quantum_embedding.html" title="Quantum embedding"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="qcnn.html" title="Quantum Convolutional Neural Networks"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../glossary.html" accesskey="U">Key Concepts</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum Differentiable Programming</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="section" id="quantum-differentiable-programming">
<span id="glossary-quantum-differentiable-programming"></span><h1>Quantum Differentiable Programming<a class="headerlink" href="#quantum-differentiable-programming" title="Permalink to this headline">¶</a></h1>
<p>In quantum computing, one can automatically compute the derivatives of
<a class="reference internal" href="variational_circuit.html"><span class="doc">variational circuits</span></a> with respect to
their input parameters. Quantum differentiable programming is a paradigm that
leverages this to make quantum algorithms differentiable, and thereby trainable.</p>
<p>Classical <a class="reference external" href="https://en.wikipedia.org/wiki/Differentiable_programming">differentiable programming</a> is a style of
programming that uses <a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> to compute the
derivatives of functions with respect to program inputs.  Differentiable
programming is closely related to deep learning, but has some conceptual
differences. In many early deep learning frameworks, the structure of models
such as neural networks, such as the number of nodes and hidden layers, is
defined statically. This is know as a “define-and-run” approach. The network is
differentiable and trained using automatic differentiation and backpropagation,
but the fundamental structure of the program doesn’t change.</p>
<p>In contrast, more recent approaches use a “define-by-run” scheme, in which there
is no underlying assumption to how the model is structured. The models are
composed of parameterized function blocks, and the structure is dynamic—it may
change depending on the input data, yet still remains trainable and
differentiable.  A critical aspect of this is that it holds true even in the
presence of classical control flow such as for loops and if statements. These
ideas allow us to use diffentiable programming in hybrid classical-quantum
computations and make the entire program differentiable end-to-end.</p>
<div class="figure align-center" id="id2">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/hybrid_graph1.png" src="../_images/hybrid_graph1.png" style="width: 90%;" /></a>
<p class="caption"><span class="caption-text">In quantum differentiable programming, hybrid computations consisting of
both classical (yellow) and quantum (blue) components are automatically
differentiable.</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="types-of-differentiation-in-programming">
<h2>Types of differentiation in programming<a class="headerlink" href="#types-of-differentiation-in-programming" title="Permalink to this headline">¶</a></h2>
<p>Derivatives and gradients are ubiquitous throughout science and engineering.  In
recent years, automatic differentiation has become a key feature in many
numerical software libraries, in particular for machine learning (e.g., <a class="reference external" href="https://github.com/Theano/Theano">Theano</a>,
<a class="reference external" href="https://github.com/HIPS/autograd">Autograd</a>, <a class="reference external" href="http://tensorflow.org/">Tensorflow</a>, <a class="reference external" href="https://pytorch.org/">Pytorch</a>, or <a class="reference external" href="https://github.com/google/jax">Jax</a>).</p>
<p>Generally speaking, automatic differentiation is the ability for a software
library to compute the derivatives of arbitrary numerical code. To better
understand how it works and what the benefits are, it is instructive to analyze
two other forms of differentiation that are used in software: symbolic
differentation, and numerical differentiation.</p>
<div class="section" id="symbolic-differentation">
<h3>Symbolic differentation<a class="headerlink" href="#symbolic-differentation" title="Permalink to this headline">¶</a></h3>
<p>This method of differentiation is one you may be familiar with from calculus
class. Symbolic differentiation manipulates expressions directly to determine
the mathematical form of the gradient. Both the input and output of the
procedure are mathematical expressions. For example, consider the function
<span class="math notranslate nohighlight">\(\sin(x)\)</span>. Symbolic differentiation produces</p>
<div class="math notranslate nohighlight">
\[\frac{d(\sin(x))}{dx} = \cos(x)\]</div>
<p>Computer algebra systems such as Mathematica perform symbolic differentiation
— if you ask it for the derivative of <span class="math notranslate nohighlight">\(\sin(x)\)</span>, it will return to you
explicitly the function <span class="math notranslate nohighlight">\(\cos(x)\)</span>, and not a numerical value. Under the
hood, a set of differentiation rules are implemented and followed. This includes
things like how to differentiate constants, polynomials, sums, and chain rules,
as well as derivatives of common functions (e.g., trigonometric functions). This
is a very powerful tool because once the set of rules is implemented, we can
symbolically differentiate arbitrary functions that are encompassed by
them. However the scope of this method can be limited since it requires
“hand-written” support for new functions. Further, symbolic differentiation suffers from
the same drawbacks we might recall from high school; sometimes, the pathway towards
an analytic solution may be intensely convoluted.</p>
</div>
<div class="section" id="numerical-differentiation">
<h3>Numerical differentiation<a class="headerlink" href="#numerical-differentiation" title="Permalink to this headline">¶</a></h3>
<p>Symbolic differentation may not be always be possible when a function falls
outside the set of implementated rules. It may also be very computationally
complex. An alternative in these situations is to compute an approximation to
the derivative numerically — this is something that can <em>always</em> be
done. There exist <a class="reference external" href="https://en.wikipedia.org/wiki/Numerical_differentiation">a variety of such numerical methods</a>, a common one being
the finite difference method. For this method the derivative is computed by
evaluating the function at two infinitesimally separated points. For example, we
can approximately compute the derivative of <span class="math notranslate nohighlight">\(\sin(x)\)</span> as follows:</p>
<div class="math notranslate nohighlight">
\[\frac{d(\sin(x))}{dx} \approx \frac{\sin(x + \epsilon) - \sin(x - \epsilon)}{2\epsilon}\]</div>
<p>The quality of this approximation depends on the size of <span class="math notranslate nohighlight">\(\epsilon\)</span>. A
smaller <span class="math notranslate nohighlight">\(\epsilon\)</span> is ideal, however this can quickly cause a calculation
to become unstable and can introduce floating point errors. So while numerical
differentiation is always possible, it does not necessarily produce the best
results for the problem at hand.</p>
</div>
<div class="section" id="id1">
<h3>Automatic differentiation<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>If you write an algorithm to compute some function <span class="math notranslate nohighlight">\(f(x, y)\)</span> (which may
include mathematical expressions, but also control flow statements like
<code class="code docutils literal notranslate"><span class="pre">if</span></code>, <code class="code docutils literal notranslate"><span class="pre">for</span></code>, etc.), then automatic differentiation provides an
algorithm for computing <span class="math notranslate nohighlight">\(\nabla f(x, y)\)</span>.</p>
<p>Automatic differentiation is a numerical approach, but what distinguishes it
from methods like finite differences is that it is an <em>exact</em> method of
differentiation. In a similar vein as symbolic differentiation, each component
of the computation provides a rule for its derivative with respect to its
inputs. However, instead of the input and output both being mathematical
expressions, the output of automatic differentiation is the numerical value of
the derivative.</p>
<p>To perform automatic differentiation, functions are first translated into
computational graphs in terms of elementary operations that have known
derivatives, such as addition and multiplication.</p>
<p><span class="html"><br></span></p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/autodiff_classical.png" src="../_images/autodiff_classical.png" style="width: 30%;" /></a>
</div>
<p><span class="html"><br></span></p>
<p>Computational graphs like this highlight the dependencies between all the
parameters. To perform differentiation with respect to a particular input
parameter, each node will contain information that contributes to the derivative
at that point in the graph. These are then combined and propagated through using
the chain rule and the differentiation rules specific to every operation. For
example, nodes that perform addition and multiplication compute derivatives using
the following rules:</p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/autodiff_rules.svg" src="../_images/autodiff_rules.svg" width="90%" /></a>
</div>
<p><span class="html"><br></span></p>
<p>The computational graph below shows the process for differentiating the function
<span class="math notranslate nohighlight">\(f(x, y) = xy + (x + y)\)</span> with respect to <span class="math notranslate nohighlight">\(x\)</span> at the point
<span class="math notranslate nohighlight">\((x, y) = (2, 3)\)</span>. Symbolically we can compute that <span class="math notranslate nohighlight">\(\frac{\partial
f}{\partial x} = y + 1\)</span>, which gives a gradient of 4. Using automatic
differentiation, the derivative with respect to <span class="math notranslate nohighlight">\(x\)</span> is numerically
computed using the rules in the previous figure for each step of the
calculation, and propagated through to produce the final result.</p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/autodiff.gif" src="../_images/autodiff.gif" style="width: 100%;" /></a>
</div>
<p><span class="html"><br></span></p>
<p>From this example, you can see that the computation can be arbitrarily extended
to include more nodes and variables, and different elementary operations
(provided their derivatives are known). When there is classical control flow,
such as an <code class="code docutils literal notranslate"><span class="pre">if</span></code> statement, the computational graph branches and
gradients are only computed in the branch where the criteria is satisfied.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The method of computing the gradient shown in the animation is a type of
“forward-mode” autodifferentiation, since the values of the gradient are
computed in the same direction of the computation. In forward-mode, the
complexity of autodifferentiating a function <span class="math notranslate nohighlight">\(f : R^m \rightarrow R\)</span>
scales with the number of parameters of the function, <span class="math notranslate nohighlight">\(m\)</span>. There are
also “backwards”, or “reverse-mode” methods, a famous one being the
<a class="reference external" href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> used for
training neural networks. In reverse-mode autodifferentiation, the gradient
can be computed with the same degree of complexity as the original function,
regardless of the number of parameters (albeit with some additional memory
overhead).</p>
</div>
</div>
</div>
<div class="section" id="automatic-differentiation-of-quantum-computations">
<h2>Automatic differentiation of quantum computations<a class="headerlink" href="#automatic-differentiation-of-quantum-computations" title="Permalink to this headline">¶</a></h2>
<p>The ability to compute <a class="reference internal" href="quantum_gradient.html"><span class="doc">quantum gradients</span></a>
means that quantum computations can become part of automatically differentiable
<a class="reference internal" href="hybrid_computation.html"><span class="doc">hybrid computation</span></a> pipelines. For example,
in PennyLane parameterized quantum operations carry information about their
parameters and specify a “recipe” that details how to automatically compute
gradients.</p>
<p><span class="html"><br></span></p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/autodiff_quantum_circuit.svg" src="../_images/autodiff_quantum_circuit.svg" width="60%" /></a>
</div>
<p><span class="html"><br></span></p>
<p>Many quantum operations make use of <a class="reference internal" href="parameter_shift.html"><span class="doc">parameter-shift rules</span></a> for this purpose. Parameter-shift rules are an
example of forward-mode autodifferentiation, and bear some resemblance to the
finite difference method presented above. They involve expressing the gradient
of a function as some combination of that function at two different
points. However, unlike in the finite difference methods, those two points are
not infinitesimally close together, but rather quite far apart. For example,</p>
<div class="math notranslate nohighlight">
\[\frac{d(\sin(x))}{dx} = \cos(x) = \frac{\sin(x + s) - \sin(x-s)}{2 \sin(s)}\]</div>
<p>where <span class="math notranslate nohighlight">\(s\)</span> is a large value, such as <span class="math notranslate nohighlight">\(\pi/2\)</span>. The formula here comes
from trigonometric identities relating <span class="math notranslate nohighlight">\(\cos\)</span> and <span class="math notranslate nohighlight">\(\sin\)</span>. This not only
provides us with an <em>exact</em> derivative, but also handles the issue of instability in
finite differences that occurs when we must use a small shift.</p>
<p>This can be extended directly to the gradients of quantum operations and entire
quantum circuits (see, for example, the arbitrary unitary rotation
<a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Rot.html#pennylane.Rot" title="(in PennyLane v0.30)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Rot</span></code></a> which uses parameter-shift rules to compute the
derivative with respect to each of its three parameters). We simply evaluate the
circuit at two different points in parameter space. In this way, the gradient of
arbitrary sequences of parameterized gates can be computed. Once evaluated the
gradients can be fed forward into subsequent parts of a larger hybrid
computation.</p>
<p><span class="html"><br></span></p>
<div class="figure align-center">
<a class="reference external image-reference" href="javascript:void(0);"><img alt="../_images/autodiff_quantum.png" src="../_images/autodiff_quantum.png" style="width: 30%;" /></a>
</div>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">glossary/quantum_differentiable_programming</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Quantum Differentiable Programming</a><ul class='current'>
<li class='current'><a class="reference internal" href="#types-of-differentiation-in-programming">Types of differentiation in programming</a><ul class='current'>
<li class='current'><a class="reference internal" href="#symbolic-differentation">Symbolic differentation</a></li>
<li class='current'><a class="reference internal" href="#numerical-differentiation">Numerical differentiation</a></li>
<li class='current'><a class="reference internal" href="#id1">Automatic differentiation</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#automatic-differentiation-of-quantum-computations">Automatic differentiation of quantum computations</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">glossary/quantum_differentiable_programming</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../glossary.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="quantum_embedding.html" title="Quantum embedding"
             >next</a> |</li>
        <li class="right" >
          <a href="qcnn.html" title="Quantum Convolutional Neural Networks"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../glossary.html" >Key Concepts</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Quantum Differentiable Programming</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>