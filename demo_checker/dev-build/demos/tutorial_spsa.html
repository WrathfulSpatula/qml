
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Use the simultaneous perturbation stochastic approximation algorithm to optimize variational circuits in PennyLane." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/spsa_mntn.png" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Optimization using SPSA &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_spsa.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Use the simultaneous perturbation stochastic approximation algorithm to optimize variational circuits in PennyLane." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Optimization using SPSA &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_spsa.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Generalized parameter-shift rules" href="tutorial_general_parshift.html" />
    <link rel="prev" title="Alleviating barren plateaus with local cost functions" href="tutorial_local_cost_functions.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_general_parshift.html" title="Generalized parameter-shift rules"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_local_cost_functions.html" title="Alleviating barren plateaus with local cost functions"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_optimization.html" accesskey="U">Optimization</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Optimization using SPSA</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-demos-tutorial-spsa-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="optimization-using-spsa">
<span id="spsa"></span><span id="sphx-glr-demos-tutorial-spsa-py"></span><h1>Optimization using SPSA<a class="headerlink" href="#optimization-using-spsa" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_vqe.html", "tutorial_vqe_qng.html", "qnspsa.html"];
    var related_tutorials_titles = ['A brief overview of VQE', 'Accelerating VQEs with quantum natural gradient', 'Quantum natural SPSA optimizer'];
</script></p>
<p><em>Authors: Antal Szava &amp; David Wierichs — Posted: 19 March 2021. Last updated: 23 February 2023.</em></p>
<p>In this tutorial, we investigate using a stochastic optimizer called
the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm to optimize quantum
circuits. This optimizer is built into PennyLane as <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="(in PennyLane v0.31)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SPSAOptimizer</span></code></a>.
SPSA is a technique that involves approximating the gradient of a
quantum circuit without having to compute it exactly.</p>
<p>This demonstration shows how the SPSA optimizer performs on the following tasks,
compared to a gradient descent optimization:</p>
<ol class="arabic simple">
<li><p>A simple task on a sampling device,</p></li>
<li><p>The variational quantum eigensolver on a simulated hardware device.</p></li>
</ol>
<p>Throughout the demo, we show results obtained with SPSA and with gradient
descent and also compare the number of executed circuits required to complete
each optimization.</p>
<div class="section" id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this headline">¶</a></h2>
<p>In PennyLane, quantum gradients on hardware are commonly computed using
<a class="reference external" href="https://pennylane.ai/qml/glossary/parameter_shift.html">parameter-shift rules</a>.
Computing quantum gradients involves evaluating the partial derivative of the quantum
function with respect to every free parameter. These partial derivatives are then used
to apply the chain rule to compute the gradient of the quantum circuit. For qubit
operations that are generated by one of the Pauli matrices, each partial
derivative computation will involve two quantum circuit evaluations with a
positive and a negative shift in the parameter values.</p>
<p>As there are two circuit evaluations for each free parameter, the number of
overall quantum circuit executions for computing a quantum gradient can be expected
to scale as <span class="math notranslate nohighlight">\(O(p)\)</span>  with the number of free parameters <span class="math notranslate nohighlight">\(p\)</span>.
This scaling can be very costly for optimization tasks with many
free parameters. For the overall optimization this scaling means we need
<span class="math notranslate nohighlight">\(O(pn)\)</span> quantum circuit evaluations, where <span class="math notranslate nohighlight">\(n\)</span> is the number of
optimization steps taken.</p>
<p>Fortunately, there are certain optimization techniques that offer an
alternative to computing the gradients of quantum circuits. One such technique
is called the Simultaneous Perturbation Stochastic Approximation (SPSA)
algorithm <a class="footnote-reference brackets" href="#spall-overview" id="id1">1</a>. SPSA is an optimization method that involves
<em>approximating</em> the gradient of the cost function at each iteration step. This
technique requires only two quantum circuit executions per iteration step,
regardless of the number of free parameters. Therefore the overall number of
circuit executions would be <span class="math notranslate nohighlight">\(O(n')\)</span> where <span class="math notranslate nohighlight">\(n'\)</span> is the number of
optimization steps taken when using SPSA. This technique is also considered
robust against noise, making it a great optimization method in the NISQ era.</p>
<p>In this demo, you’ll learn how the SPSA algorithm works, and how to apply it in
PennyLane to compute gradients of quantum circuits. You’ll also see it in action
using noisy quantum data!</p>
</div>
<div class="section" id="simultaneous-perturbation-stochastic-approximation-spsa">
<h2>Simultaneous perturbation stochastic approximation (SPSA)<a class="headerlink" href="#simultaneous-perturbation-stochastic-approximation-spsa" title="Permalink to this headline">¶</a></h2>
<p>SPSA is a general method for minimizing differentiable multivariate functions.
It is particularly useful for functions for which evaluating the gradient is not
possible, or too resource intensive. SPSA provides a stochastic method for
approximating the gradient of the cost function. To
accomplish this, the cost function is evaluated twice using perturbed parameter
vectors: every component of the original parameter vector is simultaneously
shifted with a randomly generated value. This is in contrast to
finite-differences methods where for each evaluation only one component of the
parameter vector is shifted at a time.</p>
<p>Similar to gradient-based approaches such as gradient descent, SPSA is an
iterative optimization algorithm. Let’s consider a differentiable cost function
<span class="math notranslate nohighlight">\(L(\theta)\)</span> where <span class="math notranslate nohighlight">\(\theta\)</span> is a <span class="math notranslate nohighlight">\(p\)</span>-dimensional vector and
where the optimization problem can be translated into finding a optimal
parameter setting <span class="math notranslate nohighlight">\(\theta^*\)</span>
at which <span class="math notranslate nohighlight">\(\frac{\partial L}{\partial \theta} = 0\)</span>.  It is assumed that
measurements of <span class="math notranslate nohighlight">\(L(\theta)\)</span> are available at various values of
<span class="math notranslate nohighlight">\(\theta\)</span>—this is exactly the problem that we’d consider when optimizing
quantum functions!</p>
<p>SPSA starts with an initial parameter vector <span class="math notranslate nohighlight">\(\hat{\theta}_{0}\)</span>.
Its update rule is very similar to the one of standard gradient descent:</p>
<div class="math notranslate nohighlight">
\[\hat{\theta}_{k+1} = \hat{\theta}_{k} - a_{k}\hat{g}_{k}(\hat{\theta}_{k}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{g}_{k}\)</span> is the stochastic estimate of the gradient
<span class="math notranslate nohighlight">\(g(\theta) = \frac{ \partial L}{\partial \theta}\)</span>
at the iterate <span class="math notranslate nohighlight">\(\hat{\theta}_{k}\)</span>
based on prior measurements of the cost function, and <span class="math notranslate nohighlight">\(a_{k}\)</span> is a
positive number <a class="footnote-reference brackets" href="#spall-overview" id="id2">1</a>.</p>
<p>One of the advantages of SPSA is that it is robust to noise that may occur
when measuring the function <span class="math notranslate nohighlight">\(L\)</span>. Therefore, let’s consider the function
<span class="math notranslate nohighlight">\(y(\theta)=L(\theta) + \varepsilon\)</span>, where <span class="math notranslate nohighlight">\(\varepsilon\)</span> is some
perturbation of the output. In SPSA, the estimated gradient at each iteration
step is expressed as</p>
<div class="math notranslate nohighlight">
\[\hat{g}_{ki} (\hat{\theta}_{k}) = \frac{y(\hat{\theta}_{k} +c_{k}\Delta_{k})
- y(\hat{\theta}_{k} -c_{k}\Delta_{k})}{2c_{k}\Delta_{ki}},\]</div>
<p>where <span class="math notranslate nohighlight">\(c_{k}\)</span> is a positive number and <span class="math notranslate nohighlight">\(\Delta_{k} = (\Delta_{k_1},
\Delta_{k_2}, ..., \Delta_{k_p})^{T}\)</span> is a perturbation vector. The
stochasticity of the technique comes from the fact that for each iteration step
<span class="math notranslate nohighlight">\(k\)</span> the components of the <span class="math notranslate nohighlight">\(\Delta_{k}\)</span> perturbation vector are
randomly generated using a zero-mean distribution. In most cases, the Rademacher
distribution is used, meaning each parameter is simultaneously perturbed by
either <span class="math notranslate nohighlight">\(\pm c_k\)</span>.</p>
<p>It is this perturbation that makes SPSA robust to noise — since every
parameter is already being shifted, additional shifts due to noise are less
likely to hinder the optimization process. In a sense, noise gets “absorbed”
into the already-stochastic process. This is highlighted in the figure below,
which portrays an example of the type of path SPSA takes through the space of
the function, compared to a standard gradient-based optimizer.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/spsa_mntn.png"><img alt="../_images/spsa_mntn.png" src="../_images/spsa_mntn.png" style="width: 60%;" /></a>
<div class="legend">
<p>A schematic of the search paths used by gradient descent with
parameter-shift and SPSA.</p>
</div>
</div>
<p>Now that we have explored how SPSA works, let’s see how it performs in practice!</p>
</div>
<div class="section" id="optimization-on-a-sampling-device">
<h2>Optimization on a sampling device<a class="headerlink" href="#optimization-on-a-sampling-device" title="Permalink to this headline">¶</a></h2>
<p>First, let’s consider a simple quantum circuit on a sampling device. For this,
we’ll be using a device from the <a class="reference external" href="https://pennylaneqiskit.readthedocs.io/en/latest/">PennyLane-Qiskit plugin</a> that samples quantum
circuits to get measurement outcomes and later post-processes these outcomes to
compute statistics like expectation values.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Just as with other PennyLane device, the number of samples taken for a circuit
execution can be specified using the <code class="docutils literal notranslate"><span class="pre">shots</span></code> keyword argument of the
device.</p>
</div>
<p>Once we have a device selected, we just need a couple of other ingredients for
the pieces of an example optimization to come together:</p>
<ul class="simple">
<li><p>a circuit ansatz: <code class="xref py py-func docutils literal notranslate"><span class="pre">StronglyEntanglingLayers()</span></code>,</p></li>
<li><p>initial parameters: the correct shape can be computed by the <code class="docutils literal notranslate"><span class="pre">shape</span></code> method of the ansatz.
We also use a seed so that we can simulate the same optimization every time
(except for the device noise and shot noise).</p></li>
<li><p>an observable: <span class="math notranslate nohighlight">\(\bigotimes_{i=0}^{N-1}\sigma_z^i\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> stands
for the number of qubits.</p></li>
<li><p>the number of layers in the ansatz and the number of wires.
We choose five layers and four wires.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">num_wires</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">device</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;qiskit.aer&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">num_wires</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">ansatz</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.StronglyEntanglingLayers.html#pennylane.StronglyEntanglingLayers" title="pennylane.StronglyEntanglingLayers" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">StronglyEntanglingLayers</span></a>

<span class="n">all_pauliz_tensor_prod</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.prod.html#pennylane.prod" title="pennylane.prod" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">prod</span></a><span class="p">(</span><span class="o">*</span><span class="p">[</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliZ.html#pennylane.PauliZ" title="pennylane.PauliZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span></a><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_wires</span><span class="p">)])</span>


<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
    <span class="n">ansatz</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_wires</span><span class="p">)))</span>
    <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><span class="n">all_pauliz_tensor_prod</span><span class="p">)</span>


<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">QNode</span></a><span class="p">(</span><span class="n">circuit</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

<span class="n">param_shape</span> <span class="o">=</span> <span class="n">ansatz</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">num_wires</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">param_shape</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>We will execute a few optimizations in this demo, so let’s prepare a convenience
function that runs an optimizer instance and records the cost values
along the way. Together with the number of executed circuits, this will be an
interesting quantity to evaluate the optimization cost on hardware!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_optimizer</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">interval</span><span class="p">,</span> <span class="n">execs_per_step</span><span class="p">):</span>
    <span class="c1"># Copy the initial parameters to make sure they are never overwritten</span>
    <span class="n">param</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># Obtain the device used in the cost function</span>
    <span class="n">dev</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="o">.</span><span class="n">device</span>

    <span class="c1"># Initialize the memory for cost values during the optimization</span>
    <span class="n">cost_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Monitor the initial cost value</span>
    <span class="n">cost_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">(</span><span class="n">param</span><span class="p">))</span>
    <span class="n">exec_history</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Running the </span><span class="si">{</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> optimizer for </span><span class="si">{</span><span class="n">num_steps</span><span class="si">}</span><span class="s2"> iterations.&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>
        <span class="c1"># Print out the status of the optimization</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">step</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">: Circuit executions: </span><span class="si">{</span><span class="n">exec_history</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Cost = </span><span class="si">{</span><span class="n">cost_history</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Perform an update step</span>
        <span class="n">param</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer.step" title="pennylane.SPSAOptimizer.step" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-method"><span class="n">opt</span><span class="o">.</span><span class="n">step</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">,</span> <span class="n">param</span><span class="p">)</span>

        <span class="c1"># Monitor the cost value</span>
        <span class="n">cost_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">(</span><span class="n">param</span><span class="p">))</span>
        <span class="n">exec_history</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">execs_per_step</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Step </span><span class="si">{</span><span class="n">num_steps</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">: Circuit executions: </span><span class="si">{</span><span class="n">exec_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Cost = </span><span class="si">{</span><span class="n">cost_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">cost_history</span><span class="p">,</span> <span class="n">exec_history</span>
</pre></div>
</div>
<p>Once we have defined each piece of the optimization, there’s only one
remaining component required: the <em>SPSA optimizer</em>.
We’ll use the <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="(in PennyLane v0.31)"><code class="xref py py-class docutils literal notranslate"><span class="pre">SPSAOptimizer</span></code></a> built into PennyLane,
for 200 iterations in total.</p>
<div class="section" id="choosing-the-hyperparameters">
<h3>Choosing the hyperparameters<a class="headerlink" href="#choosing-the-hyperparameters" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">SPSAOptimizer</span></code> allows us to choose the initial value of two
hyperparameters for SPSA: the <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(a\)</span> coefficients. Recall
from above that the <span class="math notranslate nohighlight">\(c\)</span> values control the scale of the random shifts when
evaluating the cost function, while the <span class="math notranslate nohighlight">\(a\)</span> coefficient is analogous to a
learning rate and affects the rate at which the parameters change at each update
step.</p>
<p>With stochastic approximation, specifying such hyperparameters significantly
influences the convergence of the optimization for a given problem. Although
there is no universal recipe for selecting these values (as they depend
strongly on the specific problem), <a class="footnote-reference brackets" href="#spall-implementation" id="id3">2</a> includes
guidelines for the selection. In our case, the initial values for <span class="math notranslate nohighlight">\(c\)</span>
and <span class="math notranslate nohighlight">\(a\)</span> were selected as a result of a grid search to ensure a fast
convergence.  We further note that apart from <span class="math notranslate nohighlight">\(c\)</span> and <span class="math notranslate nohighlight">\(a\)</span>, there
are further coefficients that are initialized in the <code class="docutils literal notranslate"><span class="pre">SPSAOptimizer</span></code>
using the previously mentioned guidelines. For more details, also consider the
<a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html">PennyLane documentation of the optimizer</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_steps_spsa</span> <span class="o">=</span> <span class="mi">200</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">SPSAOptimizer</span></a><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">num_steps_spsa</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="c1"># We spend 2 circuit evaluations per step:</span>
<span class="n">execs_per_step</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">cost_history_spsa</span><span class="p">,</span> <span class="n">exec_history_spsa</span> <span class="o">=</span> <span class="n">run_optimizer</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a><span class="p">,</span> <span class="n">num_steps_spsa</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">execs_per_step</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Running the SPSAOptimizer optimizer for 200 iterations.
Step   0: Circuit executions:    0, Cost = 0.904
Step  20: Circuit executions:   40, Cost = 0.244
Step  40: Circuit executions:   80, Cost = -0.692
Step  60: Circuit executions:  120, Cost = -0.902
Step  80: Circuit executions:  160, Cost = -0.96
Step 100: Circuit executions:  200, Cost = -0.958
Step 120: Circuit executions:  240, Cost = -0.976
Step 140: Circuit executions:  280, Cost = -0.99
Step 160: Circuit executions:  320, Cost = -0.992
Step 180: Circuit executions:  360, Cost = -0.988
Step 200: Circuit executions:  400, Cost = -0.994
</pre></div>
</div>
<p>Now let’s perform the same optimization using gradient descent. We set the
step size according to a favourable value found after grid search for fast
convergence.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_steps_grad</span> <span class="o">=</span> <span class="mi">15</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.GradientDescentOptimizer.html#pennylane.GradientDescentOptimizer" title="pennylane.GradientDescentOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span></a><span class="p">(</span><span class="n">stepsize</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="c1"># We spend 2 circuit evaluations per parameter per step:</span>
<span class="n">execs_per_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span>
<span class="n">cost_history_grad</span><span class="p">,</span> <span class="n">exec_history_grad</span> <span class="o">=</span> <span class="n">run_optimizer</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a><span class="p">,</span> <span class="n">num_steps_grad</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">execs_per_step</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Running the GradientDescentOptimizer optimizer for 15 iterations.
Step   0: Circuit executions:    0, Cost = 0.912
Step   3: Circuit executions:  360, Cost = -0.372
Step   6: Circuit executions:  720, Cost = -0.988
Step   9: Circuit executions: 1080, Cost = -0.996
Step  12: Circuit executions: 1440, Cost = -0.996
Step  15: Circuit executions: 1800, Cost = -0.996
</pre></div>
</div>
</div>
<div class="section" id="spsa-and-gradient-descent-comparison">
<h3>SPSA and gradient descent comparison<a class="headerlink" href="#spsa-and-gradient-descent-comparison" title="Permalink to this headline">¶</a></h3>
<p>At this point, nothing else remains but to check which of these approaches did better!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exec_history_grad</span><span class="p">,</span> <span class="n">cost_history_grad</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gradient descent&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exec_history_spsa</span><span class="p">,</span> <span class="n">cost_history_spsa</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;SPSA&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Circuit executions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Cost function value&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Gradient descent vs. SPSA for simple optimization&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_spsa_001.png" srcset="../_images/sphx_glr_tutorial_spsa_001.png" alt="Gradient descent vs. SPSA for simple optimization" class = "sphx-glr-single-img"/><p>It seems that SPSA performs great and it does so with significant savings when
compared to gradient descent!</p>
<p>Let’s take a deeper dive to see how much better it actually is by computing
the ratio of required circuit executions to reach an absolute accuracy of 0.01.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grad_execs_to_prec</span> <span class="o">=</span> <span class="n">exec_history_grad</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cost_history_grad</span><span class="p">)</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.99</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">spsa_execs_to_prec</span> <span class="o">=</span> <span class="n">exec_history_spsa</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">cost_history_spsa</span><span class="p">)</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.99</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Circuit execution ratio: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">grad_execs_to_prec</span><span class="o">/</span><span class="n">spsa_execs_to_prec</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Circuit execution ratio: 3.684.
</pre></div>
</div>
<p>This means that SPSA found the minimum up to an absolute accuracy of 0.01 while
using multiple times fewer circuit executions than gradient descent! That’s an important
saving, especially when running the algorithm on actual quantum hardware.</p>
</div>
</div>
<div class="section" id="spsa-and-the-variational-quantum-eigensolver">
<h2>SPSA and the variational quantum eigensolver<a class="headerlink" href="#spsa-and-the-variational-quantum-eigensolver" title="Permalink to this headline">¶</a></h2>
<p>Now that we’ve explored the theoretical underpinnings of SPSA and its use for a
toy problem optimization, let’s use it
to optimize a real chemical system, namely that of the hydrogen molecule <span class="math notranslate nohighlight">\(H_2\)</span>.
This molecule was studied previously in the <a class="reference internal" href="tutorial_vqe.html"><span class="doc">introductory variational quantum
eigensolver (VQE) demo</span></a>, and so we will reuse some of
that machinery below to set up the problem.</p>
<p>The <span class="math notranslate nohighlight">\(H_2\)</span> Hamiltonian uses 4 qubits, contains 15 terms, and has a ground
state energy of <span class="math notranslate nohighlight">\(-1.136189454088\)</span> Hartree.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">qchem</span>

<span class="n">symbols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">,</span> <span class="s2">&quot;H&quot;</span><span class="p">]</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">coordinates</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6614</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6614</span><span class="p">])</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hamiltonian.html#pennylane.Hamiltonian" title="pennylane.Hamiltonian" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">h2_ham</span></a><span class="p">,</span> <span class="n">num_qubits</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.qchem.molecular_hamiltonian.html#pennylane.qchem.molecular_hamiltonian" title="pennylane.qchem.molecular_hamiltonian" class="sphx-glr-backref-module-pennylane-qchem sphx-glr-backref-type-py-function"><span class="n">qchem</span><span class="o">.</span><span class="n">molecular_hamiltonian</span></a><span class="p">(</span><span class="n">symbols</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">coordinates</span></a><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hamiltonian.html#pennylane.Hamiltonian" title="pennylane.Hamiltonian" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">h2_ham</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hamiltonian.html#pennylane.Hamiltonian" title="pennylane.Hamiltonian" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Hamiltonian</span></a><span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hamiltonian.html#pennylane.Hamiltonian.coeffs" title="pennylane.Hamiltonian.coeffs" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-attribute"><span class="n">h2_ham</span><span class="o">.</span><span class="n">coeffs</span></a><span class="p">),</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hamiltonian.html#pennylane.Hamiltonian.ops" title="pennylane.Hamiltonian.ops" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-attribute"><span class="n">h2_ham</span><span class="o">.</span><span class="n">ops</span></a><span class="p">)</span>

<span class="n">true_energy</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.136189454088</span>


<span class="c1"># Variational ansatz for H_2 - see Intro VQE demo for more details</span>
<span class="k">def</span> <span class="nf">ansatz</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">wires</span><span class="p">):</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.BasisState.html#pennylane.BasisState" title="pennylane.BasisState" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">BasisState</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="n">wires</span><span class="o">=</span><span class="n">wires</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">wires</span><span class="p">:</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Rot.html#pennylane.Rot" title="pennylane.Rot" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Rot</span></a><span class="p">(</span><span class="o">*</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.CNOT.html#pennylane.CNOT" title="pennylane.CNOT" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">CNOT</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">wires</span><span class="p">:</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Rot.html#pennylane.Rot" title="pennylane.Rot" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Rot</span></a><span class="p">(</span><span class="o">*</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p>Since SPSA is robust to noise, let’s see how it fares compared to gradient
descent when run on noisy hardware. For this, we will set up and use a simulated
version of IBM Q’s hardware.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note: you will need to be authenticated to IBMQ to run the following (commented) code.</span>
<span class="c1"># Do not run the simulation on this device, as it will send it to real hardware</span>
<span class="c1"># For access to IBMQ, the following statements will be useful:</span>
<span class="c1"># from qiskit_ibm_provider import IBMProvider</span>
<span class="c1"># IBMProvider.save_account(&quot;MY_API_TOKEN&quot;)  # Save your IBMQ account to disk</span>
<span class="c1"># The above line only needs to be run once.</span>
<span class="c1"># List the providers to pick an available backend:</span>
<span class="c1"># IBMProvider().backends()  # List all available backends</span>
<span class="c1"># dev = qml.device(&quot;qiskit.ibmq&quot;, wires=num_qubits, backend=&quot;ibmq_lima&quot;)</span>

<span class="kn">from</span> <span class="nn">qiskit.providers.aer</span> <span class="kn">import</span> <span class="n">noise</span>
<span class="kn">from</span> <span class="nn">qiskit.providers.fake_provider</span> <span class="kn">import</span> <span class="n">FakeLima</span>

<span class="c1"># Load a fake backed to create a noise model, and create a device using that model</span>
<span class="n">noise_model</span> <span class="o">=</span> <span class="n">noise</span><span class="o">.</span><span class="n">NoiseModel</span><span class="o">.</span><span class="n">from_backend</span><span class="p">(</span><span class="n">FakeLima</span><span class="p">())</span>
<span class="n">noisy_device</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span>
    <span class="s2">&quot;qiskit.aer&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">num_qubits</span><span class="p">,</span> <span class="n">shots</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">noise_model</span><span class="o">=</span><span class="n">noise_model</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
    <span class="n">ansatz</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_qubits</span><span class="p">))</span>
    <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hamiltonian.html#pennylane.Hamiltonian" title="pennylane.Hamiltonian" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">h2_ham</span></a><span class="p">)</span>


<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">QNode</span></a><span class="p">(</span><span class="n">circuit</span><span class="p">,</span> <span class="n">noisy_device</span><span class="p">)</span>

<span class="c1"># This random seed was used in the original VQE demo and is known to allow the</span>
<span class="c1"># gradient descent algorithm to converge to the global minimum.</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">param_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_qubits</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">param_shape</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Initialize the optimizer - optimal step size was found through a grid search</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.GradientDescentOptimizer.html#pennylane.GradientDescentOptimizer" title="pennylane.GradientDescentOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span></a><span class="p">(</span><span class="n">stepsize</span><span class="o">=</span><span class="mf">2.2</span><span class="p">)</span>

<span class="c1"># We spend 2 * 15 circuit evaluations per parameter per step, as there are</span>
<span class="c1"># 15 Hamiltonian terms</span>
<span class="n">execs_per_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">15</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">param_shape</span><span class="p">)</span>
<span class="c1"># Run the optimization</span>
<span class="n">cost_history_grad</span><span class="p">,</span> <span class="n">exec_history_grad</span> <span class="o">=</span> <span class="n">run_optimizer</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a><span class="p">,</span> <span class="n">num_steps_grad</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">execs_per_step</span>
<span class="p">)</span>

<span class="n">final_energy</span> <span class="o">=</span> <span class="n">cost_history_grad</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final estimated value of the ground state energy = </span><span class="si">{</span><span class="n">final_energy</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2"> Ha&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Distance to the true ground state energy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">final_energy</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">true_energy</span><span class="p">)</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2"> Ha&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Running the GradientDescentOptimizer optimizer for 15 iterations.
Step   0: Circuit executions:    0, Cost = 0.3664768792575718
Step   3: Circuit executions: 2160, Cost = -0.4669618514568279
Step   6: Circuit executions: 4320, Cost = -0.8870435197035554
Step   9: Circuit executions: 6480, Cost = -1.0381869657341456
Step  12: Circuit executions: 8640, Cost = -1.0502921226550823
Step  15: Circuit executions: 10800, Cost = -1.0443536127959978

Final estimated value of the ground state energy = -1.04435361 Ha
Distance to the true ground state energy: 0.09183584 Ha
</pre></div>
</div>
<p>What does the optimization with gradient descent look like? Let’s plot
the energy during optimization and compare it to the exact ground state
energy of the molecule:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exec_history_grad</span><span class="p">,</span> <span class="n">cost_history_grad</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gradient descent&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Circuit executions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Energy (Ha)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">true_energy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True energy&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;H2 energy from VQE with gradient descent&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_spsa_002.png" srcset="../_images/sphx_glr_tutorial_spsa_002.png" alt="H2 energy from VQE with gradient descent" class = "sphx-glr-single-img"/><p>On noisy hardware, the energy never quite reaches its true value, no matter
how many iterations are used. This is due to the noise as well as the stochastic
nature of quantum measurements and the way they are realized on hardware.
The simulator of the noisy quantum device allows us to observe these features.</p>
<div class="section" id="vqe-with-spsa">
<h3>VQE with SPSA<a class="headerlink" href="#vqe-with-spsa" title="Permalink to this headline">¶</a></h3>
<p>Now let’s perform the same experiment using SPSA for the VQE optimization.
SPSA should use only 2 circuit executions per term in the expectation value.
Since there are 15 terms and we choose 160 iterations with two evaluations for
each gradient estimate, we expect 4800 total device
executions.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_steps_spsa</span> <span class="o">=</span> <span class="mi">160</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">SPSAOptimizer</span></a><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">num_steps_spsa</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

<span class="c1"># We spend 2 * 15 circuit evaluations per step, as there are 15 Hamiltonian terms</span>
<span class="n">execs_per_step</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">15</span>
<span class="c1"># Run the optimization</span>
<span class="n">cost_history_spsa</span><span class="p">,</span> <span class="n">exec_history_spsa</span> <span class="o">=</span> <span class="n">run_optimizer</span><span class="p">(</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.SPSAOptimizer.html#pennylane.SPSAOptimizer" title="pennylane.SPSAOptimizer" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">cost_function</span></a><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.numpy.tensor.html#pennylane.numpy.tensor" title="pennylane.numpy.tensor" class="sphx-glr-backref-module-pennylane-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">init_param</span></a><span class="p">,</span> <span class="n">num_steps_spsa</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">execs_per_step</span>
<span class="p">)</span>
<span class="n">final_energy</span> <span class="o">=</span> <span class="n">cost_history_spsa</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Final estimated value of the ground state energy = </span><span class="si">{</span><span class="n">final_energy</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2"> Ha&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Distance to the true ground state energy: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">final_energy</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">true_energy</span><span class="p">)</span><span class="si">:</span><span class="s2">.8f</span><span class="si">}</span><span class="s2"> Ha&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Running the SPSAOptimizer optimizer for 160 iterations.
Step   0: Circuit executions:    0, Cost = 0.34019591285097295
Step  20: Circuit executions:  600, Cost = -0.1703862674962844
Step  40: Circuit executions: 1200, Cost = -0.6211721258484846
Step  60: Circuit executions: 1800, Cost = -0.8519931004133263
Step  80: Circuit executions: 2400, Cost = -1.0100901164911944
Step 100: Circuit executions: 3000, Cost = -1.0428442945242897
Step 120: Circuit executions: 3600, Cost = -1.0421343654512758
Step 140: Circuit executions: 4200, Cost = -1.0523318631197824
Step 160: Circuit executions: 4800, Cost = -1.0646967042854922

Final estimated value of the ground state energy = -1.06469670 Ha
Distance to the true ground state energy: 0.07149275 Ha
</pre></div>
</div>
<p>The SPSA optimization seems to have found a similar energy value.
We again take a look at how the optimization curves compare, in particular
with respect to the circuit executions spent on the task.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exec_history_grad</span><span class="p">,</span> <span class="n">cost_history_grad</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gradient descent&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exec_history_spsa</span><span class="p">,</span> <span class="n">cost_history_spsa</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;SPSA&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">true_energy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True energy&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;$H_2$ energy from VQE using gradient descent vs. SPSA&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Circuit executions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Energy (Ha)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_spsa_003.png" srcset="../_images/sphx_glr_tutorial_spsa_003.png" alt="$H_2$ energy from VQE using gradient descent vs. SPSA" class = "sphx-glr-single-img"/><p>We observe here that the SPSA optimizer again converges in fewer device
executions than the gradient descent optimizer. 🎉</p>
<p>Due to the (simulated) hardware noise, however, the obtained energies are
higher than the true ground state energy.
In addition, the output still bounces around, which is due to shot noise
and the inherently stochastic nature of SPSA.</p>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>SPSA is a useful optimization technique that may be particularly beneficial on
near-term quantum hardware. It uses significantly fewer circuit executions to achieve
comparable results as gradient-based methods, giving it the potential
to save time and resources. It can be a good alternative to
gradient-based methods when the optimization problem involves executing
quantum circuits with many free parameters.</p>
<p>There are also extensions to SPSA that could be interesting to explore in
this context. One, in particular, uses an adaptive technique to approximate
the <em>Hessian</em> matrix during optimization to effectively increase the
convergence rate of SPSA <a class="footnote-reference brackets" href="#spall-hessian" id="id4">3</a>.</p>
<p>In addition, there is a proposal to use an SPSA variant of the quantum natural
gradient <a class="footnote-reference brackets" href="#qnspsa" id="id5">4</a>.
This is implemented in PennyLane as well and we discuss it in the
<a class="reference internal" href="qnspsa.html"><span class="doc">demo on QNSPSA</span></a>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="spall-overview"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>James C. Spall, “<a class="reference external" href="https://www.jhuapl.edu/SPSA/PDF-SPSA/Spall_An_Overview.PDF">An Overview of the Simultaneous Perturbation Method for Efficient
Optimization</a>”, 1998</p>
</dd>
<dt class="label" id="spall-implementation"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>J. C. Spall, “Implementation of the simultaneous perturbation algorithm
for stochastic optimization,” in IEEE Transactions on Aerospace and
Electronic Systems, vol. 34, no. 3, pp. 817-823, July 1998, doi:
10.1109/7.705889.</p>
</dd>
<dt class="label" id="spall-hessian"><span class="brackets"><a class="fn-backref" href="#id4">3</a></span></dt>
<dd><p>J. C. Spall, “Adaptive stochastic approximation by the simultaneous
perturbation method,” in IEEE Transactions on Automatic Control,
vol. 45, no. 10, pp. 1839-1853, Oct 2020, doi:
10.1109/TAC.2000.880982.</p>
</dd>
<dt class="label" id="qnspsa"><span class="brackets"><a class="fn-backref" href="#id5">4</a></span></dt>
<dd><p>J. Gacon, C. Zoufal, G. Carleo, and S. Woerner “Simultaneous Perturbation
Stochastic Approximation of the Quantum Fisher Information”,
<a class="reference external" href="https://quantum-journal.org/papers/q-2021-10-20-567/">Quantum, 5, 567</a>, Oct 2021</p>
</dd>
</dl>
</div>
<div class="section" id="about-the-author">
<h2>About the author<a class="headerlink" href="#about-the-author" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/antal_szava.jpg" alt="Antal Szava" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Antal Szava</h4>
        <p class="bio-text__author-description">Antal is a senior quantum software developer at Xanadu working on PennyLane. In his spare time he enjoys watching TV shows, being active outside with friends and learning about acting.</p>
    </div>
</div><div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/david_wierichs.jpg" alt="David Wierichs" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">David Wierichs</h4>
        <p class="bio-text__author-description">David is a researcher and quantum software developer at Xanadu, who likes to think about quantum gradients and how to use them in variational quantum algorithms. He enjoys sharing ideas in science and open source software and likes implementing cool stuff in PennyLane.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 12 minutes  48.873 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-spsa-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/ef008f09949efabdb1faac88aad8a113/tutorial_spsa.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_spsa.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/36803f134067a8baf1a5e83dc746fd83/tutorial_spsa.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_spsa.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_spsa</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Optimization using SPSA</a><ul class='current'>
<li class='current'><a class="reference internal" href="#background">Background</a></li>
<li class='current'><a class="reference internal" href="#simultaneous-perturbation-stochastic-approximation-spsa">Simultaneous perturbation stochastic approximation (SPSA)</a></li>
<li class='current'><a class="reference internal" href="#optimization-on-a-sampling-device">Optimization on a sampling device</a><ul class='current'>
<li class='current'><a class="reference internal" href="#choosing-the-hyperparameters">Choosing the hyperparameters</a></li>
<li class='current'><a class="reference internal" href="#spsa-and-gradient-descent-comparison">SPSA and gradient descent comparison</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#spsa-and-the-variational-quantum-eigensolver">SPSA and the variational quantum eigensolver</a><ul class='current'>
<li class='current'><a class="reference internal" href="#vqe-with-spsa">VQE with SPSA</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-author">About the author</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_spsa</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_optimization.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_general_parshift.html" title="Generalized parameter-shift rules"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_local_cost_functions.html" title="Alleviating barren plateaus with local cost functions"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_optimization.html" >Optimization</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Optimization using SPSA</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>