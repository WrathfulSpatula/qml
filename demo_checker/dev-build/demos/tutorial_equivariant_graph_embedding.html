
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Find out more about how to embedd graphs into quantum states." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/thumbnail_tutorial_equivariant_graph_embedding.png" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="An equivariant graph embedding &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_equivariant_graph_embedding.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Find out more about how to embedd graphs into quantum states." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>An equivariant graph embedding &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_equivariant_graph_embedding.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Quantum Computing" href="../demos_quantum-computing.html" />
    <link rel="prev" title="Quantum detection of time series anomalies" href="tutorial_univariate_qvr.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../demos_quantum-computing.html" title="Quantum Computing"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tutorial_univariate_qvr.html" title="Quantum detection of time series anomalies"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_qml.html" accesskey="U">Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">An equivariant graph embedding</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-demos-tutorial-equivariant-graph-embedding-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="an-equivariant-graph-embedding">
<span id="sphx-glr-demos-tutorial-equivariant-graph-embedding-py"></span><h1>An equivariant graph embedding<a class="headerlink" href="#an-equivariant-graph-embedding" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_geometric_qml.html"];
    var related_tutorials_titles = ['Geometric quantum machine learning'];
</script></p>
<p>A notorious problem when data comes in the form of graphs – think of molecules or social media
networks – is that the numerical representation of a graph in a computer is not unique.
For example, if we describe a graph via an <a class="reference external" href="https://en.wikipedia.org/wiki/Adjacency_matrix">adjacency matrix</a> whose
entries contain the edge weights as off-diagonals and node weights on the diagonal,
any simultaneous permutation of rows and columns of this matrix refer to the same graph.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/adjacency-matrices.png"><img alt="adjacency-matrices" src="../_images/adjacency-matrices.png" style="width: 60%;" /></a>
</div>
<p>For example, the graph in the image above is represented by each of the two equivalent adjacency matrices.
The top matrix can be transformed into the bottom matrix
by swapping the first row with the third row, then swapping the third column with the third column, then the
new first row with the second, and finally the first colum with the second.</p>
<p>But the number of such permutations grows factorially with the number of nodes in the graph, which
is even worse than an exponential growth!</p>
<p>If we want computers to learn from graph data, we usually want our models to “know” that all these
permuted adjacency matrices refer to the same object, so we do not waste resources on learning
this property. In mathematical terms, this means that the model should be in- or
equivariant (more about this distinction below) with respect to permutations.
This is the basic motivation of <a class="reference external" href="https://geometricdeeplearning.com/">Geometric Deep Learning</a>,
ideas of which have found their way into quantum machine learning.</p>
<p>This tutorial shows how to implement an example of a trainable permutation equivariant graph embedding
as proposed in <a class="reference external" href="https://arxiv.org/pdf/2205.06109.pdf">Skolik et al. (2022)</a>. The embedding
maps the adjacency matrix of an undirected graph with edge and node weights to a quantum state, such that
permutations of an adjacency matrix get mapped to the same states <em>if only we also
permute the qubit registers in the same fashion</em>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The tutorial is meant for beginners and does not contain the mathematical details of the
rich theory of equivariance. Have a look
<a class="reference external" href="https://pennylane.ai/qml/demos/tutorial_geometric_qml.html">at this demo</a> if you want to know more.</p>
</div>
<div class="section" id="permuted-adjacency-matrices-describe-the-same-graph">
<h2>Permuted adjacency matrices describe the same graph<a class="headerlink" href="#permuted-adjacency-matrices-describe-the-same-graph" title="Permalink to this headline">¶</a></h2>
<p>Let us first verify that permuted adjacency matrices really describe one and the same graph.
We also gain some useful data generation functions for later.</p>
<p>First we create random adjacency matrices.
The entry <span class="math notranslate nohighlight">\(a_{ij}\)</span> of this matrix corresponds to the weight of the edge between nodes
<span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> in the graph. We assume that graphs have no self-loops; instead,
the diagonal elements of the adjacency matrix are interpreted as node weights (or
“node attributes”).</p>
<p>Taking the example of a Twitter user retweet network, the nodes would be users,
edge weights indicate how often two users retweet each other and node attributes
could indicate the follower count of a user.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">create_data_point</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a random undirected adjacency matrix of dimension (n,n).</span>
<span class="sd">    The diagonal elements are interpreted as node attributes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">A</span> <span class="o">=</span> <span class="p">(</span><span class="n">mat</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">mat</span><span class="p">))</span><span class="o">/</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">create_data_point</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[[0.4  0.72 0.05]
 [0.72 0.13 0.67]
 [0.05 0.67 0.31]]
</pre></div>
</div>
<p>Let’s also write a function to generate permuted versions of this adjacency matrix.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">permute</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">permutation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a copy of A with rows and columns swapped according to permutation.</span>
<span class="sd">    For example, the permutation [1, 2, 0] swaps 0-&gt;1, 1-&gt;2, 2-&gt;0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">permutation</span><span class="p">):</span>
        <span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">P</span> <span class="o">@</span> <span class="n">A</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>

<span class="n">A_perm</span> <span class="o">=</span> <span class="n">permute</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A_perm</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[[0.13 0.67 0.72]
 [0.67 0.31 0.05]
 [0.72 0.05 0.4 ]]
</pre></div>
</div>
<p>If we create <cite>networkx</cite> graphs from both adjacency matrices and plot them,
we see that they are identical as claimed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># interpret diagonal of matrix as node attributes</span>
<span class="n">node_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">))}</span>
<span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>

<span class="n">G1</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">pos1</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G1</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G1</span><span class="p">,</span> <span class="n">pos1</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">node_labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span> <span class="n">node_color</span> <span class="o">=</span> <span class="s2">&quot;#ACE3FF&quot;</span><span class="p">)</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_edge_attributes</span><span class="p">(</span><span class="n">G1</span><span class="p">,</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edge_labels</span><span class="p">(</span><span class="n">G1</span><span class="p">,</span><span class="n">pos1</span><span class="p">,</span><span class="n">edge_labels</span><span class="o">=</span><span class="n">edge_labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>

<span class="c1"># interpret diagonal of permuted matrix as node attributes</span>
<span class="n">node_labels</span> <span class="o">=</span> <span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">A_perm</span><span class="p">[</span><span class="n">n</span><span class="p">,</span><span class="n">n</span><span class="p">]</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A_perm</span><span class="p">))}</span>
<span class="n">np</span><span class="o">.</span><span class="n">fill_diagonal</span><span class="p">(</span><span class="n">A_perm</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)))</span>

<span class="n">G2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="n">A_perm</span><span class="p">)</span>
<span class="n">pos2</span><span class="o">=</span><span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">G2</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G2</span><span class="p">,</span> <span class="n">pos2</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">node_labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">,</span> <span class="n">node_size</span> <span class="o">=</span> <span class="mi">800</span><span class="p">,</span> <span class="n">node_color</span> <span class="o">=</span> <span class="s2">&quot;#ACE3FF&quot;</span><span class="p">)</span>
<span class="n">edge_labels</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">get_edge_attributes</span><span class="p">(</span><span class="n">G2</span><span class="p">,</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx_edge_labels</span><span class="p">(</span><span class="n">G2</span><span class="p">,</span><span class="n">pos2</span><span class="p">,</span><span class="n">edge_labels</span><span class="o">=</span><span class="n">edge_labels</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax2</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mf">1.2</span><span class="o">*</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ax1</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="mf">1.2</span><span class="o">*</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ax2</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_equivariant_graph_embedding_001.png" srcset="../_images/sphx_glr_tutorial_equivariant_graph_embedding_001.png" alt="tutorial equivariant graph embedding" class = "sphx-glr-single-img"/><div class="admonition note">
<p class="admonition-title">Note</p>
<p>The issue of non-unique numerical representations of graphs ultimately stems
from the fact that the nodes in a graph
do not have an intrinsic order, and by labelling them in a numerical data structure like a matrix
we therefore impose an arbitrary order.</p>
</div>
</div>
<div class="section" id="permutation-equivariant-embeddings">
<h2>Permutation equivariant embeddings<a class="headerlink" href="#permutation-equivariant-embeddings" title="Permalink to this headline">¶</a></h2>
<p>When we design a machine learning model that takes graph data, the first step is to encode
the adjacency matrix into a quantum state using an embedding or
<a class="reference external" href="https://pennylane.ai/qml/glossary/quantum_feature_map.html">quantum feature map</a>
<span class="math notranslate nohighlight">\(\phi\)</span>:</p>
<div class="math notranslate nohighlight">
\[A \rightarrow |\phi(A)\rangle .\]</div>
<p>We may want the resulting quantum state to be the same for all adjacency matrices describing
the same graph. In mathematical terms, this means that <span class="math notranslate nohighlight">\(\phi\)</span> is an <em>invariant</em> embedding with respect to
simultaneous row and column permutations <span class="math notranslate nohighlight">\(\pi(A)\)</span> of the adjacency matrix:</p>
<div class="math notranslate nohighlight">
\[|\phi(A) \rangle = |\phi(\pi(A))\rangle \;\; \text{ for all } \pi .\]</div>
<p>However, invariance is often too strong a constraint. Think for example of an encoding that
associates each node in the graph with a qubit. We might want permutations of the adjacency
matrix to lead to the same state <em>up to an equivalent permutation of the qubits</em> <span class="math notranslate nohighlight">\(P_{\pi}\)</span>,
where</p>
<div class="math notranslate nohighlight">
\[P_{\pi} |q_1,...,q_n \rangle = |q_{\textit{perm}_{\pi}(1)}, ... q_{\textit{perm}_{\pi}(n)} \rangle .\]</div>
<p>The function <span class="math notranslate nohighlight">\(\text{perm}_{\pi}\)</span> maps each index to the permuted index according to <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The operator <span class="math notranslate nohighlight">\(P_{\pi}\)</span> is implemented by PennyLane’s <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Permute.html#pennylane.Permute" title="(in PennyLane v0.31)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Permute</span></code></a>.</p>
</div>
<p>This results in an <em>equivariant</em> embedding with respect to permutations of the adjacency matrix:</p>
<div class="math notranslate nohighlight">
\[|\phi(A) \rangle = P_{\pi}|\phi(\pi(A))\rangle \;\; \text{ for all } \pi .\]</div>
<p>This is exactly what the following quantum embedding is aiming to do! The mathematical details
behind these concepts use group theory and are beautiful, but can be a bit daunting.
Have a look at <a class="reference external" href="https://arxiv.org/abs/2210.08566">this paper</a> if you want to learn more.</p>
</div>
<div class="section" id="implementation-in-pennylane">
<h2>Implementation in PennyLane<a class="headerlink" href="#implementation-in-pennylane" title="Permalink to this headline">¶</a></h2>
<p>Let’s get our hands dirty with an example. As mentioned, we will implement the permutation-equivariant
embedding suggested in <a class="reference external" href="https://arxiv.org/pdf/2205.06109.pdf">Skolik et al. (2022)</a> which has this structure:</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/circuit1.png"><img alt="Equivariant embedding" src="../_images/circuit1.png" style="width: 70%;" /></a>
</div>
<p>The image can be found in <a class="reference external" href="https://arxiv.org/pdf/2205.06109.pdf">Skolik et al. (2022)</a> and shows one layer of the circuit.
The <span class="math notranslate nohighlight">\(\epsilon\)</span> are our edge weights while <span class="math notranslate nohighlight">\(\alpha\)</span> describe the node weights, and the <span class="math notranslate nohighlight">\(\beta\)</span>, <span class="math notranslate nohighlight">\(\gamma\)</span> are variational parameters.</p>
<p>In PennyLane this looks as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>

<span class="k">def</span> <span class="nf">perm_equivariant_embedding</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">gammas</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Ansatz to embedd a graph with node and edge weights into a quantum state.</span>

<span class="sd">    The adjacency matrix A contains the edge weights on the off-diagonal,</span>
<span class="sd">    as well as the node attributes on the diagonal.</span>

<span class="sd">    The embedding contains trainable weights &#39;betas&#39; and &#39;gammas&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">betas</span><span class="p">)</span> <span class="c1"># infer the number of layers from the parameters</span>

    <span class="c1"># initialise in the plus state</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Hadamard.html#pennylane.Hadamard" title="pennylane.Hadamard" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span></a><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
                    <span class="c1"># factor of 2 due to definition of gate</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.IsingZZ.html#pennylane.IsingZZ" title="pennylane.IsingZZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">IsingZZ</span></a><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">gammas</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">*</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">):</span>
            <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.RX.html#pennylane.RX" title="pennylane.RX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">RX</span></a><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">betas</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p>We can use this ansatz in a circuit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_qubits</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">dev</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;lightning.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">n_qubits</span><span class="p">)</span>

<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">eqc</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable</span></a><span class="p">,</span> <span class="n">trainable_betas</span><span class="p">,</span> <span class="n">trainable_gammas</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Circuit that uses the permutation equivariant embedding&quot;&quot;&quot;</span>

    <span class="n">perm_equivariant_embedding</span><span class="p">(</span><span class="n">adjacency_matrix</span><span class="p">,</span> <span class="n">trainable_betas</span><span class="p">,</span> <span class="n">trainable_gammas</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.expval.html#pennylane.expval" title="pennylane.expval" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">expval</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable</span></a><span class="p">)</span>


<span class="n">A</span> <span class="o">=</span> <span class="n">create_data_point</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">)</span>
<span class="n">betas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
<span class="n">gammas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_layers</span><span class="p">)</span>
<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">@</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">@</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.draw_mpl.html#pennylane.draw_mpl" title="pennylane.draw_mpl" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">draw_mpl</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eqc</span></a><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">A</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable</span></a><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">gammas</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_equivariant_graph_embedding_002.png" srcset="../_images/sphx_glr_tutorial_equivariant_graph_embedding_002.png" alt="tutorial equivariant graph embedding" class = "sphx-glr-single-img"/></div>
<div class="section" id="validating-the-equivariance">
<h2>Validating the equivariance<a class="headerlink" href="#validating-the-equivariance" title="Permalink to this headline">¶</a></h2>
<p>Let’s now check if the circuit is really equivariant!</p>
<p>This is the expectation value we get using the original adjacency matrix as an input:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">result_A</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eqc</span></a><span class="p">(</span><span class="n">A</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable</span></a><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">gammas</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model output for A:&quot;</span><span class="p">,</span> <span class="n">result_A</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Model output for A: 0.24607026921467134
</pre></div>
</div>
<p>If we permute the adjacency matrix, this is what we get:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">A_perm</span> <span class="o">=</span> <span class="n">permute</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>
<span class="n">result_Aperm</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eqc</span></a><span class="p">(</span><span class="n">A_perm</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable</span></a><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">gammas</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model output for permutation of A: &quot;</span><span class="p">,</span> <span class="n">result_Aperm</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Model output for permutation of A:  0.06350319616680997
</pre></div>
</div>
<p>Why are the two values different? Well, we constructed an <em>equivariant</em> ansatz,
not an <em>invariant</em> one! Remember, an <em>invariant</em> ansatz means that embedding a permutation of
the adjacency matrix leads to the same state as an embedding of the original matrix.
An <em>equivariant</em> ansatz embeds the permuted adjacency matrix into a state where the qubits
are permuted as well.</p>
<p>As a result, the final state before measurement is only the same if we
permute the qubits in the same manner that we permute the input adjacency matrix. We could insert a
permutation operator <code class="docutils literal notranslate"><span class="pre">qml.Permute(perm)</span></code> to achieve this, or we simply permute the wires
of the observables!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable_perm</span></a> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="n">perm</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">@</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="n">perm</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">@</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.PauliX.html#pennylane.PauliX" title="pennylane.PauliX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span></a><span class="p">(</span><span class="n">perm</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
</div>
<p>Now everything should work out!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">result_Aperm</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eqc</span></a><span class="p">(</span><span class="n">A_perm</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.operation.Tensor.html#pennylane.operation.Tensor" title="pennylane.operation.Tensor" class="sphx-glr-backref-module-pennylane-operation sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">observable_perm</span></a><span class="p">,</span> <span class="n">betas</span><span class="p">,</span> <span class="n">gammas</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model output for permutation of A, and with permuted observable: &quot;</span><span class="p">,</span> <span class="n">result_Aperm</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Model output for permutation of A, and with permuted observable:  0.24607026921467126
</pre></div>
</div>
<p>Et voilà!</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>Equivariant graph embeddings can be combined with other equivariant parts of a quantum machine learning pipeline
(like measurements and the cost function). <a class="reference external" href="https://arxiv.org/pdf/2205.06109.pdf">Skolik et al. (2022)</a>,
for example, use such a pipeline as part of a reinforcement learning scheme that finds heuristic solutions for the
traveling salesman problem. Their simulations compare a fully equivariant model to circuits that break
permutation equivariance and show that it performs better, confirming that if we know
about structure in our data, we should try to use this knowledge in machine learning.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Andrea Skolik, Michele Cattelan, Sheir Yarkoni,Thomas Baeck and Vedran Dunjko (2022).
Equivariant quantum circuits for learning on weighted graphs.
<a class="reference external" href="https://arxiv.org/abs/2205.06109">arXiv:2205.06109</a></p></li>
<li><p>Quynh T. Nguyen, Louis Schatzki, Paolo Braccia, Michael Ragone,
Patrick J. Coles, Frédéric Sauvage, Martín Larocca and Marco Cerezo (2022).
Theory for Equivariant Quantum Neural Networks.
<a class="reference external" href="https://arxiv.org/abs/2210.08566">arXiv:2210.08566</a></p></li>
</ol>
</div>
<div class="section" id="about-the-author">
<h2>About the author<a class="headerlink" href="#about-the-author" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/maria_schuld.jpg" alt="Maria Schuld" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Maria Schuld</h4>
        <p class="bio-text__author-description">Maria leads Xanadu's quantum machine learning team and is a seasoned PennyLane developer.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.479 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-equivariant-graph-embedding-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e3a7457a1e882b92785fad49013fe2a4/tutorial_equivariant_graph_embedding.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_equivariant_graph_embedding.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/74c8c5dc8028bbeac2f111f038216d3b/tutorial_equivariant_graph_embedding.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_equivariant_graph_embedding.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_equivariant_graph_embedding</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">An equivariant graph embedding</a><ul class='current'>
<li class='current'><a class="reference internal" href="#permuted-adjacency-matrices-describe-the-same-graph">Permuted adjacency matrices describe the same graph</a></li>
<li class='current'><a class="reference internal" href="#permutation-equivariant-embeddings">Permutation equivariant embeddings</a></li>
<li class='current'><a class="reference internal" href="#implementation-in-pennylane">Implementation in PennyLane</a></li>
<li class='current'><a class="reference internal" href="#validating-the-equivariance">Validating the equivariance</a></li>
<li class='current'><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-author">About the author</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_equivariant_graph_embedding</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_qml.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../demos_quantum-computing.html" title="Quantum Computing"
             >next</a> |</li>
        <li class="right" >
          <a href="tutorial_univariate_qvr.html" title="Quantum detection of time series anomalies"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demos_qml.html" >Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">An equivariant graph embedding</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>