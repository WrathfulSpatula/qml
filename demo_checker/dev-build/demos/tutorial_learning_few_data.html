
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta content="Generalization of quantum machine learning models." property="og:description" />
<meta content="https://pennylane.ai/qml/_images/few_data_thumbnail.png" property="og:image" />

  <link rel="icon" type="image/x-icon" href="../_static/favicon.ico">
  <link rel="shortcut icon" type="image/x-icon" href="../_static/favicon.ico">
  


  <meta property="og:title" content="Generalization in QML from few training data &#8212; PennyLane">
  <meta property="og:url" content="https://pennylane.ai/qml/demos/tutorial_learning_few_data.html">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary_large_image">

  
  
  <meta content="Generalization of quantum machine learning models." property="og:description" />
  

  <!-- Google Fonts -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto&display=swap">
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">
  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css">
  <!-- Material Design Bootstrap -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.5.14/css/mdb.min.css">
  <!-- NanoScroller -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/css/nanoscroller.min.css">
  <!-- Syntax Highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/tomorrow-night.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       "HTML-CSS": { scale: 90, linebreaks: { automatic: true } },
       TeX: {
         Macros: {
           pr : ['|\#1\\rangle\\langle\#1|',1],
           ket: ['\\left| \#1\\right\\rangle',1],
           bra: ['\\left\\langle \#1\\right|',1],
           xket: ['\\left| \#1\\right\\rangle_x',1],
           xbra: ['\\left\\langle \#1\\right|_x',1],
           braket: ['\\langle \#1 \\rangle',1],
           braketD: ['\\langle \#1 \\mid \#2 \\rangle',2],
           braketT: ['\\langle \#1 \\mid \#2 \\mid \#3 \\rangle',3],
           ketbra: ['| #1 \\rangle \\langle #2 |',2],
           hc: ['\\text{h.c.}',0],
           cc: ['\\text{c.c.}',0],
           h: ['\\hat',0],
           nn: ['\\nonumber',0],
           di: ['\\frac{d}{d \#1}',1],
           uu: ['\\mathcal{U}',0],
           inn: ['\\text{in}',0],
           out: ['\\text{out}',0],
           vac: ['\\text{vac}',0],
           I: ['\\hat{\\mathbf{1}}',0],
           x: ['\\hat{x}',0],
           p: ['\\hat{p}',0],
           a: ['\\hat{a}',0],
           ad: ['\\hat{a}^\\dagger',0],
           n: ['\\hat{n}',0],
           nbar: ['\\overline{n}',0],
           sech: ['\\mathrm{sech~}',0],
           tanh: ['\\mathrm{tanh~}',0],
           re: ['\\text{Re}',0],
           im: ['\\text{Im}',0],
           tr: ['\\mathrm{Tr} #1',1],
           sign: ['\\text{sign}',0],
           overlr: ['\\overset\\leftrightarrow{\#1}',1],
           overl: ['\\overset\leftarrow{\#1}',1],
           overr: ['\\overset\rightarrow{\#1}',1],
           avg: ['\\left< \#1 \\right>',1],
           slashed: ['\\cancel{\#1}',1],
           bold: ['\\boldsymbol{\#1}',1],
           d: ['\\mathrm d',0],
           expect: ["\\langle #1 \\rangle",1],
           pde: ["\\frac{\\partial}{\\partial \#1}",1],
           R: ["\\mathbb{R}",0],
           C: ["\\mathbb{C}",0],
           Ad: ["\\text{Ad}",0],
           Var: ["\\text{Var}",0],
           bx: ["\\mathbf{x}", 0],
           bm: ["\\boldsymbol{\#1}",1],
           haf: ["\\mathrm{haf}",0],
           lhaf: ["\\mathrm{lhaf}",0]
         }
       }
     });
     </script>

  <!-- Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-130507810-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-130507810-1');
      </script>
  
    <title>Generalization in QML from few training data &#8212; PennyLane  documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/xanadu.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/light-slider.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/hubs.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link rel="canonical" href="https://pennylane.ai/qml/demos/tutorial_learning_few_data.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction to Geometric Quantum Machine Learning" href="tutorial_geometric_qml.html" />
    <link rel="prev" title="Function Fitting using Quantum Signal Processing" href="function_fitting_qsp.html" /> 
  </head><body><nav class="navbar navbar-expand-lg navbar-light white sticky-top">

<!-- Logo and Title -->









  



  <a class="navbar-brand nav-link" href="https://pennylane.ai">
    
  <img class="pr-1" src=" ../_static/logo.png" width="28px"></img>
  
    <img id="navbar-wordmark" src="../_static/pennylane.svg"></img>
  
  </a>


  <!-- [Mobile] Collapse Button -->
  <div class="row right">
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#basicExampleNav"
      aria-controls="basicExampleNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>

  <!-- [Mobile] Collapsible Content -->
  <div class="collapse navbar-collapse" id="basicExampleNav">

    <!-- Links on the Left -->
    <ul class="navbar-nav mr-auto">
      
        
          
            <li class="nav-item active">
              <a class="nav-link" href="https://pennylane.ai/qml/">
                
  
    Learn
  

              </a>
              <span class="sr-only">(current)</span>
            </li>
          

        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/qml/demonstrations.html">
                
  
    Demos
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/install.html">
                
  
    Install
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/plugins.html">
                
  
    Plugins
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://docs.pennylane.ai">
                
  
    Documentation
  

            </a>
          </li>
        
      
        
          <li class="nav-item">
            <a class="nav-link" href="https://pennylane.ai/blog/">
                
  
    Blog
  

            </a>
          </li>
        
      
    </ul>

    <!-- Links on the Right -->
    <ul class="navbar-nav ml-auto nav-flex-icons">
      
        <li class="nav-item">
          <a class="nav-link" href="https://pennylane.ai/faq.html">
            <i class="fas fa-question pr-1"></i> FAQ
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://discuss.pennylane.ai/">
            <i class="fab fa-discourse pr-1"></i> Support
          </a>
        </li>
      
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PennyLaneAI/pennylane">
            <i class="fab fa-github pr-1"></i> GitHub
          </a>
        </li>
      

    </ul>
  </div>

</nav>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="tutorial_geometric_qml.html" title="Introduction to Geometric Quantum Machine Learning"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="function_fitting_qsp.html" title="Function Fitting using Quantum Signal Processing"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_qml.html" accesskey="U">Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Generalization in QML from few training data</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">
        <div id="content">
          <div id="right-column">
            
            

            <div class="document clearer body">
              
    <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-demos-tutorial-learning-few-data-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="generalization-in-qml-from-few-training-data">
<span id="learning-few-data"></span><span id="sphx-glr-demos-tutorial-learning-few-data-py"></span><h1>Generalization in QML from few training data<a class="headerlink" href="#generalization-in-qml-from-few-training-data" title="Permalink to this headline">¶</a></h1>
<p><script type="text/javascript">
    var related_tutorials = ["tutorial_local_cost_functions.html"];
    var related_tutorials_titles = ['Alleviating barren plateaus with local cost functions'];
</script></p>
<p><em>Authors: Korbinian Kottmann, Luis Mantilla Calderon, Maurice Weber — Posted: 29 August 2022</em></p>
<p>In this tutorial, we dive into the generalization capabilities of quantum machine learning models.
For the example of a <a class="reference external" href="https://pennylane.ai/qml/glossary/qcnn.html">Quantum Convolutional Neural Network (QCNN)</a>, we show how its generalization error behaves as a
function of the number of training samples. This demo is based on the paper
<em>“Generalization in quantum machine learning from few training data”</em>. by Caro et al. <a class="footnote-reference brackets" href="#carogeneralization" id="id1">1</a>.</p>
<div class="section" id="what-is-generalization-in-q-ml">
<h2>What is generalization in (Q)ML?<a class="headerlink" href="#what-is-generalization-in-q-ml" title="Permalink to this headline">¶</a></h2>
<p>When optimizing a machine learning model, be it classical or quantum, we aim to maximize its performance over the data
distribution of interest (e.g., images of cats and dogs). However, in practice, we are limited to a finite amount of
data, which is why it is necessary to reason about how our model performs on new, previously unseen data. The difference
between the model’s performance on the true data distribution and the performance estimated from our training data is
called the <em>generalization error</em>, and it indicates how well the model has learned to generalize to unseen data.
Generalization can be seen as a manifestation of the bias-variance trade-off; models that
perfectly fit the training data admit a low bias at the cost of a higher variance, and hence typically perform poorly on unseen
test data. In the classical machine learning community, this trade-off has been extensively
studied and has led to optimization techniques that favour generalization, for example, by regularizing models via
their variance <a class="footnote-reference brackets" href="#namkoongvariance" id="id2">3</a>.
Below, we see a canoncial example of this trade-off, with a model having low bias, but high variance
and therefore high generalization error. The low variance model, on the other hand, has a higher
bias but generalizes better.</p>
<div class="figure align-center">
<a class="reference internal image-reference" href="../_images/overfitting.png"><img alt="../_images/overfitting.png" src="../_images/overfitting.png" style="width: 65%;" /></a>
</div>
<p>Let us now dive deeper into generalization properties of quantum machine learning (QML) models. We start by describing
the typical data processing pipeline of a QML model. A classical data input <span class="math notranslate nohighlight">\(x\)</span> is first encoded in a quantum
state via a mapping <span class="math notranslate nohighlight">\(x \mapsto \rho(x)\)</span>. This encoded state is then processed through a quantum
channel <span class="math notranslate nohighlight">\(\rho(x) \mapsto \mathcal{E}_\alpha(\rho(x))\)</span> with learnable parameters <span class="math notranslate nohighlight">\(\alpha\)</span>. Finally, a measurement is performed on the resulting state
to get the final prediction. Now, the goal is to minimize the expected loss over the data-generating distribution
<span class="math notranslate nohighlight">\(P\)</span>, indicating how well our model performs on new data. Mathematically, for a loss function <span class="math notranslate nohighlight">\(\ell\)</span>, the
expected loss, denoted by <span class="math notranslate nohighlight">\(R\)</span>, is given by</p>
<div class="math notranslate nohighlight">
\[R(\alpha) = \mathbb{E}_{(x,y)\sim P}[\ell(\alpha;\,x,\,y)]\]</div>
<p>where <span class="math notranslate nohighlight">\(x\)</span> are the features, <span class="math notranslate nohighlight">\(y\)</span> are the labels, and <span class="math notranslate nohighlight">\(P\)</span> is their joint distribution.
In practice, as the joint distribution <span class="math notranslate nohighlight">\(P\)</span> is generally unknown, this quantity has to be
estimated from a finite amount of data. Given a training set <span class="math notranslate nohighlight">\(S = \{(x_i,\,y_i)\}_{i=1}^N\)</span>
with <span class="math notranslate nohighlight">\(N\)</span> samples, we estimate the performance of our QML model by calculating the
average loss over the training set</p>
<div class="math notranslate nohighlight">
\[R_S(\alpha) = \frac{1}{N}\sum_{i=1}^N \ell(\alpha;\,x_i,\,y_i),\]</div>
<p>which is referred to as the training loss and is an unbiased estimate of <span class="math notranslate nohighlight">\(R(\alpha)\)</span>. This is only a proxy
to the true quantity of interest <span class="math notranslate nohighlight">\(R(\alpha)\)</span>, and their difference is called the generalization error</p>
<div class="math notranslate nohighlight">
\[\mathrm{gen}(\alpha) =  R(\alpha) - \hat{R}_S(\alpha),\]</div>
<p>which is the quantity that we explore in this tutorial. Keeping in mind the bias-variance trade-off, one would expect
that more complex models, i.e. models with a larger number of parameters, achieve a lower error on the training data
but a higher generalization error. Having more training data, on the other hand, leads to a better approximation of the
true expected loss and hence a lower generalization error. This intuition is made precise in Ref. <a class="footnote-reference brackets" href="#carogeneralization" id="id3">1</a>,
where it is shown that <span class="math notranslate nohighlight">\(\mathrm{gen}(\alpha)\)</span> roughly scales as <span class="math notranslate nohighlight">\(\mathcal{O}(\sqrt{T / N})\)</span>, where <span class="math notranslate nohighlight">\(T\)</span>
is the number of parametrized gates and <span class="math notranslate nohighlight">\(N\)</span> is the number of training samples.</p>
<div class="section" id="generalization-bounds-for-qml-models">
<h3>Generalization bounds for QML models<a class="headerlink" href="#generalization-bounds-for-qml-models" title="Permalink to this headline">¶</a></h3>
<p>As hinted at earlier, we expect the generalization error to depend both on the richness of the model class, as well as
on the amount of training data available. As a first result, the authors of Ref. <a class="footnote-reference brackets" href="#carogeneralization" id="id4">1</a> found that for
a QML model with at most <span class="math notranslate nohighlight">\(T\)</span> parametrized local quantum channels, the generalization error depends on <span class="math notranslate nohighlight">\(T\)</span>
and <span class="math notranslate nohighlight">\(N\)</span> according to</p>
<div class="math notranslate nohighlight">
\[\mathrm{gen}(\alpha) \sim \mathcal{O}\left(\sqrt{\frac{T\log T}{N}}\right).\]</div>
<p>We see that this scaling is in line with our intuition that the generalization error scales inversely with the number
of training samples and increases with the number of parametrized gates. However, as is the case for
<a class="reference external" href="https://pennylane.ai/qml/glossary/qcnn.html">quantum convolutional neural networks (QCNNs)</a>, it is possible to get a more fine-grained bound by including knowledge on the number of gates <span class="math notranslate nohighlight">\(M\)</span> which have been reused (i.e. whose parameters are shared across wires). Naively, one could suspect that the generalization error scales as
<span class="math notranslate nohighlight">\(\tilde{\mathcal{O}}(\sqrt{MT/N})\)</span> by directly applying the above result (and where
<span class="math notranslate nohighlight">\(\tilde{\mathcal{O}}\)</span> includes logarithmic factors). However, the authors of Ref. <a class="footnote-reference brackets" href="#carogeneralization" id="id5">1</a> found
that such models actually adhere to the better scaling</p>
<div class="math notranslate nohighlight">
\[\mathrm{gen}(\alpha) \sim \mathcal{O}\left(\sqrt{\frac{T\log MT}{N}}\right).\]</div>
<p>With this, we see that for QCNNs to have a generalization error <span class="math notranslate nohighlight">\(\mathrm{gen}(\alpha)\leq\epsilon\)</span>, we need a
training set of size <span class="math notranslate nohighlight">\(N \sim T \log MT / \epsilon^2\)</span>. For the special case of QCNNs, we can explicitly connect
the number of samples needed for good generalization to the system size <span class="math notranslate nohighlight">\(n\)</span> since these models
use <span class="math notranslate nohighlight">\(\mathcal{O}(\log(n))\)</span> independently parametrized gates, each of which is used at most <span class="math notranslate nohighlight">\(n\)</span> times <a class="footnote-reference brackets" href="#congquantumcnn" id="id6">4</a>.
Putting the pieces together, we find that a training set of size</p>
<div class="math notranslate nohighlight">
\[N \sim \mathcal{O}(\mathrm{poly}(\log n))\]</div>
<p>is sufficient for the generalization error to be bounded by <span class="math notranslate nohighlight">\(\mathrm{gen}(\alpha) \leq \epsilon\)</span>.
In the next part of this tutorial, we will illustrate this result by implementing a QCNN to classify different
digits in the classical <code class="docutils literal notranslate"><span class="pre">digits</span></code> dataset. Before that, we set up our QCNN.</p>
</div>
</div>
<div class="section" id="quantum-convolutional-neural-networks">
<h2>Quantum convolutional neural networks<a class="headerlink" href="#quantum-convolutional-neural-networks" title="Permalink to this headline">¶</a></h2>
<p>Before we start building a QCNN, let us briefly review the idea of classical CNNs, which have shown
tremendous success in tasks like image recognition, recommender systems, and sound classification, to name a few.
For a more in-depth explanation of CNNs, we highly recommend <a class="reference external" href="https://www.deeplearningbook.org/contents/convnets.html">chapter 9</a>
in <a class="footnote-reference brackets" href="#dlbook" id="id7">2</a>.
Classical CNNs are a family of neural networks which make use of convolutions and pooling operations to
insert an inductive bias, favouring invariances to spatial transformations like translations, rotations, and scaling.
A <em>convolutional layer</em> consists of a small kernel (a window) that sweeps over a 2D array representation of an image and extracts local
information while sharing parameters across the spatial dimensions. In addition to the convolutional layers,
one typically uses pooling layers to reduce the size of the input and to provide a mechanism for summarizing
information from a neighbourhood of values in the input. On top of reducing dimensionality, these types of layers have the advantage
of making the model more agnostic to certain transformations like scaling and rotations.
These two types of layers are applied repeatedly in an alternating manner as shown in the figure below.</p>
<div class="figure align-center" id="id12">
<a class="reference internal image-reference" href="../_images/cnn_pic.png"><img alt="../_images/cnn_pic.png" src="../_images/cnn_pic.png" style="width: 75%;" /></a>
<p class="caption"><span class="caption-text">A graphical representation of a CNN. Obtained using Ref. <a class="footnote-reference brackets" href="#lenailnnsvg" id="id8">5</a>.</span><a class="headerlink" href="#id12" title="Permalink to this image">¶</a></p>
</div>
<p>We want to build something similar for a quantum circuit. First, we import the necessary
libraries we will need in this demo and set a random seed for reproducibility:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">jax</span><span class="p">;</span>

<span class="n">jax</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s1">&#39;jax_platform_name&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">jax</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;jax_enable_x64&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>

<span class="kn">import</span> <span class="nn">optax</span>  <span class="c1"># optimization using jax</span>

<span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">import</span> <span class="nn">pennylane.numpy</span> <span class="k">as</span> <span class="nn">pnp</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
<p>To construct a convolutional and pooling layer in a quantum circuit, we will
follow the QCNN construction proposed in <a class="footnote-reference brackets" href="#congquantumcnn" id="id9">4</a>. The former layer
will extract local correlations, while the latter allows reducing the dimensionality
of the feature vector. In a quantum circuit, the convolutional layer, consisting of a kernel swept
along the entire image, is a two-qubit unitary that correlates neighbouring
qubits.  As for the pooling layer, we will use a conditioned single-qubit unitary that depends
on the measurement of a neighboring qubit. Finally, we use a <em>dense layer</em> that entangles all
qubits of the final state using an all-to-all unitary gate as shown in the figure below.</p>
<div class="figure align-center" id="id13">
<a class="reference internal image-reference" href="../_images/qcnn-architecture.png"><img alt="../_images/qcnn-architecture.png" src="../_images/qcnn-architecture.png" style="width: 75%;" /></a>
<p class="caption"><span class="caption-text">QCNN architecture. Taken from Ref. <a class="footnote-reference brackets" href="#congquantumcnn" id="id10">4</a>.</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="breaking-down-the-layers">
<h2>Breaking down the layers<a class="headerlink" href="#breaking-down-the-layers" title="Permalink to this headline">¶</a></h2>
<p>The convolutional layer should have the weights of the two-qubit unitary as an input, which are
updated at every training step.  In PennyLane, we model this arbitrary two-qubit unitary
with a particular sequence of gates: two single-qubit  <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="(in PennyLane v0.30)"><code class="xref py py-class docutils literal notranslate"><span class="pre">U3</span></code></a> gates (parametrized by three
parameters, each), three Ising interactions between both qubits (each interaction is
parametrized by one parameter), and two additional <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="(in PennyLane v0.30)"><code class="xref py py-class docutils literal notranslate"><span class="pre">U3</span></code></a> gates on each of the two
qubits.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convolutional_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">wires</span><span class="p">,</span> <span class="n">skip_first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adds a convolutional layer to a circuit.</span>
<span class="sd">    Args:</span>
<span class="sd">        weights (np.array): 1D array with 15 weights of the parametrized gates.</span>
<span class="sd">        wires (list[int]): Wires where the convolutional layer acts on.</span>
<span class="sd">        skip_first_layer (bool): Skips the first two U3 gates of a layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_wires</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">wires</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">n_wires</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;this circuit is too small!&quot;</span>

    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">indx</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wires</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">indx</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="n">p</span> <span class="ow">and</span> <span class="n">indx</span> <span class="o">&lt;</span> <span class="n">n_wires</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">indx</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">skip_first_layer</span><span class="p">:</span>
                    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="pennylane.U3" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">U3</span></a><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">[:</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">w</span><span class="p">])</span>
                    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="pennylane.U3" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">U3</span></a><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">wires</span><span class="p">[</span><span class="n">indx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.IsingXX.html#pennylane.IsingXX" title="pennylane.IsingXX" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">IsingXX</span></a><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">wires</span><span class="p">[</span><span class="n">indx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.IsingYY.html#pennylane.IsingYY" title="pennylane.IsingYY" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">IsingYY</span></a><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">wires</span><span class="p">[</span><span class="n">indx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.IsingZZ.html#pennylane.IsingZZ" title="pennylane.IsingZZ" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">IsingZZ</span></a><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">wires</span><span class="p">[</span><span class="n">indx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="pennylane.U3" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">U3</span></a><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="mi">9</span><span class="p">:</span><span class="mi">12</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">w</span><span class="p">])</span>
                <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="pennylane.U3" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">U3</span></a><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="mi">12</span><span class="p">:],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="n">wires</span><span class="p">[</span><span class="n">indx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
</pre></div>
</div>
<p>The pooling layer’s inputs are the weights of the single-qubit conditional unitaries, which in
this case are <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="(in PennyLane v0.30)"><code class="xref py py-class docutils literal notranslate"><span class="pre">U3</span></code></a> gates. Then, we apply these conditional measurements to half of the
unmeasured wires, reducing our system size by a factor of 2.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pooling_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">wires</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adds a pooling layer to a circuit.</span>
<span class="sd">    Args:</span>
<span class="sd">        weights (np.array): Array with the weights of the conditional U3 gate.</span>
<span class="sd">        wires (list[int]): List of wires to apply the pooling layer on.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_wires</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">wires</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">wires</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;this circuit is too small!&quot;</span>

    <span class="k">for</span> <span class="n">indx</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wires</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">indx</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">indx</span> <span class="o">&lt;</span> <span class="n">n_wires</span><span class="p">:</span>
            <span class="n">m_outcome</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.measure.html#pennylane.measure" title="pennylane.measure" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">measure</span></a><span class="p">(</span><span class="n">w</span><span class="p">)</span>
            <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.cond.html#pennylane.cond" title="pennylane.cond" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">cond</span></a><span class="p">(</span><span class="n">m_outcome</span><span class="p">,</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.U3.html#pennylane.U3" title="pennylane.U3" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">U3</span></a><span class="p">)(</span><span class="o">*</span><span class="n">weights</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">wires</span><span class="p">[</span><span class="n">indx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>We can construct a QCNN by combining both layers and using an arbitrary unitary to model
a dense layer. It will take a set of features — the image — as input, encode these features using
an embedding map, apply rounds of convolutional and pooling layers, and eventually output the
desired measurement statistics of the circuit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv_and_pooling</span><span class="p">(</span><span class="n">kernel_weights</span><span class="p">,</span> <span class="n">n_wires</span><span class="p">,</span> <span class="n">skip_first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply both the convolutional and pooling layer.&quot;&quot;&quot;</span>
    <span class="n">convolutional_layer</span><span class="p">(</span><span class="n">kernel_weights</span><span class="p">[:</span><span class="mi">15</span><span class="p">],</span> <span class="n">n_wires</span><span class="p">,</span> <span class="n">skip_first_layer</span><span class="o">=</span><span class="n">skip_first_layer</span><span class="p">)</span>
    <span class="n">pooling_layer</span><span class="p">(</span><span class="n">kernel_weights</span><span class="p">[</span><span class="mi">15</span><span class="p">:],</span> <span class="n">n_wires</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">dense_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">wires</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply an arbitrary unitary gate to a specified set of wires.&quot;&quot;&quot;</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.ArbitraryUnitary.html#pennylane.ArbitraryUnitary" title="pennylane.ArbitraryUnitary" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">ArbitraryUnitary</span></a><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">wires</span><span class="p">)</span>


<span class="n">num_wires</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">device</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.device.html#pennylane.device" title="pennylane.device" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">num_wires</span><span class="p">)</span>


<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;jax&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">conv_net</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">last_layer_weights</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Define the QCNN circuit</span>
<span class="sd">    Args:</span>
<span class="sd">        weights (np.array): Parameters of the convolution and pool layers.</span>
<span class="sd">        last_layer_weights (np.array): Parameters of the last dense layer.</span>
<span class="sd">        features (np.array): Input data to be embedded using AmplitudEmbedding.&quot;&quot;&quot;</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">wires</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_wires</span><span class="p">))</span>

    <span class="c1"># inputs the state input_state</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AmplitudeEmbedding.html#pennylane.AmplitudeEmbedding" title="pennylane.AmplitudeEmbedding" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">AmplitudeEmbedding</span></a><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">wires</span><span class="p">,</span> <span class="n">pad_with</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Barrier.html#pennylane.Barrier" title="pennylane.Barrier" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Barrier</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">wires</span><span class="p">,</span> <span class="n">only_visual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># adds convolutional and pooling layers</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layers</span><span class="p">):</span>
        <span class="n">conv_and_pooling</span><span class="p">(</span><span class="n">weights</span><span class="p">[:,</span> <span class="n">j</span><span class="p">],</span> <span class="n">wires</span><span class="p">,</span> <span class="n">skip_first_layer</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">wires</span> <span class="o">=</span> <span class="n">wires</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>
        <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.Barrier.html#pennylane.Barrier" title="pennylane.Barrier" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class"><span class="n">qml</span><span class="o">.</span><span class="n">Barrier</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">wires</span><span class="p">,</span> <span class="n">only_visual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">last_layer_weights</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">4</span> <span class="o">**</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wires</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
        <span class="s2">&quot;The size of the last layer weights vector is incorrect!&quot;</span>
        <span class="sa">f</span><span class="s2">&quot; </span><span class="se">\n</span><span class="s2"> Expected </span><span class="si">{</span><span class="mi">4</span><span class="w"> </span><span class="o">**</span><span class="w"> </span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">wires</span><span class="p">))</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">, Given </span><span class="si">{</span><span class="n">last_layer_weights</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">dense_layer</span><span class="p">(</span><span class="n">last_layer_weights</span><span class="p">,</span> <span class="n">wires</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.probs.html#pennylane.probs" title="pennylane.probs" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">probs</span></a><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.draw_mpl.html#pennylane.draw_mpl" title="pennylane.draw_mpl" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-function"><span class="n">qml</span><span class="o">.</span><span class="n">draw_mpl</span></a><span class="p">(</span><a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv_net</span></a><span class="p">)(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="n">num_wires</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_learning_few_data_001.png" srcset="../_images/sphx_glr_tutorial_learning_few_data_001.png" alt="tutorial learning few data" class = "sphx-glr-single-img"/><p>In the problem we will address, we need to encode 64 features
in our quantum state. Thus, we require six qubits (<span class="math notranslate nohighlight">\(2^6 = 64\)</span>) to encode
each feature value in the amplitude of each computational basis state.</p>
</div>
<div class="section" id="training-the-qcnn-on-the-digits-dataset">
<h2>Training the QCNN on the digits dataset<a class="headerlink" href="#training-the-qcnn-on-the-digits-dataset" title="Permalink to this headline">¶</a></h2>
<p>In this demo, we are going to classify the digits <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> from the classical <code class="docutils literal notranslate"><span class="pre">digits</span></code> dataset.
Each hand-written digit image is represented as an <span class="math notranslate nohighlight">\(8 \times 8\)</span> array of pixels as shown below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
<span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_learning_few_data_002.png" srcset="../_images/sphx_glr_tutorial_learning_few_data_002.png" alt="tutorial learning few data" class = "sphx-glr-single-img"/><p>For convenience, we create a <code class="docutils literal notranslate"><span class="pre">load_digits_data</span></code> function that will make random training and
testing sets from the <code class="docutils literal notranslate"><span class="pre">digits</span></code> dataset from <code class="docutils literal notranslate"><span class="pre">sklearn.dataset</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_digits_data</span><span class="p">(</span><span class="n">num_train</span><span class="p">,</span> <span class="n">num_test</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return training and testing data of digits dataset.&quot;&quot;&quot;</span>
    <span class="n">digits</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_digits</span><span class="p">()</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span>

    <span class="c1"># only use first two classes</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))]</span>

    <span class="c1"># normalize data</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">features</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># subsample train and test split</span>
    <span class="n">train_indices</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">num_train</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">test_indices</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)),</span> <span class="n">train_indices</span><span class="p">),</span> <span class="n">num_test</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">train_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
    <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">features</span><span class="p">[</span><span class="n">test_indices</span><span class="p">],</span> <span class="n">labels</span><span class="p">[</span><span class="n">test_indices</span><span class="p">]</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span>
        <span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>To optimize the weights of our variational model, we define the cost and accuracy functions
to train and quantify the performance on the classification task of the previously described QCNN:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">compute_out</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the output of the corresponding label in the qcnn&quot;&quot;&quot;</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">feature</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <a href="https://docs.pennylane.ai/en/stable/code/api/pennylane.QNode.html#pennylane.QNode" title="pennylane.QNode" class="sphx-glr-backref-module-pennylane sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">conv_net</span></a><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">feature</span><span class="p">)[</span>
        <span class="n">label</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span>
        <span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the accuracy over the provided features and labels&quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">compute_out</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">out</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the cost over the provided features and labels&quot;&quot;&quot;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">compute_out</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_weights</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Initializes random weights for the QCNN model.&quot;&quot;&quot;</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">pnp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">weights_last</span> <span class="o">=</span> <span class="n">pnp</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">4</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">weights_last</span><span class="p">)</span>


<span class="n">value_and_grad</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">compute_cost</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>We are going to perform the classification for training sets with different values of <span class="math notranslate nohighlight">\(N\)</span>. Therefore, we
define the classification procedure once and then perform it for different datasets.
Finally, we update the weights using the <a class="reference external" href="https://docs.pennylane.ai/en/stable/code/api/pennylane.AdamOptimizer.html#pennylane.AdamOptimizer" title="(in PennyLane v0.30)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pennylane.AdamOptimizer</span></code></a> and use these updated weights to
calculate the cost and accuracy on the testing and training set:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_qcnn</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        n_train  (int): number of training examples</span>
<span class="sd">        n_test   (int): number of test examples</span>
<span class="sd">        n_epochs (int): number of training epochs</span>
<span class="sd">        desc  (string): displayed string during optimization</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: n_train,</span>
<span class="sd">        steps,</span>
<span class="sd">        train_cost_epochs,</span>
<span class="sd">        train_acc_epochs,</span>
<span class="sd">        test_cost_epochs,</span>
<span class="sd">        test_acc_epochs</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># load data</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_digits_data</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

    <span class="c1"># init weights and optimizer</span>
    <span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span> <span class="o">=</span> <span class="n">init_weights</span><span class="p">()</span>

    <span class="c1"># learning rate decay</span>
    <span class="n">cosine_decay_scheduler</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">cosine_decay_schedule</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">decay_steps</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">cosine_decay_scheduler</span><span class="p">)</span>
    <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">init</span><span class="p">((</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">))</span>

    <span class="c1"># data containers</span>
    <span class="n">train_cost_epochs</span><span class="p">,</span> <span class="n">test_cost_epochs</span><span class="p">,</span> <span class="n">train_acc_epochs</span><span class="p">,</span> <span class="n">test_acc_epochs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="c1"># Training step with (adam) optimizer</span>
        <span class="n">train_cost</span><span class="p">,</span> <span class="n">grad_circuit</span> <span class="o">=</span> <span class="n">value_and_grad</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">updates</span><span class="p">,</span> <span class="n">opt_state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">grad_circuit</span><span class="p">,</span> <span class="n">opt_state</span><span class="p">)</span>
        <span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">((</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">),</span> <span class="n">updates</span><span class="p">)</span>

        <span class="n">train_cost_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_cost</span><span class="p">)</span>

        <span class="c1"># compute accuracy on training data</span>
        <span class="n">train_acc</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">train_acc_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>

        <span class="c1"># compute accuracy and cost on testing data</span>
        <span class="n">test_out</span> <span class="o">=</span> <span class="n">compute_out</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">weights_last</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">test_out</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_out</span><span class="p">)</span>
        <span class="n">test_acc_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
        <span class="n">test_cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">test_out</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_out</span><span class="p">)</span>
        <span class="n">test_cost_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_cost</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">n_train</span><span class="o">=</span><span class="p">[</span><span class="n">n_train</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_epochs</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
        <span class="n">train_cost</span><span class="o">=</span><span class="n">train_cost_epochs</span><span class="p">,</span>
        <span class="n">train_acc</span><span class="o">=</span><span class="n">train_acc_epochs</span><span class="p">,</span>
        <span class="n">test_cost</span><span class="o">=</span><span class="n">test_cost_epochs</span><span class="p">,</span>
        <span class="n">test_acc</span><span class="o">=</span><span class="n">test_acc_epochs</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There are some small intricacies for speeding up this code that are worth mentioning. We are using <code class="docutils literal notranslate"><span class="pre">jax</span></code> for our training
because it allows for <a class="reference external" href="https://jax.readthedocs.io/en/latest/jax-101/02-jitting.html">just-in-time</a> (<code class="docutils literal notranslate"><span class="pre">jit</span></code>) compilation. A function decorated with <code class="docutils literal notranslate"><span class="pre">&#64;jax.jit</span></code> will be compiled upon its first execution
and cached for future executions. This means the first execution will take longer, but all subsequent executions are substantially faster.
Further, we use <code class="docutils literal notranslate"><span class="pre">jax.vmap</span></code> to vectorize the execution of the QCNN over all input states, as opposed to looping through the training and test set at every execution.</p>
</div>
<p>Training for different training set sizes yields different accuracies, as seen below. As we increase the training data size, the overall test accuracy,
a proxy for the models’ generalization capabilities, increases:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_test</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">n_reps</span> <span class="o">=</span> <span class="mi">100</span>


<span class="k">def</span> <span class="nf">run_iterations</span><span class="p">(</span><span class="n">n_train</span><span class="p">):</span>
    <span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train_acc&quot;</span><span class="p">,</span> <span class="s2">&quot;train_cost&quot;</span><span class="p">,</span> <span class="s2">&quot;test_acc&quot;</span><span class="p">,</span> <span class="s2">&quot;test_cost&quot;</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="s2">&quot;n_train&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_reps</span><span class="p">):</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">train_qcnn</span><span class="p">(</span><span class="n">n_train</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">)</span>
        <span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">results_df</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">results</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">results_df</span>


<span class="c1"># run training for multiple sizes</span>
<span class="n">train_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">80</span><span class="p">]</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">run_iterations</span><span class="p">(</span><span class="n">n_train</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n_train</span> <span class="ow">in</span> <span class="n">train_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
    <span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">results_df</span><span class="p">,</span> <span class="n">run_iterations</span><span class="p">(</span><span class="n">n_train</span><span class="o">=</span><span class="n">n_train</span><span class="p">)])</span>
</pre></div>
</div>
<p>Finally, we plot the loss and accuracy for both the training and testing set
for all training epochs, and compare the test and train accuracy of the model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># aggregate dataframe</span>
<span class="n">df_agg</span> <span class="o">=</span> <span class="n">results_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;n_train&quot;</span><span class="p">,</span> <span class="s2">&quot;step&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;std&quot;</span><span class="p">])</span>
<span class="n">df_agg</span> <span class="o">=</span> <span class="n">df_agg</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;whitegrid&#39;</span><span class="p">)</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">16.5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">generalization_errors</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># plot losses and accuracies</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_train</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df_agg</span><span class="p">[</span><span class="n">df_agg</span><span class="o">.</span><span class="n">n_train</span> <span class="o">==</span> <span class="n">n_train</span><span class="p">]</span>

    <span class="n">dfs</span> <span class="o">=</span> <span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">train_cost</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">test_cost</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">train_acc</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">],</span> <span class="n">df</span><span class="o">.</span><span class="n">test_acc</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]]</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="s2">&quot;x--&quot;</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="s2">&quot;x--&quot;</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">fr</span><span class="s2">&quot;$N=</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="sa">fr</span><span class="s2">&quot;$N=</span><span class="si">{</span><span class="n">n_train</span><span class="si">}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">axs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">axs</span><span class="p">[</span><span class="n">k</span><span class="p">]]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">step</span><span class="p">,</span> <span class="n">dfs</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">lines</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">labels</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">markevery</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>


    <span class="c1"># plot final loss difference</span>
    <span class="n">dif</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">step</span> <span class="o">==</span> <span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">test_cost</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">step</span> <span class="o">==</span> <span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">train_cost</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">]</span>
    <span class="n">generalization_errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dif</span><span class="p">)</span>

<span class="c1"># format loss plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Train and Test Losses&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>

<span class="c1"># format generalization error plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">generalization_errors</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$gen(\alpha)$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Generalization Error $gen(\alpha) = R(\alpha) - \hat</span><span class="si">{R}</span><span class="s1">_N(\alpha)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Training Set Size&#39;</span><span class="p">)</span>

<span class="c1"># format loss plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Train and Test Accuracies&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>

<span class="n">legend_elements</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">mpl</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;N=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">)</span>
    <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
    <span class="n">mpl</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Black&#39;</span><span class="p">),</span>
    <span class="n">mpl</span><span class="o">.</span><span class="n">lines</span><span class="o">.</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;Black&#39;</span><span class="p">)</span>
    <span class="p">]</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">legend_elements</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="n">legend_elements</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_tutorial_learning_few_data_003.png" srcset="../_images/sphx_glr_tutorial_learning_few_data_003.png" alt="Train and Test Losses, Generalization Error $gen(\alpha) = R(\alpha) - \hat{R}_N(\alpha)$, Train and Test Accuracies" class = "sphx-glr-single-img"/><hr class="docutils" />
<p>The key takeaway of this work is that some quantum learning
models can achieve high-fidelity predictions using a few training data points.
We implemented a model known as the quantum convolutional neural network (QCNN) using PennyLane
for a binary classification task. Using six qubits, we have trained the QCNN to distinguish
between handwritten digits of <span class="math notranslate nohighlight">\(0\)</span>’s and <span class="math notranslate nohighlight">\(1\)</span>’s. With <span class="math notranslate nohighlight">\(80\)</span> samples, we have
achieved a model with accuracy greater than <span class="math notranslate nohighlight">\(97\%\)</span> in <span class="math notranslate nohighlight">\(100\)</span> training epochs.
Furthermore, we have compared the test and train accuracy of this model for a different number of
training samples and found the scaling of the generalization error agrees with the theoretical
bounds obtained in <a class="footnote-reference brackets" href="#carogeneralization" id="id11">1</a>.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="carogeneralization"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id3">2</a>,<a href="#id4">3</a>,<a href="#id5">4</a>,<a href="#id11">5</a>)</span></dt>
<dd><p>Matthias C. Caro, Hsin-Yuan Huang, M. Cerezo, Kunal Sharma, Andrew Sornborger, Lukasz Cincio, Patrick J. Coles.
“Generalization in quantum machine learning from few training data”
<a class="reference external" href="https://arxiv.org/abs/2111.05292">arxiv:2111.05292</a>, 2021.</p>
</dd>
<dt class="label" id="dlbook"><span class="brackets"><a class="fn-backref" href="#id7">2</a></span></dt>
<dd><p>Ian Goodfellow, Yoshua Bengio and Aaron Courville.
<a class="reference external" href="http://www.deeplearningbook.org">“Deep Learning”2</a>, 2016.</p>
</dd>
<dt class="label" id="namkoongvariance"><span class="brackets"><a class="fn-backref" href="#id2">3</a></span></dt>
<dd><p>Hongseok Namkoong and John C. Duchi.
“Variance-based regularization with convex objectives.”
<a class="reference external" href="https://proceedings.neurips.cc/paper/2017/file/5a142a55461d5fef016acfb927fee0bd-Paper.pdf">Advances in Neural Information Processing Systems</a>, 2017.</p>
</dd>
<dt class="label" id="congquantumcnn"><span class="brackets">4</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id9">2</a>,<a href="#id10">3</a>)</span></dt>
<dd><p>Iris Cong, Soonwon Choi, Mikhail D. Lukin.
“Quantum Convolutional Neural Networks”
<a class="reference external" href="https://arxiv.org/abs/1810.03787">arxiv:1810.03787</a>, 2018.</p>
</dd>
<dt class="label" id="lenailnnsvg"><span class="brackets"><a class="fn-backref" href="#id8">5</a></span></dt>
<dd><p>Alexander LeNail.
“NN-SVG: Publication-Ready Neural Network Architecture Schematics”
<a class="reference external" href="https://doi.org/10.21105/joss.00747">Journal of Open Source Software</a>, 2019.</p>
</dd>
</dl>
</div>
<div class="section" id="about-the-authors">
<h2>About the authors<a class="headerlink" href="#about-the-authors" title="Permalink to this headline">¶</a></h2>
<div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/korbinian_kottmann.jpg" alt="Korbinian Kottmann" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Korbinian Kottmann</h4>
        <p class="bio-text__author-description">Korbinian is a Quantum Scientist at Xanadu, interested in quantum simulation and quantum software.</p>
    </div>
</div><div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/luis_mantilla.jpg" alt="Luis Mantilla Calderon" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Luis Mantilla Calderon</h4>
        <p class="bio-text__author-description">Luis is a summer resident at Xanadu. He works in quantum error correction and is interested in QML, quantum compilation, and BCI technology.</p>
    </div>
</div><div class="bio" >
    <div class="photo" >
        <img class="photo__img" src="../_static/authors/maurice_weber.jpeg" alt="Maurice Weber" >
    </div>
    <div class="bio-text">
        <h4 class="bio-text__author-name">Maurice Weber</h4>
        <p class="bio-text__author-description">Maurice is a summer resident at Xanadu and a PhD student at ETH Zürich. He is interested in the intersection of Machine Learning and Quantum Computing.</p>
    </div>
</div><p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 7 minutes  28.732 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-demos-tutorial-learning-few-data-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/db1cdebb407f9cf1c49f24ff7028aab8/tutorial_learning_few_data.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tutorial_learning_few_data.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6d415bf4225ad53e855560b70cc6d3e0/tutorial_learning_few_data.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tutorial_learning_few_data.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


    <script type="text/javascript">
        // This script ensures that the active navbar entry switches
        // from 'QML' to 'Demos' for any webpage within the demos/ directory,
        // or for any of the demonstration landing pages
        // (e.g., demos_optimization).
        var pagename = document.location.href.match(/[^\/]+$/)[0];
        var dir = document.URL.substr(0,document.URL.lastIndexOf('/')).match(/[^\/]+$/)[0];

        if (pagename.includes("demos") || pagename.includes("demonstrations") || dir.includes("demos")) {

            $(".nav-item.active").removeClass("active");
            var demos_link = $('.navbar-nav a').filter(function(index) { return $(this).text() === "Demos"; })[0]
            $(demos_link).parent().addClass("active");
        }
    </script>

              <div id="bottom-dl" class="xanadu-call-to-action-links">
                <div id="tutorial-type">demos/tutorial_learning_few_data</div>
                <div class="download-python-link">
                  <i class="fab fa-python"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Python script</div>
                </div>
                <div class="download-notebook-link">
                  <i class="fas fa-download"></i>&nbsp;
                  <div class="call-to-action-desktop-view">Download Notebook</div>
                </div>
                <div class="github-view-link">
                  <i class="fab fa-github"></i>&nbsp;
                  <div class="call-to-action-desktop-view">View on GitHub</div>
                </div>
              </div>

            </div>
            
          </div>
        
<div class="localtoc-container nano has-scrollbar">
  <div class="nano-content">
    <div id="localtoc">
        
          <h3>Contents</h3>
          <!-- Display the ToC for the current document if it is not empty. -->
          <ul class='current'>
<li class='current'><a class="reference internal" href="#">Generalization in QML from few training data</a><ul class='current'>
<li class='current'><a class="reference internal" href="#what-is-generalization-in-q-ml">What is generalization in (Q)ML?</a><ul class='current'>
<li class='current'><a class="reference internal" href="#generalization-bounds-for-qml-models">Generalization bounds for QML models</a></li>
</ul>
</li>
<li class='current'><a class="reference internal" href="#quantum-convolutional-neural-networks">Quantum convolutional neural networks</a></li>
<li class='current'><a class="reference internal" href="#breaking-down-the-layers">Breaking down the layers</a></li>
<li class='current'><a class="reference internal" href="#training-the-qcnn-on-the-digits-dataset">Training the QCNN on the digits dataset</a></li>
<li class='current'><a class="reference internal" href="#references">References</a></li>
<li class='current'><a class="reference internal" href="#about-the-authors">About the authors</a></li>
</ul>
</li>
</ul>

        
    </div>

    <div class="xanadu-call-to-action-links">
        <h3>Downloads</h3>
        <div id="tutorial-type">demos/tutorial_learning_few_data</div>
        <div class="download-python-link">
            <i class="fab fa-python"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Python script</div>
        </div>
        <div class="download-notebook-link">
            <i class="fas fa-download"></i>&nbsp;
            <div class="call-to-action-desktop-view">Download Notebook</div>
        </div>
        <div class="github-view-link">
            <i class="fab fa-github"></i>&nbsp;
            <div class="call-to-action-desktop-view">View on GitHub</div>
        </div>
    </div>
    <div id="related-tutorials" class="mt-4">
      <h3> Related</h3>
    </div>
  </div>
</div>


    
          <div class="up-button">
            
              
                <a href="../demos_qml.html"><i class="fas fa-angle-double-left"></i></a>
              
            
          </div>

          <div class="clearfix"></div>
        </div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="tutorial_geometric_qml.html" title="Introduction to Geometric Quantum Machine Learning"
             >next</a> |</li>
        <li class="right" >
          <a href="function_fitting_qsp.html" title="Function Fitting using Quantum Signal Processing"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">PennyLane  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../quantum-computing.html" >Quantum Computing</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../demonstrations.html" >Demos</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="../demos_qml.html" >Quantum machine learning</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Generalization in QML from few training data</a></li> 
      </ul>
    </div>
  <script type="text/javascript">
    $("#mobile-toggle").click(function () {
      $("#left-column").slideToggle("slow");
    });
  </script>

  <!-- jQuery -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/jquery-ui.min.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- Bootstrap core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <!-- MDB core JavaScript -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.10/js/mdb.min.js"></script>
  <!-- NanoScroller -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery.nanoscroller/0.8.7/javascripts/jquery.nanoscroller.min.js"></script>
  <!-- Syntax Highlighting -->
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js"></script>
  <script type="text/javascript">hljs.initHighlightingOnLoad();</script>

  <script type="text/javascript">
    $("a.reference.internal").each(function(){
      var link = $(this).attr("href");

      var hash = link.split("#")[1];
      var page = link.split("#")[0].split("/").slice(-1)[0].replace(".html", "");

      if (hash == page) {
        $(this).attr("href", link.split("#")[0]);
      }
    });

    $(".document > .section").removeClass("section");
    $("h1 ~ .section").removeClass("section");
    $(".localtoc-container .nano-content").css("height", $("#content").height());
    $(".localtoc-container").css("height", $("#content").height());
    $(".nano").nanoScroller();
  </script>

  <script type="text/javascript">
      $(window).scroll(function(){
        var scrollBottom = $(document).height() - $(window).height() - $(window).scrollTop();
        if (scrollBottom < 342) {
          $(".localtoc-container").css("height", "calc(100% - " + (342 - scrollBottom) + "px)");
          $(".localtoc-container .nano-content").css("height", "calc(100% - 119px)");
        }
      });
  </script>

  <script type="text/javascript">
    if ($(".current").length) {
      var target = $(".current")[0]
      var rect = target.getBoundingClientRect();
      if (rect.bottom > window.innerHeight) {
          $(".nano").nanoScroller({ scrollTo: $(".current") });
      } else {
          $(".nano").nanoScroller({ scrollTop: 0 });
      }
    }
    $(document).ready(function () {
        $(".css-transitions-only-after-page-load").each(function (index, element) {
            setTimeout(function () { $(element).removeClass("css-transitions-only-after-page-load") }, 10);
        });
        if (window.location.hash) {
          var target = $("[id='" + window.location.hash.substr(1) + "']");
          if (target.closest(".collapse").length) {
            target.closest(".collapse").addClass("show");
            target.closest(".collapse").prev().find(".rotate").addClass("up");
          }
        }
    });
  </script>

    <script type="text/javascript">
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrlArray = $("#tutorial-type").text().split('/');

      if (tutorialUrlArray[0] == "demos") {
        tutorialUrlArray[0] = "demonstrations";
      }

      var githubLink = "https://github.com/" + "PennyLaneAI/qml" + "/blob/master/" + tutorialUrlArray.join("/") + ".py",
          pythonLink = $(".sphx-glr-download .reference.download")[0].href,
          notebookLink = $(".sphx-glr-download .reference.download")[1].href;

      $(".download-python-link").wrap("<a href=" + pythonLink + " data-behavior='call-to-action-event' data-response='Download Python script' download target='_blank'/>");
      $(".download-notebook-link").wrap("<a href=" + notebookLink + " data-behavior='call-to-action-event' data-response='Download Notebook' download target='_blank'/>");
      $(".github-view-link").wrap("<a href=" + githubLink + " data-behavior='call-to-action-event' data-response='View on Github' target='_blank'/>");
      $("#right-column").addClass("page-shadow");
    } else {
      $(".xanadu-call-to-action-links").hide();
      $("#bottom-dl").attr('style','display: none !important');
    }
    </script>

    <script type="text/javascript">
      function makeUL(urls, text) {
          var list = document.createElement('ul');

          for (var i = 0; i < urls.length; i++) {
              var item = document.createElement('li');
              var a = document.createElement('a');
              var linkText = document.createTextNode(text[i]);
              a.appendChild(linkText);
              a.href = urls[i];
              item.appendChild(a);
              list.appendChild(item);
          }
          return list;
      }

      if (typeof related_tutorials !== 'undefined') {
          document.getElementById('related-tutorials').appendChild(makeUL(related_tutorials, related_tutorials_titles));
          $("#related-tutorials ul li a").append(' <i class="fas fa-angle-double-right" style="font-size: smaller;"></i>')
          $("#related-tutorials").show();

    } else {
          $("#related-tutorials").hide();
    }
    </script>

  <!-- Account for MathJax when navigating to anchor tags. -->
  <script type="text/javascript">
    function scrollToElement(e) {
      // Scrolls to the given element, taking into account the navbar.
      MathJax.Hub.Queue(function() {
        // The following MUST be done asynchronously to take effect.
        setTimeout(function() {
          const navbar = document.querySelector("nav.navbar");
          const navbarHeight = navbar ? navbar.offsetHeight : 0;
          const scrollToY = e.offsetTop + e.offsetParent.offsetTop - navbarHeight;
          window.scrollTo(0, scrollToY);
        }, 0);
      });
    }

    function scrollToFragment(fragment) {
      // Scrolls to the position of the given URL fragment (which includes the "#").
      const elementID = fragment.replace(".", "\\.");
      if (elementID !== "") {
        const element = document.querySelector(elementID);
        if (element !== null) {
          scrollToElement(element);
        }
      }
    }

    $(document).ready(() => {
      scrollToFragment(window.location.hash);
      window.addEventListener("popstate", (_) => scrollToFragment(document.location.hash), false);
    });
  </script>

  <!-- Hide the rendering of :orphan: metadata. -->
  <script type="text/javascript">
    $(document).ready(() => {
      const elements = document.getElementsByClassName("field-odd");
      for (const element of elements) {
          if (element.innerHTML.trim() === "orphan") {
            element.style.display = "none";
          }
      }
    });
  </script>

  <script type="text/javascript">
    jQuery.noConflict(true);
  </script>

  

<footer class="page-footer text-md-left pt-4">

  <hr class="pb-0 mb-0">
  <div class="container-fluid">
    <div class="row justify-content-md-center">

      
      <!-- About -->
      <div class="col-md-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <p>        PennyLane is an open-source software framework for quantum
        machine learning, quantum chemistry, and quantum computing, 
        with the ability to run on all hardware.
        Maintained with ❤️ by Xanadu.
        </p>
      </div>
      

      <!-- Links -->
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">PennyLane</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://pennylane.ai/">Home</a></li>
          
          <li><a href="https://pennylane.ai/qml">Learn</a></li>
          
          <li><a href="https://pennylane.ai/qml/demonstrations.html">Demonstrations</a></li>
          
          <li><a href="https://docs.pennylane.ai/">Documentation</a></li>
          
          <li><a href="https://github.com/PennyLaneAI/pennylane">GitHub</a></li>
          
          <li><a href="https://twitter.com/pennylaneai">Twitter</a></li>
          
          <li><a href="https://pennylane.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      
      <div class="col-md-2 col-4">
        <h5 class="mb-1 footer-heading">Xanadu</h5>
        <hr width=100px class="d-inline-block mt-0 mb-1 accent-4">
        <ul class="list-unstyled">
          
          <li><a href="https://xanadu.ai/">Home</a></li>
          
          <li><a href="https://xanadu.ai/about/">About</a></li>
          
          <li><a href="https://xanadu.ai/photonics">Hardware</a></li>
          
          <li><a href="https://xanadu.ai/careers/">Careers</a></li>
          
          <li><a href="https://cloud.xanadu.ai">Cloud</a></li>
          
          <li><a href="https://discuss.pennylane.ai/">Forum</a></li>
          
          <li><a href="https://xanadu.ai/blog">Blog</a></li>
          
        </ul>
      </div>
      

    </div>
  </div>
  <hr>

  <!-- Social -->
  <div class="social-section text-center">
      <ul class="list-unstyled list-inline mb-0">
          
          <li class="list-inline-item"><a class="btn-git" href="https://twitter.com/PennyLaneAI"><i class="fab fa-twitter"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://github.com/PennyLaneAI/pennylane"><i class="fab fa-github"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://linkedin.com/company/xanaduai/"><i class="fab fa-linkedin-in"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://discuss.pennylane.ai"><i class="fab fa-discourse"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://xanadu-quantum.slack.com/join/shared_invite/zt-nkwn25v9-H4hituCb_PUj4idG0MhSug#/shared-invite/email"><i class="fab fa-slack"> </i></a></li>
          
          <li class="list-inline-item"><a class="btn-git" href="https://pennylane.ai/blog/"><i class="fas fa-rss"> </i></a></li>
          
      </ul>
      
        
          <a href="https://xanadu.us17.list-manage.com/subscribe?u=725f07a1d1a4337416c3129fd&id=294b062630" style="font-size: initial;">
            Stay updated with our newsletter
          </a>
        
      
  </div>

  <!-- Copyright -->
  <div class="footer-copyright py-3 mt-0 text-center">
      <div class="container-fluid">
            Copyright &copy; 2022, Xanadu Quantum Technologies, Inc.

        
          <br>
          TensorFlow, the TensorFlow logo, and any related marks are trademarks of Google Inc.
        
      </div>
  </div>
</footer>
  </body>
</html>