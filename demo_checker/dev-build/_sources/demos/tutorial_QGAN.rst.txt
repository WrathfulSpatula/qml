
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "demos/tutorial_QGAN.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_demos_tutorial_QGAN.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_demos_tutorial_QGAN.py:


.. _quantum_GAN:

Quantum generative adversarial networks with Cirq + TensorFlow
==============================================================

.. meta::
    :property="og:description": This demo constructs and trains a Quantum
        Generative Adversarial Network (QGAN) using PennyLane, Cirq, and TensorFlow.
    :property="og:image": https://pennylane.ai/qml/_images/qgan3.png

*Author: Nathan Killoran — Posted: 11 October 2019. Last updated: 30 January 2023.*

This demo constructs a Quantum Generative Adversarial Network (QGAN)
(`Lloyd and Weedbrook
(2018) <https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.121.040502>`__,
`Dallaire-Demers and Killoran
(2018) <https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.012324>`__)
using two subcircuits, a *generator* and a *discriminator*. The
generator attempts to generate synthetic quantum data to match a pattern
of "real" data, while the discriminator tries to discern real data from
fake data (see image below). The gradient of the discriminator’s output provides a
training signal for the generator to improve its fake generated data.

|

.. figure:: ../demonstrations/QGAN/qgan.png
    :align: center
    :width: 75%
    :target: javascript:void(0)

|

.. GENERATED FROM PYTHON SOURCE LINES 38-45

Using Cirq + TensorFlow
-----------------------
PennyLane allows us to mix and match quantum devices and classical machine
learning software. For this demo, we will link together
Google's `Cirq <https://cirq.readthedocs.io/en/stable/>`_ and `TensorFlow <https://www.tensorflow.org/>`_ libraries.

We begin by importing PennyLane, NumPy, and TensorFlow.

.. GENERATED FROM PYTHON SOURCE LINES 45-50

.. code-block:: default


    import numpy as np
    import pennylane as qml
    import tensorflow as tf








.. GENERATED FROM PYTHON SOURCE LINES 51-52

We also declare a 3-qubit simulator device running in Cirq.

.. GENERATED FROM PYTHON SOURCE LINES 52-56

.. code-block:: default


    dev = qml.device('cirq.simulator', wires=3)









.. GENERATED FROM PYTHON SOURCE LINES 57-68

Generator and Discriminator
---------------------------

In classical GANs, the starting point is to draw samples either from
some "real data" distribution, or from the generator, and feed them to
the discriminator. In this QGAN example, we will use a quantum circuit
to generate the real data.

For this simple example, our real data will be a qubit that has been
rotated (from the starting state :math:`\left|0\right\rangle`) to some
arbitrary, but fixed, state.

.. GENERATED FROM PYTHON SOURCE LINES 68-74

.. code-block:: default


    def real(angles, **kwargs):
        qml.Hadamard(wires=0)
        qml.Rot(*angles, wires=0)









.. GENERATED FROM PYTHON SOURCE LINES 75-82

For the generator and discriminator, we will choose the same basic
circuit structure, but acting on different wires.

Both the real data circuit and the generator will output on wire 0,
which will be connected as an input to the discriminator. Wire 1 is
provided as a workspace for the generator, while the discriminator’s
output will be on wire 2.

.. GENERATED FROM PYTHON SOURCE LINES 82-111

.. code-block:: default


    def generator(w, **kwargs):
        qml.Hadamard(wires=0)
        qml.RX(w[0], wires=0)
        qml.RX(w[1], wires=1)
        qml.RY(w[2], wires=0)
        qml.RY(w[3], wires=1)
        qml.RZ(w[4], wires=0)
        qml.RZ(w[5], wires=1)
        qml.CNOT(wires=[0, 1])
        qml.RX(w[6], wires=0)
        qml.RY(w[7], wires=0)
        qml.RZ(w[8], wires=0)


    def discriminator(w):
        qml.Hadamard(wires=0)
        qml.RX(w[0], wires=0)
        qml.RX(w[1], wires=2)
        qml.RY(w[2], wires=0)
        qml.RY(w[3], wires=2)
        qml.RZ(w[4], wires=0)
        qml.RZ(w[5], wires=2)
        qml.CNOT(wires=[0, 2])
        qml.RX(w[6], wires=2)
        qml.RY(w[7], wires=2)
        qml.RZ(w[8], wires=2)









.. GENERATED FROM PYTHON SOURCE LINES 112-116

We create two QNodes. One where the real data source is wired up to the
discriminator, and one where the generator is connected to the
discriminator. In order to pass TensorFlow Variables into the quantum
circuits, we specify the ``"tf"`` interface.

.. GENERATED FROM PYTHON SOURCE LINES 116-131

.. code-block:: default


    @qml.qnode(dev, interface="tf")
    def real_disc_circuit(phi, theta, omega, disc_weights):
        real([phi, theta, omega])
        discriminator(disc_weights)
        return qml.expval(qml.PauliZ(2))


    @qml.qnode(dev, interface="tf")
    def gen_disc_circuit(gen_weights, disc_weights):
        generator(gen_weights)
        discriminator(disc_weights)
        return qml.expval(qml.PauliZ(2))









.. GENERATED FROM PYTHON SOURCE LINES 132-157

QGAN cost functions
-------------------

There are two cost functions of interest, corresponding to the two
stages of QGAN training. These cost functions are built from two pieces:
the first piece is the probability that the discriminator correctly
classifies real data as real. The second piece is the probability that the
discriminator classifies fake data (i.e., a state prepared by the
generator) as real.

The discriminator is trained to maximize the probability of
correctly classifying real data, while minimizing the probability of
mistakenly classifying fake data.

.. math:: 

    Cost_D = \mathrm{Pr}(real|\mathrm{fake}) - \mathrm{Pr}(real|\mathrm{real})

The generator is trained to maximize the probability that the
discriminator accepts fake data as real.

.. math:: 

    Cost_G = - \mathrm{Pr}(real|\mathrm{fake})


.. GENERATED FROM PYTHON SOURCE LINES 157-181

.. code-block:: default


    def prob_real_true(disc_weights):
        true_disc_output = real_disc_circuit(phi, theta, omega, disc_weights)
        # convert to probability
        prob_real_true = (true_disc_output + 1) / 2
        return prob_real_true


    def prob_fake_true(gen_weights, disc_weights):
        fake_disc_output = gen_disc_circuit(gen_weights, disc_weights)
        # convert to probability
        prob_fake_true = (fake_disc_output + 1) / 2
        return prob_fake_true


    def disc_cost(disc_weights):
        cost = prob_fake_true(gen_weights, disc_weights) - prob_real_true(disc_weights)
        return cost


    def gen_cost(gen_weights):
        return -prob_fake_true(gen_weights, disc_weights)









.. GENERATED FROM PYTHON SOURCE LINES 182-189

Training the QGAN
-----------------

We initialize the fixed angles of the "real data" circuit, as well as
the initial parameters for both generator and discriminator. These are
chosen so that the generator initially prepares a state on wire 0 that
is very close to the :math:`\left| 1 \right\rangle` state.

.. GENERATED FROM PYTHON SOURCE LINES 189-203

.. code-block:: default


    phi = np.pi / 6
    theta = np.pi / 2
    omega = np.pi / 7
    np.random.seed(0)
    eps = 1e-2
    init_gen_weights = np.array([np.pi] + [0] * 8) + \
                       np.random.normal(scale=eps, size=(9,))
    init_disc_weights = np.random.normal(size=(9,))

    gen_weights = tf.Variable(init_gen_weights)
    disc_weights = tf.Variable(init_disc_weights)









.. GENERATED FROM PYTHON SOURCE LINES 204-205

We begin by creating the optimizer:

.. GENERATED FROM PYTHON SOURCE LINES 205-209

.. code-block:: default


    opt = tf.keras.optimizers.SGD(0.4)
    opt.build([disc_weights, gen_weights])








.. GENERATED FROM PYTHON SOURCE LINES 210-212

In the first stage of training, we optimize the discriminator while
keeping the generator parameters fixed.

.. GENERATED FROM PYTHON SOURCE LINES 212-222

.. code-block:: default


    cost = lambda: disc_cost(disc_weights)

    for step in range(50):
        opt.minimize(cost, [disc_weights])
        if step % 5 == 0:
            cost_val = cost().numpy()
            print("Step {}: cost = {}".format(step, cost_val))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Step 0: cost = -0.057276904582977295
    Step 5: cost = -0.2634810581803322
    Step 10: cost = -0.42739149928092957
    Step 15: cost = -0.4726157709956169
    Step 20: cost = -0.48406896740198135
    Step 25: cost = -0.4894639253616333
    Step 30: cost = -0.4928186237812042
    Step 35: cost = -0.4949491620063782
    Step 40: cost = -0.4962702840566635
    Step 45: cost = -0.4970718026161194




.. GENERATED FROM PYTHON SOURCE LINES 223-225

At the discriminator’s optimum, the probability for the discriminator to
correctly classify the real data should be close to one.

.. GENERATED FROM PYTHON SOURCE LINES 225-229

.. code-block:: default


    print("Prob(real classified as real): ", prob_real_true(disc_weights).numpy())






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Prob(real classified as real):  0.9985870718955994




.. GENERATED FROM PYTHON SOURCE LINES 230-232

For comparison, we check how the discriminator classifies the
generator’s (still unoptimized) fake data:

.. GENERATED FROM PYTHON SOURCE LINES 232-236

.. code-block:: default


    print("Prob(fake classified as real): ", prob_fake_true(gen_weights, disc_weights).numpy())






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Prob(fake classified as real):  0.5011128038167953




.. GENERATED FROM PYTHON SOURCE LINES 237-242

In the adversarial game we now have to train the generator to better
fool the discriminator. For this demo, we only perform one stage of the
game. For more complex models, we would continue training the models in an
alternating fashion until we reach the optimum point of the two-player
adversarial game.

.. GENERATED FROM PYTHON SOURCE LINES 242-252

.. code-block:: default


    cost = lambda: gen_cost(gen_weights)

    for step in range(50):
        opt.minimize(cost, [gen_weights])
        if step % 5 == 0:
            cost_val = cost().numpy()
            print("Step {}: cost = {}".format(step, cost_val))






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Step 0: cost = -0.5833386406302452
    Step 5: cost = -0.8915732204914093
    Step 10: cost = -0.9784242212772369
    Step 15: cost = -0.9946482181549072
    Step 20: cost = -0.9984995126724243
    Step 25: cost = -0.9995637834072113
    Step 30: cost = -0.9998717606067657
    Step 35: cost = -0.999961793422699
    Step 40: cost = -0.9999887347221375
    Step 45: cost = -0.9999964535236359




.. GENERATED FROM PYTHON SOURCE LINES 253-255

At the optimum of the generator, the probability for the discriminator
to be fooled should be close to 1.

.. GENERATED FROM PYTHON SOURCE LINES 255-259

.. code-block:: default


    print("Prob(fake classified as real): ", prob_fake_true(gen_weights, disc_weights).numpy())






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Prob(fake classified as real):  0.9999987185001373




.. GENERATED FROM PYTHON SOURCE LINES 260-263

At the joint optimum the discriminator cost will be close to zero,
indicating that the discriminator assigns equal probability to both real and
generated data.

.. GENERATED FROM PYTHON SOURCE LINES 263-266

.. code-block:: default


    print("Discriminator cost: ", disc_cost(disc_weights).numpy())





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Discriminator cost:  0.0014116466045379639




.. GENERATED FROM PYTHON SOURCE LINES 267-274

The generator has successfully learned how to simulate the real data
enough to fool the discriminator.

Let's conclude by comparing the states of the real data circuit and the generator. We expect
the generator to have learned to be in a state that is very close to the one prepared in the
real data circuit. An easy way to access the state of the first qubit is through its
`Bloch sphere <https://en.wikipedia.org/wiki/Bloch_sphere>`__ representation:

.. GENERATED FROM PYTHON SOURCE LINES 274-290

.. code-block:: default


    obs = [qml.PauliX(0), qml.PauliY(0), qml.PauliZ(0)]

    @qml.qnode(dev, interface="tf")
    def bloch_vector_real(angles):
        real(angles)
        return [qml.expval(o) for o in obs]

    @qml.qnode(dev, interface="tf")
    def bloch_vector_generator(angles):
        generator(angles)
        return [qml.expval(o) for o in obs]

    print(f"Real Bloch vector: {bloch_vector_real([phi, theta, omega])}")
    print(f"Generator Bloch vector: {bloch_vector_generator(gen_weights)}")





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Real Bloch vector: [<tf.Tensor: shape=(), dtype=float64, numpy=-0.21694186329841614>, <tf.Tensor: shape=(), dtype=float64, numpy=0.45048439502716064>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.8660252690315247>]
    Generator Bloch vector: [<tf.Tensor: shape=(), dtype=float64, numpy=-0.28404659032821655>, <tf.Tensor: shape=(), dtype=float64, numpy=0.4189322590827942>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.8624440431594849>]




.. GENERATED FROM PYTHON SOURCE LINES 291-293

About the author
----------------
.. include:: ../_static/authors/nathan_killoran.txt


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  52.862 seconds)


.. _sphx_glr_download_demos_tutorial_QGAN.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example




    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tutorial_QGAN.py <tutorial_QGAN.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tutorial_QGAN.ipynb <tutorial_QGAN.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
